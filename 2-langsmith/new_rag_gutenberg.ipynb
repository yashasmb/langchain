{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09a237e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "757ccce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aef0d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                         \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                         \"Chrome/115.0 Safari/537.36\"}\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    \"https://www.gutenberg.org/files/84/84-h/84-h.htm\",\n",
    "    requests_kwargs={\"headers\": headers}\n",
    ")\n",
    "\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f75f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter  =   RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=300)\n",
    "splitted_docs_ori = splitter.split_documents(docs)\n",
    "len(splitted_docs_ori)\n",
    "splitted_docs = splitted_docs_ori[:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44ec32ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasha\\AppData\\Local\\Temp\\ipykernel_35592\\2256179261.py:3: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d75834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstoredb = FAISS.from_documents(splitted_docs, embeddings)\n",
    "vectorstoredb.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9987796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "llm = GoogleGenerativeAI(model = \"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "51ff456e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template=\"You are a knowledgeable literature assistant. \\n    Use ONLY the provided context (which comes from classic literature texts such as Project Gutenberg) \\n    to answer the question. \\n    If the context does not contain the answer, say 'I don't know based on the given text.' \\n    Do not use outside knowledge or make assumptions.\\n\\n    <context>\\n    {context}\\n    </context>\\n\\n    Question: {input}\\n    Answer:\"), additional_kwargs={})])\n",
       "| GoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), client=ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000017B500962C0>, default_metadata=(), model_kwargs={}))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a knowledgeable literature assistant. \n",
    "    Use ONLY the provided context (which comes from classic literature texts such as Project Gutenberg) \n",
    "    to answer the question. \n",
    "    If the context does not contain the answer, say 'I don't know based on the given text.' \n",
    "    Do not use outside knowledge or make assumptions.\n",
    "\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    Question: {input}\n",
    "    Answer:\"\"\"\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,)\n",
    "\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8470703",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstoredb.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retriever_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9fe1187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000017AC5DAF940>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template=\"You are a knowledgeable literature assistant. \\n    Use ONLY the provided context (which comes from classic literature texts such as Project Gutenberg) \\n    to answer the question. \\n    If the context does not contain the answer, say 'I don't know based on the given text.' \\n    Do not use outside knowledge or make assumptions.\\n\\n    <context>\\n    {context}\\n    </context>\\n\\n    Question: {input}\\n    Answer:\"), additional_kwargs={})])\n",
       "            | GoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), client=ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000017B500962C0>, default_metadata=(), model_kwargs={}))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b063ea8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"By July 7th, Robert Walton says that he is safe and well advanced on his voyage and in good spirits. He also states that his men are bold and firm of purpose. He makes no personal declaration regarding the voyage's ultimate success in this letter.\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is Robert Walton's assessment of his voyage's progress and the morale of his crew by July 7th, and what is his personal declaration regarding its ultimate success?\"\n",
    "response = retriever_chain.invoke({\"input\":question})\n",
    "\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "daad0c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"Who is the recipient of Robert Walton's first letter, and from what city is it sent?\",\n",
       " 'context': [Document(id='961ada54-5eb6-4983-b333-792a1ba37190', metadata={'source': 'https://www.gutenberg.org/files/84/84-h/84-h.htm', 'title': 'Frankenstein | Project Gutenberg', 'language': 'en'}, page_content='Your affectionate brother,\\r\\nRobert Walton\\r\\n\\n\\n\\nLetter 3\\n\\nTo Mrs. Saville, England.\\n\\n\\r\\nJuly 7th, 17—.\\r\\n\\n\\r\\nMy dear Sister,\\r\\n\\n\\r\\nI write a few lines in haste to say that I am safe—and well advanced on my\\r\\nvoyage. This letter will reach England by a merchantman now on its homeward\\r\\nvoyage from Archangel; more fortunate than I, who may not see my native land,\\r\\nperhaps, for many years. I am, however, in good spirits: my men are bold and\\r\\napparently firm of purpose, nor do the floating sheets of ice that continually\\r\\npass us, indicating the dangers of the region towards which we are advancing,\\r\\nappear to dismay them. We have already reached a very high latitude; but it is\\r\\nthe height of summer, and although not so warm as in England, the southern\\r\\ngales, which blow us speedily towards those shores which I so ardently desire\\r\\nto attain, breathe a degree of renovating warmth which I had not expected.\\r\\n\\n\\r\\nNo incidents have hitherto befallen us that would make a figure in a letter.\\r\\nOne or two stiff gales and the springing of a leak are accidents which\\r\\nexperienced navigators scarcely remember to record, and I shall be well content\\r\\nif nothing worse happen to us during our voyage.'),\n",
       "  Document(id='4f4fab38-faa4-4e13-8f5e-9300cb0b2191', metadata={'source': 'https://www.gutenberg.org/files/84/84-h/84-h.htm', 'title': 'Frankenstein | Project Gutenberg', 'language': 'en'}, page_content='But to return to dearer considerations. Shall I meet you again, after having\\r\\ntraversed immense seas, and returned by the most southern cape of Africa or\\r\\nAmerica? I dare not expect such success, yet I cannot bear to look on the\\r\\nreverse of the picture. Continue for the present to write to me by every\\r\\nopportunity: I may receive your letters on some occasions when I need them most\\r\\nto support my spirits. I love you very tenderly. Remember me with affection,\\r\\nshould you never hear from me again.\\r\\n\\n\\r\\nYour affectionate brother,\\r\\nRobert Walton\\r\\n\\n\\n\\nLetter 3\\n\\nTo Mrs. Saville, England.\\n\\n\\r\\nJuly 7th, 17—.\\r\\n\\n\\r\\nMy dear Sister,'),\n",
       "  Document(id='c70ae456-bee0-4eaa-8298-8ee122a1104f', metadata={'source': 'https://www.gutenberg.org/files/84/84-h/84-h.htm', 'title': 'Frankenstein | Project Gutenberg', 'language': 'en'}, page_content='I shall depart for the latter town in a fortnight or three weeks; and my\\r\\nintention is to hire a ship there, which can easily be done by paying the\\r\\ninsurance for the owner, and to engage as many sailors as I think necessary\\r\\namong those who are accustomed to the whale-fishing. I do not intend to sail\\r\\nuntil the month of June; and when shall I return? Ah, dear sister, how can I\\r\\nanswer this question? If I succeed, many, many months, perhaps years, will pass\\r\\nbefore you and I may meet. If I fail, you will see me again soon, or never.\\r\\n\\n\\r\\nFarewell, my dear, excellent Margaret. Heaven shower down blessings on you, and\\r\\nsave me, that I may again and again testify my gratitude for all your love and\\r\\nkindness.\\r\\n\\n\\r\\nYour affectionate brother,\\r\\nR. Walton\\r\\n\\n\\n\\nLetter 2\\n\\nTo Mrs. Saville, England.\\n\\n\\r\\nArchangel, 28th March, 17—.\\r\\n\\n\\r\\nHow slowly the time passes here, encompassed as I am by frost and snow! Yet a\\r\\nsecond step is taken towards my enterprise. I have hired a vessel and am\\r\\noccupied in collecting my sailors; those whom I have already engaged appear to\\r\\nbe men on whom I can depend and are certainly possessed of dauntless courage.'),\n",
       "  Document(id='73028572-fdb9-4275-867b-88032c5580fc', metadata={'source': 'https://www.gutenberg.org/files/84/84-h/84-h.htm', 'title': 'Frankenstein | Project Gutenberg', 'language': 'en'}, page_content='No incidents have hitherto befallen us that would make a figure in a letter.\\r\\nOne or two stiff gales and the springing of a leak are accidents which\\r\\nexperienced navigators scarcely remember to record, and I shall be well content\\r\\nif nothing worse happen to us during our voyage.\\r\\n\\n\\r\\nAdieu, my dear Margaret. Be assured that for my own sake, as well as yours, I\\r\\nwill not rashly encounter danger. I will be cool, persevering, and prudent.\\r\\n\\n\\r\\nBut success shall crown my endeavours. Wherefore not? Thus far I have\\r\\ngone, tracing a secure way over the pathless seas, the very stars themselves\\r\\nbeing witnesses and testimonies of my triumph. Why not still proceed over the\\r\\nuntamed yet obedient element? What can stop the determined heart and resolved\\r\\nwill of man?\\r\\n\\n\\r\\nMy swelling heart involuntarily pours itself out thus. But I must finish.\\r\\nHeaven bless my beloved sister!\\r\\n\\n\\r\\nR.W.\\r\\n\\n\\n\\nLetter 4\\n\\nTo Mrs. Saville, England.\\n\\n\\r\\nAugust 5th, 17—.\\r\\n\\n\\r\\nSo strange an accident has happened to us that I cannot forbear recording it,\\r\\nalthough it is very probable that you will see me before these papers can come\\r\\ninto your possession.')],\n",
       " 'answer': 'What month does R. Walton intend to sail?'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1ebf3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What does the author say about his education?\n"
     ]
    }
   ],
   "source": [
    "response = retriever_chain.invoke({\"input\": \"What is the main theme of the story?\"})\n",
    "print(response[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a801b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
