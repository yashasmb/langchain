{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ba475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ff9d1b3",
   "metadata": {},
   "source": [
    "## Text loader (.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "164f336c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.text.TextLoader at 0x2d3a7e47d00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('speech.txt')\n",
    "loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f3217b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'speech.txt'}, page_content='An actor (masculine/gender-neutral), ')]\n"
     ]
    }
   ],
   "source": [
    "print(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742ecd2",
   "metadata": {},
   "source": [
    "## Reading a pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2df2cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5475c4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250510174542', 'source': 'stroke.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1'}, page_content=\"IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING, VOL. XX, NO. XX, XXXX 2025 1\\nIdentification of subtypes of post-stroke and\\nneurotypical gait behaviors using neural network\\nanalysis of gait cycle kinematics\\nAndrian Kuch, Nicolas Schweighofer, James M. Finley, Alison McKenzie, Yuxin Wen and Natalia Sánchez\\nAbstract— Gait impairment post-stroke is highly\\nheterogeneous. Prior studies classified heterogeneous gait\\npatterns into subgroups using peak kinematics, kinetics,\\nor spatiotemporal variables. A limitation of this approach is\\nthe need to select discrete featuresin the gait cycle. Using\\ncontinuous gait cycle data, we accounted for differences\\nin magnitude and timing of kinematics. Here, we propose\\na machine-learning pipeline combining supervised and\\nunsupervised learning. We first trained a Convolutional\\nNeural Network and a Temporal Convolutional Network to\\nextract features that distinguish impaired from neurotypical\\ngait. Then, we used unsupervised time-series k-means and\\nGaussian Mixture Models to identify gait clusters. We tested\\nour pipeline using kinematic data of 28 neurotypical and 39\\nindividuals post-stroke. We assessed differences between\\nclusters using ANOVA. We identified two neurotypical gait\\nclusters (C1, C2). C1: normative gait pattern. C2: shorter\\nstride time. We observed three post-stroke gait clusters (S1,\\nS2, S3). S1: mild impairment and increased bilateral knee\\nflexion during loading response. S2: moderate impairment,\\nslow speed, short steps, increased knee flexion during\\nstance bilaterally, and reduced paretic knee flexion during\\nswing. S3: mild impairment, asymmetric swing time,\\nincreased ankle abduction during the gait cycle, and\\nreduced dorsiflexion bilaterally. Our results indicate that\\njoint kinematics post-stroke are mostly distinct from\\ncontrols, and highlight kinematic impairments in the\\nnon-paretic limb. The post-stroke clusters showed distinct\\nimpairments that would require different interventions,\\nproviding additional information for clinicians about\\nrehabilitation targets.\\nIndex Terms— clustering methods, kinematics, stroke,\\nmachine learning, neural networks, gait analysis,\\nneurorehabilitation\\nThis work was supported by grants NIH (NCMRR R03HD107630,\\nNCATS R03TR004248, KL2TR001854) to Natalia Sánchez\\n(Corresponding author). (Natalia Sánchez and Yuxin Wen share\\nthe senior authorship)\\nThis work involved human subjects or animals in its research.\\nApproval of all ethical and experimental procedures and protocols was\\ngranted by the University of Southern California Institutional Review\\nBoard (IRB HS-19-00430 and HS-18-00533, HS-19-00075) and by\\nChapman University (IRB-23-12).\\nAndrian Kuch, Alison McKenzie are with the Department of Physical\\nTherapy, Chapman University, CA, USA.\\nNicolas Schweighofer, James M. Finley are with the Division of\\nBiokinesiology and Physical Therapy, University of Southern California,\\nCA, USA.\\nYuxin Wen is with the Fowler School of Engineering, Chapman\\nUniversity, CA, USA\\nNatalia Sánchez (e-mail: sanchezaldana@chapman.edu) is with the\\nDepartment of Physical Therapy, Chapman University, CA, USA, and\\nthe Fowler School of Engineering, Chapman University, CA, USA.\\nI. I NTRODUCTION\\nG\\nAIT patterns differ between stroke survivors due\\nto heterogeneity in lesion type, size, location,\\nand differences in recovery [1]–[6]. These differences\\nmake intervention prescription difficult in research and\\nrehabilitation. By systematically identifying gait intervention\\ntargets, we can enhance the efficacy of physical therapy\\naimed at improving gait function in stroke survivors.\\nDifferent types of gait patterns post-stroke have been\\nidentified qualitatively and quantitatively in prior research\\nstudies [1], [2], [5]–[7]. Using visual assessment of paretic\\nelectromyography, a seminal study identified three subgroups\\nof abnormal muscle activation during gait post-stroke based\\non activation onset and levels: early triceps surae activation,\\ndecreased activation of paretic musculature, and paretic\\nmuscle coactivation [1]. Similarly, Olney and Richards\\nqualitatively identified different subgroups of gait impairments\\nusing peak spatiotemporal, peak kinematic, and peak kinetic\\ncharacteristics [6]. A more systematic quantitative approach\\nused activation onset, percentages of maximum voluntary\\ncontraction and peak kinematics for the paretic limb in\\ncombination with hierarchical clustering to identify four\\nclusters of gait behaviors post-stroke [2]: fast walkers with\\nmid-stance reduced knee flexion, an intermediate velocity\\ngroup with increased mid-stance knee flexion, slow walkers\\nwith excessive mid-stance knee flexion, and slow walkers\\nwith mid-stance knee hyperextension [2]. Our recent work\\nused spatiotemporal variables and peak ground reaction forces\\nfrom both the paretic and non-paretic extremities, input into\\na k-means clustering algorithm to identify five types of gait\\nbehaviors [5]. These included fast and asymmetric walkers,\\nmoderate speed and asymmetric walkers, slow walkers with\\nfrontal plane impairment, slow and symmetric walkers, and a\\ncluster of less impaired individuals with similar spatiotemporal\\nand kinetic characteristics to neurotypical controls. While\\nall these previous studies provided valuable information to\\nidentify different types of gait post-stroke, a caveat is that they\\nhave only used discrete metrics over the gait cycle [2], [5]–[7].\\nThese discrete gait metrics summarize changes in magnitude\\nbut not in the timing of gait kinematics, kinetics, and muscle\\nactivations that result in gait impairment post-stroke. Thus, an\\napproach that captures the dynamic patterns in the gait cycle\\ncontributing to walking impairment can provide additional\\ninformation for rehabilitation interventions.\\nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2025.3568325\\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250510174542', 'source': 'stroke.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2'}, page_content=\"2 IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING, VOL. XX, NO. XX, XXXX 2025\\nThe use of machine learning to study gait has become\\na common practice in research [8]. Previous studies using\\nsupervised methods aimed to classify neurotypical and\\npathological gait or detect different activities [8]. In a\\nrecent systematic review [8], most of the listed studies\\nextracted discrete summary features a priori to use as\\ninputs to machine learning. However, machine learning\\nalgorithms can be leveraged to use multivariate time series\\nas opposed to discrete data. Using time series data,\\nmachine learning frameworks distinguished neurotypical and\\npost-stroke gait using supervised [9], unsupervised [10],\\n[11], or self-supervised [12] methods. Researchers also\\nshowed different gait patterns in healthy individuals [13]\\nand individuals post-stroke [14]. Despite these advancements,\\na binary classification of impaired and non-impaired gait\\npatterns does not inform clinical practice and cannot, on its\\nown, identify gait subtypes.\\nUnsupervised approaches can identify gait subtypes and\\nspecific aspects of gait that need to be targeted systematically\\nduring rehabilitation interventions [10], [11], [15], [16].\\nPulido-Valdeolivas [15] combined dynamic time-warping\\nalgorithms with unsupervised clustering methods to identify\\nsix clusters of gait behaviors in individuals with hereditary\\nspastic paraplegia. These six clusters were: kinematics similar\\nto healthy adults, increased knee flexion at initial contact,\\nreduced knee flexion during swing, crouch gait, decreased\\nhip flexion, and jump-knee [15]. However, a completely\\nunsupervised approach can provide clusters that are difficult\\nto interpret without ground truth and external references to\\nvalidate the clusters [17]. Moreover, unsupervised methods\\nare dependent on the choice of distance measure, potentially\\nleading to results that are not always generalizable [17]. A\\nway to overcome this limitation is to combine supervised and\\nunsupervised learning. Starting with a supervised layer, we can\\nextract meaningful features that best distinguish impaired and\\nneurotypical gait. Then, based on the extracted features, we\\ncan leverage unsupervised methods to identify gait subtypes.\\nHere, we designed a pipeline to analyze gait cycle\\nkinematics by combining supervised and unsupervised\\nanalyses to identify clusters of gait behaviors. We implemented\\nour pipeline in participants post-stroke and neurotypical\\ncontrols. We hypothesized that we would observe distinct\\nclusters of gait behaviors in individuals post-stroke [1], [2],\\n[5], and a mixed cluster of control and individuals post-stroke\\n[5], inclusive of less impaired individuals with full recovery of\\ngait kinematics. We identified rehabilitation interventions that\\ncan be applied to each of our clusters based on the magnitude\\nand timing of gait impairment. Our proposed pipeline can be\\napplied to other continuous data during different motor tasks\\nand to other pathological populations to identify subtypes of\\nbehaviors across different variables and populations.\\nII. M ETHODS\\nData in n = 67 participants, including 39 individuals\\npost-stroke and 28 age and sex-matched neurotypical controls,\\nwere curated from previous studies (TABLE I) [5], [18],\\n[19]. Inclusion criteria for participants post-stroke were: (1)\\nunilateral cerebrovascular accident more than six months\\nbefore data collection, (2) unilateral paresis, (3) ability to\\nprovide informed consent, and (4) ability to walk 5 minutes\\non a treadmill without assistance (e.g., a cane or walker). The\\nuse of an ankle-foot orthosis or brace was permitted. Inclusion\\ncriteria for neurotypical participants were: (1) being of the\\nsame age and sex as a participant post-stroke, (2) having no\\nmusculoskeletal or neurologic injury that hinders walking, and\\n(3) the ability to provide informed consent.\\nA. Experimental protocol for data collection\\nWe performed the following assessments in participants\\npost-stroke and neurotypical controls: Berg Balance Scale\\n(BBS) [20], Activity-Specific Balance Confidence (ABC) test\\n[21], and 10-meter walk test. In participants post-stroke,\\nwe performed the lower extremity motor domain of the\\nFugl-Meyer (FM) assessment of motor impairment [22] and\\nthe Functional Gait Assessment (FGA) [23].\\nAfter clinical assessments, we determined participants’\\nself-selected speed on an instrumented treadmill (Bertec,\\nColumbus, USA). We used the staircase method [24], by\\nincreasing or decreasing the speed in steps of 0.05 m/s until\\nreaching at least 70% of the overground gait speed measured\\nvia the 10-meter walk test. Participants post-stroke walked at\\nthis speed for three minutes and were instructed to walk as\\nit felt natural. Neurotypical control participants walked at the\\nspeed of a post-stroke participant matched for age and sex, to\\ndifferentiate impairments due to stroke from those due to a\\nslower gait speed [25]. No handrail support was provided.\\nTABLE I: Participant demographics. F: Female, M: Male, SS: Self-selected,\\nFM: lower extremity Fugl-Meyer score, ABC: Activities Balance Confidence\\nScale, FGA: Functional Gait Assessment, BBS: Berg Balance Score, L:\\nLeft, R: Right. *Significant differences between participants post-stroke and\\ncontrols (p <0.05)\\nStroke (N=39) Control (N=28)\\nSex 17F/22M 16F/12M\\nAge (years) 59.5 ±10.8 [29-78] 62.4 ±14.2 [24-81]\\nMass (kg) 74.1 ±16.3 [45-104] 73 ±15.7 [46-110]\\nHeight (m) 1.58 ±0.08 [1.44-1.80] 1.60 ±0.09 [1.42-1.74]\\nSpeed (m/s) 0.56 ±0.20 [0.20-0.95]\\nSS: 0.84±0.26 [0.48-1.43]\\nSlow: 0.64±0.19 [0.3-1.0]\\nABC (100 max) 74.0±18.0* [38-98] 95.7±4.7 [83.75-100]\\nBBS (56 max) 50.8±5.5* [49-56] 54.1±2.6 [49-56]\\nFM (34 max) 26.6 ±4.83 [15-33]\\nFGA (30 max) 21.2 ±0.95 [6-30]\\nParesis 22R/17L\\nTime since stroke\\n(months) 92±84.5 [6-467]\\nSegmental kinematics were recorded using a full-body\\nmarker set, with bony landmarks and marker clusters [26],\\n[27]. Marker data were recorded using a 10-camera Qualisys\\nOqus motion capture system (Qualisys AB, Göteborg,\\nSweden) at 100 Hz. Forces were measured from force plates\\nembedded in the treadmill at 1000 Hz.\\nData processing: Markers were labeled using Qualisys\\nTrack Manager and exported to Visual 3D (C-Motion,\\nKingston, Canada) to construct a full-body model.\\nThree-dimensional marker positions were filtered using\\na Butterworth lowpass filter with a 6 Hz cutoff frequency.\\nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2025.3568325\\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250510174542', 'source': 'stroke.pdf', 'total_pages': 12, 'page': 2, 'page_label': '3'}, page_content=\"KUCH et al.: IDENTIFICATION OF SUBTYPES OF POST -STROKE AND NEUROTYPICAL GAIT BEHAVIORS USING NEURAL NETWORK ANAL YSIS OF GAIT\\nCYCLE KINEMATICS 3\\nWe then created a model in Visual 3D with the following\\nsegments: trunk, thighs, shanks, and feet. Participants\\npost-stroke wore a safety harness over their pelvis to prevent\\nfalls [19]. Thus, we removed the reflective markers from\\nthe pelvis, which prevented us from calculating hip and\\npelvis kinematics. All data were exported from Visual 3D to\\nMATLAB (2023b, The MathWorks Inc., Natick, USA) for\\nfurther processing and analysis using custom-written code.\\nAnkle plantar/dorsiflexion, ankle abduction/adduction, and\\nknee flexion/extension kinematics were extracted for the\\nmiddle 50 seconds of the gait trial bilaterally in all participants\\n(Fig. 1A). Data were segmented into strides using ground\\nreaction forces, with a threshold of 32 N [28], [29] to\\ndetect initial contact. All strides were interpolated in time\\nto 101 samples. The first sample corresponds to 0% of the\\ngait cycle, representing the non-dominant or paretic heel\\nstrike, and 100% corresponds to the end of the gait cycle.\\nIn participants post-stroke, we identified the paretic and\\nnon-paretic extremities. In neurotypical adults, the dominant\\nleg was the one they would use to kick a ball (right for all).\\nWe compared non-dominant to paretic side, and dominant to\\nnon-paretic side. We obtained the median gait cycle across all\\nstrides to reduce the influence of outlier stepping patterns, thus\\nobtaining a representative stride for each degree of freedom\\nbilaterally for each participant (Fig. 1A).\\nB. Kinematics clustering analyses\\nMachine learning pipeline: We used kinematics collected\\nat self-selected speed for individuals post-stroke and at the\\nmatched slower speed for neurotypical controls. Results using\\nself-selected speeds in controls are included in Supplement\\n1 [31]. We trained a supervised deep learning method\\ncombining a Convolutional Neural Network (CNN) [32], [33]\\nand a Temporal Convolutional Network (TCN) [34] with\\ncontrol/stroke labels to extract group distinctive features from\\ngait cycle kinematics in the frequency and time domains,\\nrespectively. To extract the frequency-related features of the\\ngait data, we first applied a continuous wavelet transform\\n[35] to express our data in the time-frequency domain, which\\nwe then fed into the CNN. In parallel, we used a TCN on\\nthe gait cycle kinematics to extract the time-related features.\\nThen, we used unsupervised time series k-means clustering to\\nidentify clusters of gait behaviors with the combined weights\\nof the CNN-TCN features. The clustering pipeline was coded\\nin Python (3.11, Python Software Foundation) and is available\\nonline [31]. The detailed stages of our pipeline are (Fig. 1B):\\n1) Convolutional Neural Network (Fig. 1B.1): We first\\npre-processed the 6 gait cycle joint angle data (size\\n6x101) into a continuous wavelet transform module.\\nThis allows a two-dimensional representation (64x64)\\nof the signals as time-related frequency components for\\nthe 6 joint angles (64x64x6). We multiplied each signal\\nby the Morlet wavelet, and the wavelet coefficients of\\nthe transformed signals were used as CNN inputs. A\\nCNN is designed to learn spatial hierarchies of features\\nautomatically and adaptively through backpropagation.\\n32 convolutional kernels with a 3×3 size, followed by\\na 2D max pooling layer, then 64 convolutional kernels\\nwith a 3×3 size, a 2D max pooling layer, were used to\\nextract high-level features. A flattened layer was used\\nto reorganize the feature maps into a one-dimensional\\narray and fed into two consecutive fully connected dense\\nlayers of 128 and 64 features (1x64), respectively.\\n2) Temporal Convolutional Network (Fig. 1 B.2): TCN is a\\nresidual network-based CNN designed for handling time\\nsequence data. To complement waveform characteristics\\ncollected by CNN, the kinematic data (size 6x101) were\\nfed in parallel into a TCN module to extract temporal\\nfeatures. By fusing the two networks, we can effectively\\nlearn spatial-temporal information. The output of TCN\\nis a flattened layer of 64 features (1x64).\\n3) Supervised feature extraction (Fig. 1 B.3): the outputs\\nof CNN and TCN were concatenated into a CNN-TCN\\nmodel and fed into two consecutive fully connected\\nlayers of 101 features (1x101) and trained with the labels\\ncontrol/stroke to identify the high-level spatiotemporal\\nfeatures for neurotypical and post-stroke gait.\\n4) Unsupervised clustering (Fig. 1 B.4): Once the full\\nmodel is trained, it extracts features used for time series\\nk-means clustering for all individuals in our data set.\\nTo ensure that the results were not dependent on a unique\\ntraining and testing split, we used 10,000 bootstrapped\\niterations. At each iteration, a new random stratified 80/20\\ntrain/test split was performed to train the models.\\nNumber of clusters: To determine the optimal number of\\nclusters c, we calculated the within clusters sum of squared\\nerrors to the cluster centroid over 10,000 bootstrap iterations\\n[36] for c= 2 to 10 clusters and selected c′ as the number\\nof clusters beyond which the sum of squared errors did not\\ndecrease significantly. We then selected c as the number of\\nclusters having an average within-cluster sum of squared errors\\nunder one standard error of c′ [17] (Fig. 1 C.1).\\nCluster stability: After the bootstrap iterations, we obtained\\na clustering matrix M (individuals x iterations) where each\\nelement represents a cluster number from 1 to c. We then\\nassessed cluster stability over all iterations, which was defined\\nas how often individuals were clustered together in a latent\\nspace. To do so, we first calculated a similarity matrix (size\\nindividuals x individuals):\\nSimilarityi,j =\\nPb\\nk=1 δ(Mi,k, Mj,k)\\nb (1)\\nWhere i and j are indices to represent individuals, k is the\\niteration index, b the total number of bootstrap iterations and\\nδ(Mi,k, Mj,k) =\\n(\\n1 if Mi,k = Mj,k\\n0 if Mi,k ̸= Mj,k\\n(2)\\nThen, we computed the dissimilarity matrix\\n(Dissimilarity = 1−Similarity, Fig. 1 C.2), and projected\\nit in a two-dimensional latent space using multidimensional\\nscaling, attempting to preserve the pairwise Euclidean\\ndistance between each element [17]. In the latent space, we\\nperformed a clustering using a Gaussian mixture model f(x):\\nf(x) =\\ncX\\nm=1\\nαmϕ(x; µm; Σm) (3)\\nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2025.3568325\\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250510174542', 'source': 'stroke.pdf', 'total_pages': 12, 'page': 3, 'page_label': '4'}, page_content=\"4 IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING, VOL. XX, NO. XX, XXXX 2025\\nFig. 1: A: Study pipeline. Median gait cycle knee and ankle kinematics are computed and fed into a Convolution Neural Network (CNN)-Temporal\\nConvolutional Network (TCN) to obtain gait clusters. We bootstrapped 10,000 times to assess the cluster number and composition. We then used 1-D\\nStatistical Parametric Mapping (SPM) to assess between-clusters differences. B: Detailed machine learning pipeline. Continuous Wavelet Transform (CWT).\\nStage 1: CNN. Stage 2: TCN ( [30]), blue circles: input layer (6x101 here), yellow circles: output layer (1x64 here). Stage 3: Feature extraction. Stage 4:\\nclustering. C: C.1: Optimal number of clusters. C.2: Dissimilarity matrix, 1: never in the same cluster, 0: always in the same cluster. C.3: Projection of the\\ndissimilarity matrix in a latent multidimensional scaling space (MDS). The clusters are identified using a 5-component Gaussian Mixture Model, represented\\nwith their respective 95 % confidence ellipse. Controls: C1 and C2, Stroke: S1, S2, and S3.\\nA Gaussian mixture model [17] is represented as a sum of\\nc Gaussian distributions ϕ, each having a mixing proportion\\nαm, mean µm, and full covariance matrices Σm (Fig. 1 C.3).\\nThis probabilistic method is suited to handle non-spherical\\nclusters in the latent space (Fig. 1 C.3) and allows us to obtain\\nindividual probability estimates of each participant belonging\\nto each of the identified clusters [17]. The Gaussian mixture\\nclustering was performed 10,000 times, each iteration having\\nnew initialization parameters.\\nPipeline comparisons: To verify if combining frequency and\\ntime-related features improves classification and clustering,\\nwe compared our supervised CNN-TCN pipeline to CNN\\nonly and TCN only. To assess whether combining supervised\\nand unsupervised methods provided better classification\\nand clustering, we also compared our pipeline to a fully\\nunsupervised time-series approach using the dtwclust package\\nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2025.3568325\\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250510174542', 'source': 'stroke.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5'}, page_content=\"KUCH et al.: IDENTIFICATION OF SUBTYPES OF POST -STROKE AND NEUROTYPICAL GAIT BEHAVIORS USING NEURAL NETWORK ANAL YSIS OF GAIT\\nCYCLE KINEMATICS 5\\nin the software R.\\nWe evaluated the accuracy of classifying individuals into\\neither the stroke or control group. For CNN-TCN, CNN\\nonly, and TCN only, after stage 3 (Fig. 1B.3), we added\\na fully connected layer using a sigmoid activation for a\\nbinary stroke/control classification. We used the classification\\naccuracy of each test set to build the confusion matrix of\\nactual versus predicted labels (stroke/control). Fordtwclust, we\\nused 10,000 iterations and a partitional clustering performed\\non the dynamic time-warping barycenter averaging centroids.\\nEach iteration had a new random seed to change the starting\\npoint of the algorithm. We used our entire data set of 67\\nindividuals for the dtwclust unsupervised clustering into two\\ngroups (stroke/control) and built the confusion matrix.\\nWe also evaluated how well the Gaussian Mixture Model\\ncaptures the data distribution in the multidimensional latent\\nspace, which visually represents the clustering structure.\\nWe identified the stable c clusters for CNN only, TCN\\nonly, and dtwclust as described before: dissimilarity matrix,\\nmultidimensional latent space, and Gaussian Mixture Model.\\nThen, we used log-likelihood ln( ˆL) to compare the goodness\\nof fit of each Gaussian mixture model in its own respective\\nlatent space. We identified the Gaussian mixture models with\\nthe highest log-likelihood across all iterations.\\nTo assess if the supervised layers are biased toward\\nclassifying an individual into control or stroke groups, we\\nmislabeled participants post-stroke in S1 who were the closest\\nto C2 in the multidimensional latent space as control, and\\nassessed how it affected their projection in the latent space\\nafter training (Supplement 2 [31]).\\nC. Statistical analysis\\nComparisons between individuals post-stroke and\\nneurotypical controls: We assessed differences in\\ndemographics and clinical measures between post-stroke and\\nneurotypical individuals in SPSS (29.0, IBM Corp, Armonk,\\nUSA). Normality was assessed using the Shapiro-Wilk test.\\nFor normal data, we used independent samples t-tests to\\ncompare between groups. Otherwise, we used the Wilcoxon\\nsigned rank test. To compare differences in the distribution\\nof males vs. females across groups, we used a χ2 test.\\nFor normal data, values are reported as mean ±SD, and\\nfor non-normal data, values are reported as median ±IQR.\\nKinematic comparisons showing differences during gait in\\nthe time and the time-frequency domain between participants\\npost-stroke and controls are provided in Supplement 3 [31].\\nComparison within clusters: Within stroke clusters (S1, S2,\\nS3), we used Student’s t-tests to assess for asymmetries\\nbetween paretic/non-paretic extremities for step lengths, swing\\ntimes, and stance times.\\nComparison between clusters: We used one-way ANOV A\\nto compare demographics, clinical and spatiotemporal\\ncharacteristics between clusters. If we observed significant\\nresults, we performed multiple comparisons with Tukey’s\\ntest. We clarify that the discrete metrics were not used in\\nthe machine learning pipeline to identify the distinct gait\\nclusters and were assessed post-hoc. We used 1-dimensional\\nstatistical parametric mapping one-way ANOV A [37] to assess\\ngait cycle kinematic differences between clusters. Post-hoc\\ntests were done via statistical parametric mapping t-tests with\\nBonferroni correction. For all post-hoc tests, the significance\\nlevel α was adjusted according to the number of pairwise\\ncomparisons within each outcome. We present the equivalent\\np-values readjusted to α = 0.05. We used 2-dimensional\\nstatistical parametric mapping [38] to compare the continuous\\nwavelet transform matrix coefficients between groups in the\\ntime-frequency domain (Supplement 4 [31]).\\nComparison to clinical and spatiotemporal clusters: We\\nevaluated whether CNN-TCN clustering using continuous\\nkinematic data returned different clusters than using only\\ndiscrete features [5]. We compared our kinematic-based\\nclusters to a k-means clustering using only discrete clinical and\\nspatiotemporal characteristics by computing the χ2 statistic on\\nthe contingency table. We further assessed the adjusted Rand\\nindex as a controlled for chance metric of similarity between\\ntwo clustering partitions [39]: 1 indicates complete agreement,\\n0 indicates no better agreement than a random clustering.\\nIII. R ESULTS\\nA. Differences between participants post-stroke and\\nneurotypical controls\\nWe observed no significant differences between participants\\npost-stroke and neurotypical controls in age, height, mass,\\nself-selected treadmill gait speed, matched gait speed (p>0.05),\\nand proportion of males vs. females (p>0.05). We observed\\nsignificant differences in ABC and BBS between participants\\npost-stroke and neurotypical controls (Wilcoxon Signed Rank\\ntest p<0.001, Table I).\\nB. CNN-TCN performed better than other algorithms\\nThe confusion matrix for the four evaluated algorithms\\nis presented in Table II. During the supervised analyses\\nand over 10,000 iterations, our CNN-TCN pipeline predicted\\nindividuals of the test set correctly 85.0 ±14.7 % of the time\\nfor participants with stroke and 87.7 ±11.2 % for control\\nparticipants. The overall accuracy for the CNN-TCN model\\nwas 86.4%, only marginally higher than for CNN only (86.3%)\\nand TCN only (84.1%) to classify individuals as stroke/control.\\nHowever, the log-likelihood was higher for the CNN-TCN\\nmodel (ln( ˆL) = 76.3) compared to CNN only ( ln( ˆL) = 1.6)\\nand TCN only ( ln( ˆL) = 37 .0), indicating a relatively better\\nfit of the five-component Gaussian Mixture Model for our\\nproposed full CNN-TCN pipeline.\\nThe unsupervised clustering based on dynamic\\ntime-warping package in R was better at predicting\\ncontrol individuals (94.8 ±0.1 %) but was close to random\\nat predicting individuals post-stroke (52.5 ±0.1 %), which\\nresulted in worse overall accuracy (73.7%). The log-likelihood\\nfor the dtwclust five components Gaussian Mixture Model\\nwas 34.3. Thus, when considering both accuracy and relative\\ngoodness of fit, our fused CNN-TCN pipeline fared better\\nthan each individual component and dtwclust. This suggests\\nthat adding ground truth knowledge in supervised analyses\\nusing two classes improves accuracy, and that combining both\\nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2025.3568325\\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250510174542', 'source': 'stroke.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6'}, page_content=\"6 IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING, VOL. XX, NO. XX, XXXX 2025\\ntemporal and spatial features improves cluster identification\\nin the multidimensional scaling space.\\nTABLE II : Confusion matrix for individual blocks of Convolutional\\nNeural Network (CNN), Temporal Convolutional Network (TCN), dual-stage\\nCNN-TCN and Dynamic Time-Warping clustering ( dtwclust)\\nCNN Predicted\\nStroke Control\\nActual Stroke 85.4% 14.5%\\nControl 12.9% 87.1%\\nTCN Predicted\\nStroke Control\\nActual Stroke 83.0% 17.0%\\nControl 14.8% 85.2%\\nCNN-TCN Predicted\\nStroke Control\\nActual Stroke 85.0% 15.0%\\nControl 12.3% 87.7%\\ndtwclust Predicted\\nStroke Control\\nActual Stroke 52.5% 47.5%\\nControl 5.2% 94.8%\\nC. k=5 provided stable clusters\\nWhen determining the optimal number of clusters, we\\nidentified the “elbow” [36] at k’=7, and then selected k=5 as\\nthe optimum number of clusters using the one standard error\\nrule [17] (Fig. 1 C.1). Thus, we computed a 5-component\\nGaussian mixture model from the dissimilarity matrix (Fig.\\n1 C.2). We observed two control clusters (C1, C2) and three\\nclusters of individuals post-stroke (S1, S2, S3) (Fig. 1 C.3).\\nThe mixing proportion of all but one individual was above\\n99% (Supplement 5 [31]). Only one participant in S2 had a\\nmixing proportion of 93% for S2, with a mixing proportion of\\n7% for S1. None of the individuals post-stroke were assigned\\nto a control cluster (Fig. 1 C.3).\\nWe provide in Supplement 1 [31] the clustering outcomes\\nusing controls’ kinematics at self-selected speed instead\\nof matched-speed. We obtained a similar structure (2\\ncontrol and 3 post-stroke clusters). However, using features\\nfrom controls at self-selected speed slightly altered the\\npost-stroke cluster assignment. This highlights the importance\\nof speed-matching in identifying clusters due to impairment\\nrather than gait speed. Despite these differences, the clinical\\nand spatiotemporal characteristics were not different between\\nself-selected clusters compared to matched-speed clusters.\\nWe further assessed that our pipeline did not introduce bias\\nin the supervised stage with the added knowledge of class to\\nextract features. 5 participants post-stroke were projected with\\nneurotypical individuals when being mislabeled, suggesting\\nthat there is a subset of individuals in S1 with a neurotypical\\ncontrol gait pattern that might not have been detected\\nas a stroke participant with only unsupervised methods\\n(Supplement 2 [31]).\\nD. All clusters had significantly different clinical\\ncharacteristics and kinematic patterns\\nWe compared demographics, clinical measures, and\\nspatiotemporal characteristics using one-way ANOV A\\nbetween the five identified clusters (C1, C2, S1, S2,\\nS3). All clinical measures were significantly different\\nbetween groups (Fig. 2): FM (p=0.003), FGA (p=0.02),\\nABC (p<0.001), and BBS (p<0.001). Age (p=0.56) and\\nheight (p=0.94) were not different between clusters. The\\nfollowing spatiotemporal characteristics were significantly\\ndifferent between clusters: gait speed (p=0.003), stride\\nlength (p=0.008), paretic/non-dominant step length\\n(p=0.01), non-paretic/dominant step length (p=0.007),\\nstride time (p=0.001), paretic/non-dominant stance\\ntime (p<0.001), and non-paretic/dominant stance time\\n(p=0.004). Paretic/non-dominant swing time (p=0.57)\\nand non-paretic/dominant swing time (p=0.08) were not\\nsignificantly different between clusters.\\nFig. 2: Clinical and spatiotemporal characteristics of clusters (Controls: C1\\nand C2, Stroke: S1, S2, and S3). One-way ANOV A showed a difference for all\\nparameters (p<0.05), except paretic/non-dominant and non-paretic/dominant\\nswing times (p=0.574 and p=0.078, respectively). FM: Fugl-Meyer lower\\nextremity, ABC: Activities Balance Confidence, FGA: Functional Gait\\nAssessment, BBS: Berg Balance Scale, P: Paretic, NP: Non-Paretic, D:\\nDominant, ND: Non-Dominant. ∗ lower than all the other clusters, + lower\\nthan C1 and C2, - difference between two clusters.\\nFor the knee and ankle kinematics, the 1D SPM\\none-way ANOV A showed significant differences between\\nclusters in all degrees of freedom: paretic/non-dominant\\nankle plantar/dorsiflexion (p<0.001 whole gait cycle),\\nnon-paretic/dominant ankle plantar/dorsiflexion (p=0.049\\nat loading response, p=0.001 during pre-swing,\\np=0.006 at terminal stance), paretic/non-dominant ankle\\nabduction/adduction (p=0.03 during loading response),\\nnon-paretic/dominant ankle abduction/adduction (p<0.001\\nwhole gait cycle), paretic/non-dominant knee flexion/extension\\n(p=0.03 at initial contact and loading response, p<0.001\\nduring pre-swing, p=0.04 during terminal swing) and\\nnon-paretic/dominant knee flexion/extension (p=0.002 during\\nterminal swing, p=0.001 during loading response and swing,\\np=0.007 during pre-swing). Supplement 6 [31] contains a\\nshort walking clip of each cluster, which we describe next:\\nControl Cluster 1 (C1): N=12 controls. Normative gait\\npattern (Fig. 3). C1 was exclusively composed of control\\nindividuals. Participants in C1 were 62.8 ±13.8 years old\\nand walked at a self-selected speed of 0.96 ±0.28 m/s. Their\\nmatched-speed to participants post-stroke was significantly\\nslower than their self-selected speed (0.65 ±0.20 m/s, p=0.01).\\nTheir non-dominant and dominant step lengths were both\\n0.39±0.07 m, stride length was 0.78 ±0.13 m, stride time\\nwas 1.45 ±0.26 s, non-dominant stance time was 0.99 ±0.22\\ns, dominant stance time was 1.03 ±0.26 s, non-dominant\\nswing time was 0.46 ±0.06 s, and dominant swing time was\\n0.45±0.06 s (Fig. 2). The kinematics in this cluster are those\\ndescribed in the literature for healthy adults [40]. Thus, we\\nwill report post-hoc comparisons relative to C1 in Fig. 4.\\nControl Cluster 2 (C2): N=16 controls. Control\\nparticipants with short stride times. Participants in C2\\nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2025.3568325\\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250510174542', 'source': 'stroke.pdf', 'total_pages': 12, 'page': 6, 'page_label': '7'}, page_content=\"KUCH et al.: IDENTIFICATION OF SUBTYPES OF POST -STROKE AND NEUROTYPICAL GAIT BEHAVIORS USING NEURAL NETWORK ANAL YSIS OF GAIT\\nCYCLE KINEMATICS 7\\nFig. 3: Normative kinematics for C1, and gait phases snapshots from Visual\\n3D. The gait cycle starts at the non-dominant initial contact (IC). TO: toe-off.\\nwere 62.1 ±15.6 years old, walked at a self-selected speed\\nof 0.75 ±0.22 m/s (significantly slower than the self-selected\\nspeed of C1, p=0.03), and a matched-speed to participants\\npost-stroke of 0.63 ±0.18 m/s, (significantly slower than their\\nself-selected speed, p=0.034, but not significantly slower\\nthan the matched-speed of C1). Compared to C1, they had\\nshorter non-dominant stance time (0.78 ±0.13 s, p=0.02)\\nand stride time (1.18 ±0.16 s, p=0.009) when walking at\\nspeeds matched to participants post-stroke (Fig. 2). The\\nnon-dominant step length (0.34±0.08 m), dominant step length\\n(0.32±0.08 m), stride length (0.66 ±0.16 m), dominant stance\\ntime (0.82 ±0.18 s), non-dominant swing time (0.39 ±0.06\\ns), and dominant swing time (0.35 ±0.15 s) were not\\nsignificantly different from C1. We did not observe significant\\ndifferences in kinematics between C1 and C2 (Fig. 4 C1\\nC2). The differences between the two control clusters are\\npresent in the time-frequency domain for the dominant knee\\nflexion/extension (Supplement 4 [31]). In the same range of\\nnormalized frequency [0.025-0.034 cycles/sample], compared\\nto C1, the coefficients of the continuous wavelet transform\\nmatrix in C2 were lower during initial swing and loading\\nresponse, but higher during mid-swing (Supplement 4 [31]).\\nThis suggests more stable knee kinematics during loading\\nresponse and increased variability during swing, likely caused\\nby the different stepping strategies at a slower gait speed (Fig.\\n2, Supplement 6 [31]).\\nStroke Cluster 1 (S1): N=17. Participants post-stroke\\nwith bilateral increased knee flexion at initial\\ncontact/loading response. Participants in S1 were 58.2 ±13.8\\nyears old and walked at a speed of 0.65 ±0.17 m/s (Fig. 2).\\nTheir FM score was 29 ±4, indicating mild impairment, FGA\\nwas 23 ±5, and BBS was 54 ±2. ABC was 74 ±14, lower\\nthan C1 (p<0.001) and C2 (p<0.001) (Fig. 2). Compared\\nto C1, they had a shorter paretic stance time (0.76 ±0.19\\ns, p=0.005), but no differences were found for paretic step\\nlength (0.35 ±0.07 m), non-paretic step length (0.35 ±0.08\\nm), stride length (0.70 ±0.15 m), stride time (1.24 ±0.22\\ns), non-paretic stance time (0.88 ±0.21 s), paretic swing\\ntime (0.48 ±0.30 s), and non-paretic swing time (0.37 ±0.06\\ns) (Fig. 2). At a cluster level in S1, no asymmetry was\\ndetected between the paretic and non-paretic extremities for\\nstep length (p=0.90), swing time (p=0.14) and stance time\\n(p=0.07). Compared to C1, we observed increased paretic\\nknee flexion at initial contact/loading response (p=0.047),\\nand during terminal swing (p=0.04) (Fig. 4 C1 S1). In the\\nnon-paretic extremity, we observed increased ankle abduction\\nduring pre-swing (p=0.04), terminal swing (p=0.04), and\\nterminal stance (p=0.007). Finally, for the non-paretic side, we\\nobserved increased knee flexion during pre-swing (p=0.01),\\nat initial contact, and loading response (p=0.02).\\nStroke Cluster 2 (S2): N=12. Increased stance knee\\nflexion bilaterally and reduced paretic swing knee flexion.\\nParticipants in S2 were 64.0 ±3.4 years old and walked at\\na slower speed (0.40 ±0.15 m/s, p<0.05 compared to all\\nother clusters) (Fig. 2). The FM score was 23 ±5, indicating\\nmoderate impairment. The FM score was lower than S1\\n(p=0.004) and S3 (p=0.02). FGA was 17 ±6, lower than S1\\n(p=0.019) but not S3 (p=0.06). BBS was 46 ±7, lower than\\nS1 (p<0.001) and S3 (p=0.02). ABC was 76 ±15. Compared\\nto C1, individuals post-stroke in S2 had a shorter paretic\\nstep length (0.26 ±0.08 m, p=0.005), non-paretic step length\\n(0.25±0.09 m, p=0.004), and stride length (0.51 ±0.17 m,\\np=0.004). Compared to S1, paretic step length (p=0.005),\\nnon-paretic step length (p=0.004) and stride length (p=0.004)\\nwere also shorter, with longer stride time (1.47 ±0.22 s,\\np=0.039) and paretic stance time (0.99 ±0.18 s, p=0.005).\\nTheir non-paretic stance time was 1.12 ±0.25 s, paretic\\nswing time 0.48 ±0.15 s, non-paretic swing time 0.35 ±0.12\\ns (Fig. 2). At a cluster level in S2, no asymmetry was\\ndetected between the paretic and non-paretic extremities\\nfor step length (p=0.84), swing time (p=0.07) and stance\\ntime (p=0.18). Compared to C1, we observed increased\\nparetic ankle abduction during loading response and stance\\n(p<0.001), and terminal swing (p=0.02) (Fig. 4 C1 S2).\\nWe further observed increased paretic knee flexion at initial\\ncontact and loading response (p=0.046), and during terminal\\nswing (p=0.04), and decreased paretic knee flexion mid-swing\\n(p=0.02). In the non-paretic extremity, we observed increased\\nankle abduction during the entire stance phase (p<0.001) and\\npre-swing (p=0.046). We also observed decreased non-paretic\\ndorsiflexion at initial contact and loading response (p=0.008).\\nFinally, we observed increased non-paretic knee flexion from\\nterminal swing to loading response (p=0.006). Compared\\nto S1, S2 had decreased paretic knee flexion mid-swing\\n(p=0.007) (Fig. 4 S1 S2). After Bonferroni correction,\\ndifferences between S2 and S3 were not significant in the\\ntime domain (Fig. 4 S2 S3), or in the time-frequency domain\\n(Supplement 4 [31]). Post-hoc comparisons between stroke\\nclusters are reported in Fig. 4.\\nStroke Cluster 3 (S3): N=10. Impaired ankle function.\\nParticipants in S3 were 56.7 ±11.1 years old and walked at a\\nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2025.3568325\\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250510174542', 'source': 'stroke.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8'}, page_content=\"8 IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING, VOL. XX, NO. XX, XXXX 2025\\nFig. 4: Post-hoc 1D-Statistical Parametric Mapping t-test with Bonferroni correction of joint kinematics for the median gait cycle between the reference\\ncontrol cluster C1 (purple) and the other clusters, and between all three stroke clusters. The non-dominant side for control individuals is compared to the\\nparetic side of individuals post-stroke, and the dominant side to the non-paretic.\\nspeed of 0.62 ±0.19 m/s. The FM score was 28 ±4, ABC was\\n79±12, FGA was 23 ±5, BBS was 52 ±3 (Fig. 4). Compared\\nto C1, they had similar gait spatiotemporal characteristics\\nparetic step length was 0.33 ±0.09 m, non-paretic step\\nlength 0.34 ±0.08 m, stride length 0.67 ±0.17 m, stride time\\n1.31±0.22 s, paretic stance time 0.82 ±0.18 s, non-paretic\\nstance time 0.92 ±0.12 s, paretic swing time 0.49 ±0.07 s,\\nnon-paretic swing time 0.38 ±0.05 s. The peak knee flexion\\noccurring earlier in the gait cycle caused a longer swing\\ntime on the paretic side (p=0.001). Compared to C1, we\\nobserved increased paretic ankle abduction bilaterally for\\nthe entire gait cycle (both p<0.001) (Fig. 4). We observed\\ndecreased paretic dorsiflexion during loading response and\\nmid-stance (p<0.001). We observed increased paretic knee\\nflexion from loading response to mid-stance (p<0.001) and\\nduring pre-swing (p=0.001) and terminal swing (p=0.03). In\\nthe non-paretic extremity, we observed decreased dorsiflexion\\nduring loading response (p=0.003) and terminal stance\\n(p=0.003). Finally, we observed increased knee flexion during\\npre-swing and initial swing (p<0.001), initial contact and\\nloading response (p=0.004), and terminal stance (p=0.01). The\\ndifferences between S1 and S3 were not significant in the time\\ndomain, but significant in the time-frequency domain for all\\njoints during the gait cycle (Supplement 4 [31]).\\nE. Kinematics clusters are different from clinical and\\nspatiotemporal clusters\\nWe compared our kinematic stroke clusters (S1, S2, S3)\\nwith a k-means clustering using clinical and spatiotemporal\\nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2025.3568325\\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250510174542', 'source': 'stroke.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9'}, page_content=\"KUCH et al.: IDENTIFICATION OF SUBTYPES OF POST -STROKE AND NEUROTYPICAL GAIT BEHAVIORS USING NEURAL NETWORK ANAL YSIS OF GAIT\\nCYCLE KINEMATICS 9\\ncharacteristics (listed in Fig. 2) for 3 clusters (S1’, S2’, S3’).\\nWe observed that most individuals in S1 and S2 were grouped\\ntogether in S1’ and S2’, respectively, while individuals\\nfrom S3 were split (Table III). Detailed spatiotemporal\\ncharacteristics of S1’, S2’, and S3’ are presented in\\nSupplement 7 [31]. We found a significant association between\\nthe two clustering results ( p = 0 .008), and an adjusted\\nRand index of 0.19, indicating low agreement. Moreover,\\nusing a decision tree classifier to identify each cluster’s most\\ninfluential discrete features, we observed different features\\nand different feature boundaries (Supplement 7 [31]). This\\nsuggests that clinical and spatiotemporal characteristics do not\\nfully capture kinematic gait subtypes.\\nTABLE III : Contingency table for stroke clusters using continuous\\nkinematics compared to discrete clinical and spatiotemporal characteristics\\nClinical\\nspatiotemporal\\nKinematic\\nS1’ S2’ S3’\\nS1 12 2 3\\nS2 1 8 3\\nS3 5 2 3\\nIV. D ISCUSSION\\nGait impairment is heterogeneous, posing a challenge in\\nprescribing research or rehabilitation interventions [4]. To\\ninform rehabilitation, previous research identified post-stroke\\ngait subgroups based on peak spatiotemporal characteristics,\\npeak kinematics, peak kinetics, or muscular activity [1],\\n[2], [5]–[7]. These discrete metrics cannot capture the\\nsimultaneous temporal and spatial variation in the gait cycle\\nin people post-stroke. Here, we developed a pipeline using\\nconvolutional networks to identify gait subgroups and tested\\nit with gait cycle kinematics of neurotypical and individuals\\nwith chronic stroke. We showed that providing the true labels\\nin a supervised stage first to extract frequency and time-related\\nfeatures from gait cycle kinematics was more accurate than a\\nfully unsupervised dynamic time-warping clustering.\\nOur pipeline identified distinct gait behaviors in both\\nneurotypical controls and participants post-stroke. In control\\nparticipants, the subgroups were differentiated by the\\nself-selected gait speed, which was slower in C2, reshaping\\ntheir gait pattern and altering spatiotemporal and kinematics\\ncharacteristics [41]. In participants post-stroke, subgroups\\nwere characterized by kinematic impairments that affected\\ndistinct phases of the gait cycle. The supervised portion of our\\npipeline performed similarly to previous work distinguishing\\nbetween post-stroke and neurotypical gait [9], [10], [12], [14].\\nOur results indicate that at a joint kinematics level, most\\nparticipants post-stroke have movement patterns distinct from\\nneurotypical controls. As the sample size increases, it is likely\\nthat a more densely populated multidimensional latent space\\nreveals a continuum of gait impairment ranging from highly\\nimpaired to recovered. In cases where individuals are projected\\nbetween distinct clusters, clinicians could use the cluster\\nmembership probability provided by the Gaussian Mixture\\nModel as an objective criterion to inform treatment. Our\\nresults also indicate that individuals post-stroke show similar\\nlevels of function and impairment measured using clinical\\noutcomes while displaying different joint kinematics. Finally,\\nour results highlight movement patterns in the non-paretic\\nextremity during gait, which are seldom reported [6], [42],\\n[43] and differ from typically described compensatory patterns\\n[44]. Using our pipeline, we have provided a more detailed\\nassessment of the distinct types of gait behaviors post-stroke,\\nwhich affect both the paretic and non-paretic extremities, and\\ncan point to specific intervention targets post-stroke.\\nThe post-stroke clusters in our study point to different\\nimpairments and potential rehabilitation interventions. S1,\\nparticipants post-stroke with increased knee flexion at initial\\ncontact/loading and terminal swing bilaterally showed the least\\namount of gait impairments. The increased paretic knee flexion\\nseen during loading response and terminal swing corresponds\\nto common knee patterns post-stroke [6], [45] and might\\nindicate potential hip extensor weakness [42], [43]. Treatment\\nfor participants in S1 might include strengthening of hip\\nextensors, as well as knee extensors during functional tasks\\ntraining such as stair climbing, sit-to-stand, and exercises\\nchallenging eccentric contractions. S2, participants post-stroke\\nwith increased stance knee flexion, reduced swing knee\\nflexion, and reduced dorsiflexion showed the most impaired\\ngait pattern. Participants in S2 also showed increased ankle\\nabduction in the paretic extremity, which might point to limb\\ncircumduction to advance the paretic limb forward due to the\\nobserved decreased knee flexion during the swing phase [6],\\n[42], [45]. Participants in S2 may benefit from dorsiflexion\\nstrengthening, electrical stimulation of dorsiflexors during\\nswing to elicit a mass flexion response [4], [43], an ankle-foot\\northosis [4], [43], manual cues to guide knee flexion during\\nswing [4], and balance training [46]. S3 showed no differences\\nin speed, FM, FGA, or Berg to S1, yet it showed additional\\ngait impairments, including a flexed knee during stance\\nbilaterally, increased non-paretic knee flexion during swing,\\nreduced dorsiflexion bilaterally, and increased ankle abduction.\\nPotential treatments for participants in S3 may include\\nstrengthening of hip extensors, hamstrings, knee extensors,\\nand dorsiflexors. Additional treatments might include gait\\nretraining with an emphasis on improving coordination due\\nto bilateral impairment, such as walking with an incline or on\\nuneven ground [47], or action observation interventions [48].\\nOur present clusters share common clinical and\\nspatiotemporal characteristics compared to our previous\\nwork that used discrete spatiotemporal and kinetics data [5],\\nwithout using any of this information in the training process.\\nParticipants in S1 had similar clinical and spatiotemporal\\ncharacteristics as ‘the moderate speed, symmetric, and\\nshort stance times’ cluster [5]. Participants in S2 have\\nsimilar spatiotemporal characteristics to the ‘slow speed and\\nfrontal plane force asymmetries’ group [5], only differing\\nin not having stance time asymmetry. This suggests that\\ncharacteristics defining some subtypes of gait post-stroke\\nclusters are consistent and could be generalizable. In addition,\\nthe characteristics of participants in S3 differed from any of\\nour previous work, suggesting that our current approach is\\nable to identify behavior post-stroke that was not detected\\nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2025.3568325\\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250510174542', 'source': 'stroke.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10'}, page_content=\"10 IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING, VOL. XX, NO. XX, XXXX 2025\\nwith only discrete data. This result is further strengthened\\nby the low agreement between clusters from kinematics and\\ndiscrete clinical spatiotemporal characteristics (Table III).\\nPrevious studies have used speed alone [3], or identified\\nspeed as the main determinant of cluster allocation [2]. Our\\nfindings contrast with those studies, as S1 and S3 had similar\\nspeeds and clinical characteristics while showing different\\nkinematic patterns, indicating that clinical scores are not\\ngranular enough to show specific gait kinematic impairments.\\nUsing kinematics over a gait cycle, we obtained two\\nmoderate-speed clusters and one slow cluster. Characteristics\\nof our clusters resembled those previously reported [2]. S1,\\nwhich had slightly decreased terminal swing knee extension,\\ninitial contact and loading response but adequate dorsiflexion,\\nresembled the Fast group reported by Mulroy [2], despite\\nthe more moderate gait speed in our participants. S2 had a\\nslow speed with excessive stance knee flexion and inadequate\\nswing dorsiflexion, similar to what was reported by Mulroy\\nas the slow flexed group [2]. We supplement this information\\nby showing impaired non-paretic kinematics, particularly\\nincreasing non-paretic ankle abduction through stance, and\\nreduced non-paretic dorsiflexion during swing, and increased\\nnon-paretic knee flexion in loading response in S2. The\\nimpairments we observed in the non-paretic limb suggest\\ncompensatory behavior [49], [50] or additional impairments\\nin the non-paretic extremity [51]. We did not observe a knee\\nhyperextension pattern as in previous work [2], [6], [45]. Our\\nfindings show that clinical measures such as speed or FM\\nscore are not sensitive to kinematic differences. Thus, our\\napproach can provide insights beyond what is provided by\\nclinical measures.\\nCombining both time-frequency (CNN) and time-related\\nfeatures (TCN) to find subgroups of gait only marginally\\nimproved the accuracy of classifying neurotypical and\\npost-stroke gait. However, CNN-TCN provided a relatively\\nbetter model to identify clusters of gait behaviors post-stroke\\nin the multidimensional latent space. Our 86.4% accuracy for\\nbinary classification of stroke/control is comparable to other\\nframeworks using kinematic-only methods, ranging from 85%\\nto 91% [9], [12]. Previous works classified gait activities [52]\\nor pathology [53] using time-frequency. Our results indicate\\nthat post-stroke gait subtypes also exist in the time-frequency\\ndomain (Supplement 4 [31]), where higher frequencies might\\nindicate instability and impaired inter-limb coordination [53].\\nFuture work could compare our gait subtypes to eventual\\nsubtypes using the feature space obtained from other machine\\nlearning algorithm frameworks, based on support vector\\nmachine [9], variational autoencoder [10], attention [12], deep\\nneural networks [13], or recurrent neural networks [14].\\nUsing a median gait cycle for each joint angle to\\ncharacterize an individual instead of raw time-series inherently\\nreduces the stride-to-stride variability of gait post-stroke.\\nThus, our work differs from studies using entire gait bouts\\nto analyze gait in healthy adults [13] and stroke survivors\\n[10], [14]. Since TCN performs well in capturing temporal\\ndependencies [54], with non-time-normalized raw data as\\ninput, TCN might weigh more in a CNN-TCN architecture,\\nand TCN alone could be sufficient to identify the gait clusters.\\nAnother solution could be non-linear registration as proposed\\nin recent frameworks [11], [15], [16], [55]. Pataky [55] showed\\nthat separating the amplitude and time-shift of time-series\\ndata could highlight differences not detected with linear\\nnormalization. Moreover, using time-normalizing gait cycles\\npotentially reduced alignment differences between signals, and\\nusing non-normalized time-series might improve the clustering\\noutcome for a dynamic time-warping clustering approach.\\nWhile kinematics differences were expected in the\\npost-stroke clusters [2], [5], [6], they were not significant\\nin the two control clusters. By adding the time-frequency\\ndomain in our pipeline, we were able to differentiate: 1)\\nbetween neurotypical adults presenting normative gait patterns\\nand neurotypical adults with affected kinematics because a\\nmatched slower gait speed [25], 2) between highly functional\\nindividuals post-stroke who scored high in all the clinical\\nassessments and ‘visually normal’ kinematics and neurotypical\\ncontrols. Our approach has the potential to complement and\\naugment the clinical observation of gait since it can use any\\ntype of time series captured in a clinical setting with wearable\\ndevices [56] or phones [57]. Another application could be\\nto instrument clinical assessments, such as the Fugl-Meyer\\nAssessment or Berg Balance Scale, and investigate how\\nmovement strategies are associated with specific impairments.\\nLimitations\\nA clear limitation of our study is the lack of hip kinematics,\\nlimiting our ability to identify subtypes of hip impairment,\\nwhich are potentially at the root of knee and ankle impairment.\\nWith hip kinematics, we might detect additional clusters and\\nexpand the implications of our work. Our marker set did not\\nallow us to measure accurately the inversion and eversion of\\nthe foot, which is often impaired post-stroke. Participants were\\nallowed to use walking aids, which modify ankle and knee\\nkinematics post-stroke [58]. Given that only two participants\\nin our study wore ankle braces, this should not affect our\\nfindings significantly. Spasticity and botulinum toxin injection\\ntreatment were not controlled for, which may affect gait.\\nFinally, we identified subtypes of gait post-stroke with distinct\\nkinematic patterns, but we did not identify which kinematic\\nfeatures are the most important to characterize a subtype.\\nV. C ONCLUSION\\nThe presented machine-learning pipeline used entire gait\\ncycle kinematics to identify five distinct gait subgroups. We\\nshowed that individuals post-stroke differed from neurotypical\\nindividuals at a joint level, even when they had mild\\nimpairment and similar spatiotemporal characteristics. Our\\napproach has the potential to aid clinicians by augmenting\\nobservation of gait. Our proposed pipeline can be implemented\\non other time series data during different motor tasks and\\non other pathological populations to identify subgroups of\\nbehaviors across different variables and populations.\\nACKNOWLEDGEMENTS\\nWe thank Chang Liu, Sungwoo Park, Tara Cornwell, Ryan\\nNovotny, Catherine Yunis, and Isabel Munoz-Orozco, who\\ncontributed to data collection and processing for this study.\\nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2025.3568325\\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250510174542', 'source': 'stroke.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11'}, page_content=\"KUCH et al.: IDENTIFICATION OF SUBTYPES OF POST -STROKE AND NEUROTYPICAL GAIT BEHAVIORS USING NEURAL NETWORK ANAL YSIS OF GAIT\\nCYCLE KINEMATICS 11\\nREFERENCES\\n[1] E. Knutsson and C. Richards, “Different types of disturbed motor control\\nin gait of hemiparetic patients,” Brain, vol. 102, pp. 405–430, 1979.\\n[2] S. Mulroy, J. Gronley, W. Weiss, C. Newsam, and J. Perry, “Use of\\ncluster analysis for gait pattern classification of patients in the early\\nand late recovery phases following stroke,” Gait & Posture , vol. 18,\\npp. 114–125, 8 2003.\\n[3] J. Perry, M. Garrett, J. Gronley, and S. Mulroy, “Classification of walking\\nhandicap in the stroke population,” Stroke, vol. 26, pp. 982–989, 1995.\\n[4] C. Winstein, J. Stein, R. Arena, B. Bates, L. Cherney, S. Cramer,\\nF. Deruyter, J. Eng, B. Fisher, R. Harvey, C. Lang, M. MacKay-Lyons,\\nK. Ottenbacher, S. Pugh, M. Reeves, L. Richards, W. Stiers, and\\nR. Zorowitz, “Guidelines for adult stroke rehabilitation and recovery:\\nA guideline for healthcare professionals from the american heart\\nassociation/american stroke association,” Stroke, vol. 47, pp. e98–e169,\\n6 2016.\\n[5] N. Sánchez, N. Schweighofer, S. J. Mulroy, R. T. Roemmich, T. M.\\nKesar, G. Torres-Oviedo, B. E. Fisher, J. M. Finley, and C. J. Winstein,\\n“Multi-site identification and generalization of clusters of walking\\nbehaviors in individuals with chronic stroke and neurotypical controls,”\\nNeurorehabilitation and Neural Repair , vol. 37, pp. 810–822, 12 2023.\\n[6] S. J. Olney and C. Richards, “Hemiparetic gait following stroke. part i:\\nCharacteristics,” Gait & Posture, vol. 4, pp. 136–148, 4 1996.\\n[7] H. Kim, Y . Kim, S. Kim, and M. Choi, “Pathological gait clustering\\nin post-stroke patients using motion capture data,” Gait and Posture ,\\nvol. 94, pp. 210–216, 5 2022.\\n[8] P. Khera and N. Kumar, “Role of machine learning in gait analysis:\\na review,” Journal of Medical Engineering and Technology , vol. 44,\\npp. 441–467, 11 2020.\\n[9] C. Cui, G. B. Bian, Z. G. Hou, J. Zhao, G. Su, H. Zhou, L. Peng,\\nand W. Wang, “Simultaneous recognition and assessment of post-stroke\\nhemiparetic gait by fusing kinematic, kinetic, and electrophysiological\\ndata,” IEEE Transactions on Neural Systems and Rehabilitation\\nEngineering, vol. 26, pp. 856–864, 4 2018.\\n[10] R. Felius, M. Punt, M. Geerars, N. Wouda, R. Rutgers, S. Bruijn,\\nS. David, and J. van Dieën, “Exploring unsupervised feature extraction\\nof imu-based gait data in stroke rehabilitation using a variational\\nautoencoder,” Plos one, vol. 19, no. 10, p. e0304558, 2024.\\n[11] K. Swaminathan, I. Tolkova, L. Baker, D. Arumukhom Revi,\\nL. N. Awad, C. J. Walsh, and L. Mahadevan, “A continuous\\nstatistical-geometric framework for normative and impaired gaits,”\\nJournal of the Royal Society Interface , vol. 19, no. 196, p. 20220402,\\n2022.\\n[12] R. J. Cotton, J. Peiffer, K. Shah, A. DeLillo, A. Cimorelli, S. Anarwala,\\nK. Abdou, and T. Karakostas, “Self-supervised learning of gait-based\\nbiomarkers,” in International Workshop on PRedictive Intelligence In\\nMEdicine, pp. 277–291, Springer, 2023.\\n[13] F. Horst, S. Lapuschkin, W. Samek, K.-R. Müller, and W. I. Schöllhorn,\\n“Explaining the unique nature of individual gait patterns with deep\\nlearning,” Scientific reports, vol. 9, no. 1, p. 2391, 2019.\\n[14] T. S. Winner, M. C. Rosenberg, K. Jain, T. M. Kesar, L. H. Ting,\\nand G. J. Berman, “Discovering individual-specific gait signatures\\nfrom data-driven models of neuromechanical dynamics,” PLOS\\nComputational Biology, vol. 19, no. 10, p. e1011556, 2023.\\n[15] I. Pulido-Valdeolivas, D. Gómez-Andrés, J. A. Martín-Gonzalo,\\nI. Rodríguez-Andonaegui, J. López-López, S. I. Pascual-Pascual, and\\nE. Rausell, “Gait phenotypes in paediatric hereditary spastic paraplegia\\nrevealed by dynamic time warping analysis and random forests,” PLoS\\nONE, vol. 13, 3 2018.\\n[16] A. Sardá-Espinosa, “Comparing time-series clustering algorithms in r\\nusing the dtwclust package,” The R Journal , vol. 11, p. 22, 2019.\\n[17] T. Hastie, R. Tibshirani, and J. Friedman, “The elements of statistical\\nlearning data mining, inference, and prediction,” 2009.\\n[18] S. Park, C. Liu, N. Sánchez, J. K. Tilson, S. J. Mulroy, and J. M. Finley,\\n“Using biofeedback to reduce step length asymmetry impairs dynamic\\nbalance in people poststroke,” Neurorehabilitation and Neural Repair ,\\nvol. 35, pp. 738–749, 8 2021.\\n[19] C. Liu, J. L. McNitt-Gray, and J. M. Finley, “Impairments in the\\nmechanical effectiveness of reactive balance control strategies during\\nwalking in people post-stroke,” Frontiers in Neurology, vol. 13, 10 2022.\\n[20] K. Berg, “Measuring balance in the elderly: preliminary development of\\nan instrument,” Physiotherapy Canada, vol. 41, pp. 304–311, 11 1989.\\n[21] E. M. Botner, W. C. Miller, and J. J. Eng, “Measurement properties of\\nthe activities-specific balance confidence scale among individuals with\\nstroke,” Disability and Rehabilitation , vol. 27, pp. 156–163, 2 2005.\\n[22] A. R. Fugl-Meyer, L. Jääskö, I. Leyman, S. Olsson, and S. Steglind, “The\\npost-stroke hemiplegic patient. 1. a method for evaluation of physical\\nperformance.,” Scandinavian journal of rehabilitation medicine , vol. 7,\\npp. 13–31, 1975.\\n[23] J. H. Lin, M. J. Hsu, H. W. Hsu, H. C. Wu, and C. L. Hsieh,\\n“Psychometric comparisons of 3 functional ambulation measures for\\npatients with stroke,” Stroke, vol. 41, pp. 2021–2025, 9 2010.\\n[24] T. N. Cornsweet, “The staircase-method in psychophysics,” The\\nAmerican Journal of Psychology , vol. 75, p. 485, 9 1962.\\n[25] G. Chen, C. Patten, D. Kothari, and F. Zajac, “Gait differences between\\nindividuals with post-stroke hemiparesis and non-disabled controls at\\nmatched speeds,” Gait and Posture, vol. 22, pp. 51–56, 8 2005.\\n[26] C. Liu, L. D. Macedo, and J. M. Finley, “Conservation of reactive\\nstabilization strategies in the presence of step length asymmetries during\\nwalking,” Frontiers in Human Neuroscience , vol. 12, 6 2018.\\n[27] K. L. Havens, T. Mukherjee, and J. M. Finley, “Analysis of biases in\\ndynamic margins of stability introduced by the use of simplified center\\nof mass estimates during walking and turning,”Gait and Posture, vol. 59,\\npp. 162–167, 1 2018.\\n[28] B. P. Selgrade, M. Thajchayapong, G. E. Lee, M. E. Toney, and\\nY . H. Chang, “Changes in mechanical work during neural adaptation\\nto asymmetric locomotion,” Journal of Experimental Biology , vol. 220,\\npp. 2993–3000, 8 2017.\\n[29] N. Sánchez, S. N. Simha, J. M. Donelan, and J. M. Finley,\\n“Using asymmetry to your advantage: Learning to acquire and accept\\nexternal assistance during prolonged split-belt walking,” Journal of\\nNeurophysiology, vol. 125, pp. 344–357, 2 2021.\\n[30] K. Lee, J. Ray, and C. Safta, “The predictive skill of convolutional neural\\nnetworks models for disease forecasting (figure 3) - cc by 4.0,” PLoS\\nONE, vol. 16, 7 2021.\\n[31] A. Kuch, N. Schweighofer, J. Finley, A. McKenzie, Y . Wen, and\\nN. Sánchez, “Code repository.” https://zenodo.org/records/11998330,\\n2024.\\n[32] L. Alzubaidi, J. Zhang, A. Humaidi, A. AlDujaili, Y . Duan,\\nO. AlShamma, J. Santamaría, M. Fadhel, M. AlAmidie, and L. Farhan,\\n“Review of deep learning: concepts, cnn architectures, challenges,\\napplications, future directions,” Journal of Big Data , vol. 8, 12 2021.\\n[33] D. Jung, M. D. Nguyen, M. Park, J. Kim, and K. R. Mun, “Multiple\\nclassification of gait using time-frequency representations and deep\\nconvolutional neural networks,” IEEE Transactions on Neural Systems\\nand Rehabilitation Engineering , vol. 28, pp. 997–1005, 4 2020.\\n[34] S. Bai, J. Z. Kolter, and V . Koltun, “An empirical evaluation of generic\\nconvolutional and recurrent networks for sequence modeling,” 3 2018.\\n[35] O. Rioul and P. Duhamel, “Fast algorithms for discrete and continuous\\nwavelet transforms,” IEEE Transactions on Information Theory, vol. 38,\\npp. 569–586, 3 1992.\\n[36] M. A. Syakur, B. K. Khotimah, E. M. Rochman, and B. D.\\nSatoto, “Integration k-means clustering method and elbow method for\\nidentification of the best customer profile cluster,” in IOP Conference:\\nMaterials Science and Engineering , vol. 336, IOP Publishing, 4 2018.\\n[37] T. C. Pataky, M. A. Robinson, and J. Vanrenterghem, “Region-of-interest\\nanalyses of onedimensional biomechanical trajectories: Bridging 0d and\\n1d theory, augmenting statistical power,” PeerJ, vol. 2016, 2016.\\n[38] T. C. Pataky, “Generalized n-dimensional biomechanical field analysis\\nusing statistical parametric mapping,” Journal of Biomechanics, vol. 43,\\npp. 1976–1982, 7 2010.\\n[39] L. Hubert and P. Arabie, “Comparing partitions,” Journal of\\nclassification, vol. 2, pp. 193–218, 1985.\\n[40] C. A. Fukuchi, R. K. Fukuchi, and M. Duarte, “A public dataset of\\noverground and treadmill walking kinematics and kinetics in healthy\\nindividuals,” PeerJ, vol. 2018, 2018.\\n[41] C. A. Fukuchi, R. K. Fukuchi, and M. Duarte, “Effects of walking speed\\non gait biomechanics in healthy participants: A systematic review and\\nmeta-analysis,” Systematic Reviews, vol. 8, 6 2019.\\n[42] B. Balaban and F. Tok, “Gait disturbances in patients with stroke,” PM\\nand R, vol. 6, pp. 635–642, 2014.\\n[43] C. Beyaert, R. Vasa, and G. E. Frykberg, “Gait post-stroke:\\nPathophysiology and rehabilitation strategies,” Neurophysiologie\\nClinique, vol. 45, pp. 335–355, 2015.\\n[44] N. Sánchez, A. M. Acosta, R. López-Rosado, and J. P. Dewald,\\n“Neural constraints affect the ability to generate hip abduction torques\\nwhen combined with hip extension or ankle plantarflexion in chronic\\nhemiparetic stroke,” Frontiers in Neurology, vol. 9, 7 2018.\\n[45] S. M. Woolley, “Characteristics of gait in hemiplegia,” Topics in Stroke\\nRehabilitation, vol. 7, pp. 1–18, 1 2001.\\nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2025.3568325\\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250510174542', 'source': 'stroke.pdf', 'total_pages': 12, 'page': 11, 'page_label': '12'}, page_content=\"12 IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING, VOL. XX, NO. XX, XXXX 2025\\n[46] G. Yavuzer, F. Eser, D. Karakus, B. Karaoglan, and H. J. Stam, “The\\neffects of balance training on gait late after stroke: A randomized\\ncontrolled trial,” Clinical Rehabilitation, vol. 20, pp. 960–969, 2006.\\n[47] Y . Sekiguchi, K. Honda, and S.-I. Izumi, “Effect of walking adaptability\\non an uneven surface by a stepping pattern on walking activity after\\nstroke,” Frontiers in Human Neuroscience , vol. 15, p. 762223, 2022.\\n[48] J. J. Zhang, K. N. Fong, N. Welage, and K. P. Liu, “The activation of\\nthe mirror neuron system during action observation and action execution\\nwith mirror visual feedback in stroke: a systematic review,” Neural\\nplasticity, vol. 2018, no. 1, p. 2321045, 2018.\\n[49] B. Balaban and F. Tok, “Gait disturbances in patients with stroke,”\\nPm&r, vol. 6, no. 7, pp. 635–642, 2014.\\n[50] B. Raja, R. R. Neptune, and S. A. Kautz, “Coordination of\\nthe non-paretic leg during hemiparetic gait: expected and novel\\ncompensatory patterns,” Clinical biomechanics , vol. 27, no. 10,\\npp. 1023–1030, 2012.\\n[51] S. Graziadio, L. Tomasevic, G. Assenza, F. Tecchio, and J. Eyre, “The\\nmyth of the ‘unaffected’side after unilateral stroke: Is reorganisation of\\nthe non-infarcted corticospinal system to re-establish balance the price\\nfor recovery?,” Experimental neurology, vol. 238, no. 2, pp. 168–175,\\n2012.\\n[52] M. Nyan, F. Tay, K. Seah, and Y . Sitoh, “Classification of gait patterns in\\nthe time–frequency domain,” Journal of biomechanics , vol. 39, no. 14,\\npp. 2647–2656, 2006.\\n[53] E. Sejdi ´c, K. A. Lowry, J. Bellanca, M. S. Redfern, and J. S. Brach,\\n“A comprehensive assessment of gait accelerometry signals in time,\\nfrequency and time-frequency domains,” IEEE Transactions on Neural\\nSystems and Rehabilitation Engineering , vol. 22, no. 3, pp. 603–612,\\n2013.\\n[54] C. Lea, M. D. Flynn, R. Vidal, A. Reiter, and G. D. Hager, “Temporal\\nconvolutional networks for action segmentation and detection,” in\\nproceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pp. 156–165, 2017.\\n[55] T. C. Pataky, M. A. Robinson, J. Vanrenterghem, and C. J.\\nDonnelly, “Simultaneously assessing amplitude and temporal effects\\nin biomechanical trajectories using nonlinear registration and statistical\\nnonparametric mapping,” Journal of Biomechanics, vol. 136, p. 111049,\\n2022.\\n[56] P. Shull, W. Jirattigalachote, M. Hunt, M. Cutkosky, and S. Delp,\\n“Quantified self and human movement: the clinical impact of wearable\\nsensing and feedback for gait analysis and intervention,” Gait and\\nPosture, vol. 40, pp. 11–19, 2014.\\n[57] S. Uhlrich, A. Falisse, L. Kidzi ´nski, J. Muccini, M. Ko, A. Chaudhari,\\nJ. Hicks, and S. Delp, “Opencap: Human movement dynamics from\\nsmartphone videos,” PLoS Computational Biology , vol. 19, 10 2023.\\n[58] S. Tyson, E. Sadeghi-Demneh, and C. Nester, “A systematic review and\\nmeta-analysis of the effect of an ankle-foot orthosis on gait biomechanics\\nafter stroke,” Clinical Rehabilitation, vol. 27, pp. 879–891, 10 2013.\\nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2025.3568325\\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\")]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PyPDFLoader(\"stroke.pdf\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c48a7",
   "metadata": {},
   "source": [
    "## web based reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6ca646",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(web_path=\"https://www.scrapethissite.com/pages/simple/\",)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f39d33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ecedf4",
   "metadata": {},
   "source": [
    "## arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c2e0c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "loader = ArxivLoader(query=\"1706.03762\").load()\n",
    "# 1706.03762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9ce094e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023\\n1\\nIntroduction\\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [35, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2\\nBackground\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [12]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3\\nModel Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[10], consuming the previously generated symbols as additional input when generating the next.\\n2\\nFigure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1\\nEncoder and Decoder Stacks\\nEncoder:\\nThe encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder:\\nThe decoder is also composed of a stack of N = 6 identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2\\nAttention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3\\nScaled Dot-Product Attention\\nMulti-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1\\nScaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V ) = softmax(QKT\\n√dk\\n)V\\n(1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof\\n1\\n√dk . Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by\\n1\\n√dk .\\n3.2.2\\nMulti-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\\ni=1 qiki, has mean 0 and variance dk.\\n4\\noutput values. These are concatenated and once again projected, resulting in the final values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\nMultiHead(Q, K, V ) = Concat(head1, ..., headh)W O\\nwhere headi = Attention(QW Q\\ni , KW K\\ni , V W V\\ni )\\nWhere the projections are parameter matrices W Q\\ni\\n∈Rdmodel×dk, W K\\ni\\n∈Rdmodel×dk, W V\\ni\\n∈Rdmodel×dv\\nand W O ∈Rhdv×dmodel.\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3\\nApplications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3\\nPosition-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0, xW1 + b1)W2 + b2\\n(2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4\\nEmbeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [30]. In the embedding layers, we multiply those weights by √dmodel.\\n5\\nTable 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\\nLayer Type\\nComplexity per Layer\\nSequential\\nMaximum Path Length\\nOperations\\nSelf-Attention\\nO(n2 · d)\\nO(1)\\nO(1)\\nRecurrent\\nO(n · d2)\\nO(n)\\nO(n)\\nConvolutional\\nO(k · n · d2)\\nO(1)\\nO(logk(n))\\nSelf-Attention (restricted)\\nO(r · n · d)\\nO(1)\\nO(n/r)\\n3.5\\nPositional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and fixed [9].\\nIn this work, we use sine and cosine functions of different frequencies:\\nPE(pos,2i) = sin(pos/100002i/dmodel)\\nPE(pos,2i+1) = cos(pos/100002i/dmodel)\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any fixed offset k, PEpos+k can be represented as a linear function of\\nPEpos.\\nWe also experimented with using learned positional embeddings [9] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4\\nWhy Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\n6\\nlength n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[38] and byte-pair [31] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\\nthe input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < n does not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [18], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexity\\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5\\nTraining\\nThis section describes the training regime for our models.\\n5.1\\nTraining Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2\\nHardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3\\nOptimizer\\nWe used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate = d−0.5\\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5)\\n(3)\\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps = 4000.\\n5.4\\nRegularization\\nWe employ three types of regularization during training:\\n7\\nTable 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU\\nTraining Cost (FLOPs)\\nEN-DE\\nEN-FR\\nEN-DE\\nEN-FR\\nByteNet [18]\\n23.75\\nDeep-Att + PosUnk [39]\\n39.2\\n1.0 · 1020\\nGNMT + RL [38]\\n24.6\\n39.92\\n2.3 · 1019\\n1.4 · 1020\\nConvS2S [9]\\n25.16\\n40.46\\n9.6 · 1018\\n1.5 · 1020\\nMoE [32]\\n26.03\\n40.56\\n2.0 · 1019\\n1.2 · 1020\\nDeep-Att + PosUnk Ensemble [39]\\n40.4\\n8.0 · 1020\\nGNMT + RL Ensemble [38]\\n26.30\\n41.16\\n1.8 · 1020\\n1.1 · 1021\\nConvS2S Ensemble [9]\\n26.36\\n41.29\\n7.7 · 1019\\n1.2 · 1021\\nTransformer (base model)\\n27.3\\n38.1\\n3.3 · 1018\\nTransformer (big)\\n28.4\\n41.8\\n2.3 · 1019\\nResidual Dropout\\nWe apply dropout [33] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\nLabel Smoothing\\nDuring training, we employed label smoothing of value ϵls = 0.1 [36]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6\\nResults\\n6.1\\nMachine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [38].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of floating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision floating-point capacity of each GPU 5.\\n6.2\\nModel Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8\\nTable 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN\\ndmodel\\ndff\\nh\\ndk\\ndv\\nPdrop\\nϵls\\ntrain\\nPPL\\nBLEU\\nparams\\nsteps\\n(dev)\\n(dev)\\n×106\\nbase\\n6\\n512\\n2048\\n8\\n64\\n64\\n0.1\\n0.1\\n100K\\n4.92\\n25.8\\n65\\n(A)\\n1\\n512\\n512\\n5.29\\n24.9\\n4\\n128\\n128\\n5.00\\n25.5\\n16\\n32\\n32\\n4.91\\n25.8\\n32\\n16\\n16\\n5.01\\n25.4\\n(B)\\n16\\n5.16\\n25.1\\n58\\n32\\n5.01\\n25.4\\n60\\n(C)\\n2\\n6.11\\n23.7\\n36\\n4\\n5.19\\n25.3\\n50\\n8\\n4.88\\n25.5\\n80\\n256\\n32\\n32\\n5.75\\n24.5\\n28\\n1024\\n128\\n128\\n4.66\\n26.0\\n168\\n1024\\n5.12\\n25.4\\n53\\n4096\\n4.75\\n26.2\\n90\\n(D)\\n0.0\\n5.77\\n24.6\\n0.2\\n4.95\\n25.5\\n0.0\\n4.67\\n25.3\\n0.2\\n5.47\\n25.7\\n(E)\\npositional embedding instead of sinusoids\\n4.92\\n25.7\\nbig\\n6\\n1024\\n4096\\n16\\n0.3\\n300K\\n4.33\\n26.4\\n213\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical\\nresults to the base model.\\n6.3\\nEnglish Constituency Parsing\\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\\nmodels have not been able to attain state-of-the-art results in small-data regimes [37].\\nWe trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the\\nPenn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\\nfor the semi-supervised setting.\\nWe performed only a small number of experiments to select the dropout, both attention and residual\\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\\nremained unchanged from the English-to-German base translation model. During inference, we\\n9\\nTable 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ)\\nParser\\nTraining\\nWSJ 23 F1\\nVinyals & Kaiser el al. (2014) [37]\\nWSJ only, discriminative\\n88.3\\nPetrov et al. (2006) [29]\\nWSJ only, discriminative\\n90.4\\nZhu et al. (2013) [40]\\nWSJ only, discriminative\\n90.4\\nDyer et al. (2016) [8]\\nWSJ only, discriminative\\n91.7\\nTransformer (4 layers)\\nWSJ only, discriminative\\n91.3\\nZhu et al. (2013) [40]\\nsemi-supervised\\n91.3\\nHuang & Harper (2009) [14]\\nsemi-supervised\\n91.3\\nMcClosky et al. (2006) [26]\\nsemi-supervised\\n92.1\\nVinyals & Kaiser el al. (2014) [37]\\nsemi-supervised\\n92.1\\nTransformer (4 layers)\\nsemi-supervised\\n92.7\\nLuong et al. (2015) [23]\\nmulti-task\\n93.0\\nDyer et al. (2016) [8]\\ngenerative\\n93.3\\nincreased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\\nfor both WSJ only and the semi-supervised setting.\\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\\nprisingly well, yielding better results than all previously reported models with the exception of the\\nRecurrent Neural Network Grammar [8].\\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\\nParser [29] even when training only on the WSJ training set of 40K sentences.\\n7\\nConclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements\\nWe are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\nReferences\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n10\\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\\nnetwork grammars. In Proc. of NAACL, 2016.\\n[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[10] Alex Graves.\\nGenerating sequences with recurrent neural networks.\\narXiv preprint\\narXiv:1308.0850, 2013.\\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in\\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\\n[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735–1780, 1997.\\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 832–841. ACL, August 2009.\\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[23] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n11\\n[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\\ncorpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference,\\npages 152–159. ACL, June 2006.\\n[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July\\n2006.\\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.\\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\\nAdvances in Neural Information Processing Systems, 2015.\\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\\n1: Long Papers), pages 434–443. ACL, August 2013.\\n12\\nAttention Visualizations\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\\n13\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15\\n')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc555f",
   "metadata": {},
   "source": [
    "## recursively split text by char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1703285b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CharacterTextSplitter', 'ElementType', 'ExperimentalMarkdownSyntaxTextSplitter', 'HTMLHeaderTextSplitter', 'HTMLSectionSplitter', 'HTMLSemanticPreservingSplitter', 'HeaderType', 'JSFrameworkTextSplitter', 'KonlpyTextSplitter', 'Language', 'LatexTextSplitter', 'LineType', 'MarkdownHeaderTextSplitter', 'MarkdownTextSplitter', 'NLTKTextSplitter', 'PythonCodeTextSplitter', 'RecursiveCharacterTextSplitter', 'RecursiveJsonSplitter', 'SentenceTransformersTokenTextSplitter', 'SpacyTextSplitter', 'TextSplitter', 'TokenTextSplitter', 'Tokenizer', 'split_text_on_tokens']\n"
     ]
    }
   ],
   "source": [
    "import langchain_text_splitters\n",
    "print(langchain_text_splitters.__all__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6cc40f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cb8da3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "904f71d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('id', None)\n",
      "('metadata', {'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'})\n",
      "('page_content', 'Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu')\n",
      "('type', 'Document')\n"
     ]
    }
   ],
   "source": [
    "for i  in docs[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6ed8ce28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('id', None)\n",
      "('metadata', {'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'})\n",
      "('page_content', 'University of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,')\n",
      "('type', 'Document')\n"
     ]
    }
   ],
   "source": [
    "for i  in docs[1]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbecfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e3c83c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"speech.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    speech_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1752942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=30)\n",
    "docs = text_splitter.create_documents([speech_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fa07731d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 599, which is longer than the specified 100\n",
      "Created a chunk of size 617, which is longer than the specified 100\n",
      "Created a chunk of size 744, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "with open(\"speech.txt\") as f:\n",
    "    speech_text = f.read()  \n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=30)\n",
    "docs = text_splitter.create_documents([speech_text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2be47b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content=\"Speech is the use of the human voice as a medium for language. Spoken language combines vowel and consonant sounds to form units of meaning like words, which belong to a language's lexicon. There are many different intentional speech acts, such as informing, declaring, asking, persuading, directing; acts may vary in various aspects like enunciation, intonation, loudness, and tempo to convey meaning. Individuals may also unintentionally communicate aspects of their social position through speech, such as sex, age, place of origin, physiological and mental condition, education, and experiences.\"),\n",
       " Document(metadata={}, page_content=\"While normally used to facilitate communication with others, people may also use speech without the intent to communicate. Speech may nevertheless express emotions or desires; people talk to themselves sometimes in acts that are a development of what some psychologists (e.g., Lev Vygotsky) have maintained is the use of silent speech in an interior monologue to vivify and organize cognition, sometimes in the momentary adoption of a dual persona as self addressing self as though addressing another person. Solo speech can be used to memorize or to test one's memorization of things, and in prayer or in meditation.\"),\n",
       " Document(metadata={}, page_content=\"Researchers study many different aspects of speech: speech production and speech perception of the sounds used in a language, speech repetition, speech errors, the ability to map heard spoken words onto the vocalizations needed to recreate them, which plays a key role in children's enlargement of their vocabulary, and what different areas of the human brain, such as Broca's area and Wernicke's area, underlie speech. Speech is the subject of study for linguistics, cognitive science, communication studies, psychology, computer science, speech pathology, otolaryngology, and acoustics. Speech compares with written language,[1] which may differ in its vocabulary, syntax, and phonetics from the spoken language, a situation called diglossia.\"),\n",
       " Document(metadata={}, page_content=\"The evolutionary origin of speech is subject to debate and speculation. While animals also communicate using vocalizations, and trained apes such as Washoe and Kanzi can use simple sign language, no animals' vocalizations are articulated phonemically and syntactically, and do not constitute speech.\")]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "da0d1907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'document_loaders', 'utilities', 'utils']\n"
     ]
    }
   ],
   "source": [
    "import langchain_community\n",
    "print(dir(langchain_community))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "638c7dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - adapters\n",
      " - agent_toolkits\n",
      " - agents\n",
      " - cache\n",
      " - callbacks\n",
      " - chains\n",
      " - chat_loaders\n",
      " - chat_message_histories\n",
      " - chat_models\n",
      " - cross_encoders\n",
      " - docstore\n",
      " - document_compressors\n",
      " - document_loaders\n",
      " - document_transformers\n",
      " - embeddings\n",
      " - example_selectors\n",
      " - graph_vectorstores\n",
      " - graphs\n",
      " - indexes\n",
      " - llms\n",
      " - memory\n",
      " - output_parsers\n",
      " - query_constructors\n",
      " - retrievers\n",
      " - storage\n",
      " - tools\n",
      " - utilities\n",
      " - utils\n",
      " - vectorstores\n"
     ]
    }
   ],
   "source": [
    "import pkgutil\n",
    "for module in pkgutil.iter_modules(langchain_community.__path__):\n",
    "    print(\" -\", module.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "805daf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_asyncio Module\n",
      "_bz2 Module\n",
      "_ctypes Module\n",
      "_ctypes_test Module\n",
      "_decimal Module\n",
      "_elementtree Module\n",
      "_hashlib Module\n",
      "_lzma Module\n",
      "_msi Module\n",
      "_multiprocessing Module\n",
      "_overlapped Module\n",
      "_queue Module\n",
      "_socket Module\n",
      "_sqlite3 Module\n",
      "_ssl Module\n",
      "_testbuffer Module\n",
      "_testcapi Module\n",
      "_testconsole Module\n",
      "_testimportmultiple Module\n",
      "_testinternalcapi Module\n",
      "_testmultiphase Module\n",
      "_tkinter Module\n",
      "_uuid Module\n",
      "_zoneinfo Module\n",
      "pyexpat Module\n",
      "select Module\n",
      "unicodedata Module\n",
      "winsound Module\n",
      "__future__ Module\n",
      "_aix_support Module\n",
      "_bootsubprocess Module\n",
      "_collections_abc Module\n",
      "_compat_pickle Module\n",
      "_compression Module\n",
      "_markupbase Module\n",
      "_osx_support Module\n",
      "_py_abc Module\n",
      "_pydecimal Module\n",
      "_pyio Module\n",
      "_sitebuiltins Module\n",
      "_strptime Module\n",
      "_threading_local Module\n",
      "_weakrefset Module\n",
      "abc Module\n",
      "aifc Module\n",
      "antigravity Module\n",
      "argparse Module\n",
      "ast Module\n",
      "asynchat Module\n",
      "asyncio Package\n",
      "asyncore Module\n",
      "base64 Module\n",
      "bdb Module\n",
      "binhex Module\n",
      "bisect Module\n",
      "bz2 Module\n",
      "cProfile Module\n",
      "calendar Module\n",
      "cgi Module\n",
      "cgitb Module\n",
      "chunk Module\n",
      "cmd Module\n",
      "code Module\n",
      "codecs Module\n",
      "codeop Module\n",
      "collections Package\n",
      "colorsys Module\n",
      "compileall Module\n",
      "concurrent Package\n",
      "configparser Module\n",
      "contextlib Module\n",
      "contextvars Module\n",
      "copy Module\n",
      "copyreg Module\n",
      "crypt Module\n",
      "csv Module\n",
      "ctypes Package\n",
      "curses Package\n",
      "dataclasses Module\n",
      "datetime Module\n",
      "dbm Package\n",
      "decimal Module\n",
      "difflib Module\n",
      "dis Module\n",
      "distutils Package\n",
      "doctest Module\n",
      "email Package\n",
      "encodings Package\n",
      "ensurepip Package\n",
      "enum Module\n",
      "filecmp Module\n",
      "fileinput Module\n",
      "fnmatch Module\n",
      "fractions Module\n",
      "ftplib Module\n",
      "functools Module\n",
      "genericpath Module\n",
      "getopt Module\n",
      "getpass Module\n",
      "gettext Module\n",
      "glob Module\n",
      "graphlib Module\n",
      "gzip Module\n",
      "hashlib Module\n",
      "heapq Module\n",
      "hmac Module\n",
      "html Package\n",
      "http Package\n",
      "idlelib Package\n",
      "imaplib Module\n",
      "imghdr Module\n",
      "imp Module\n",
      "importlib Package\n",
      "inspect Module\n",
      "io Module\n",
      "ipaddress Module\n",
      "json Package\n",
      "keyword Module\n",
      "lib2to3 Package\n",
      "linecache Module\n",
      "locale Module\n",
      "logging Package\n",
      "lzma Module\n",
      "mailbox Module\n",
      "mailcap Module\n",
      "mimetypes Module\n",
      "modulefinder Module\n",
      "msilib Package\n",
      "multiprocessing Package\n",
      "netrc Module\n",
      "nntplib Module\n",
      "ntpath Module\n",
      "nturl2path Module\n",
      "numbers Module\n",
      "opcode Module\n",
      "operator Module\n",
      "optparse Module\n",
      "os Module\n",
      "pathlib Module\n",
      "pdb Module\n",
      "pickle Module\n",
      "pickletools Module\n",
      "pipes Module\n",
      "pkgutil Module\n",
      "platform Module\n",
      "plistlib Module\n",
      "poplib Module\n",
      "posixpath Module\n",
      "pprint Module\n",
      "profile Module\n",
      "pstats Module\n",
      "pty Module\n",
      "py_compile Module\n",
      "pyclbr Module\n",
      "pydoc Module\n",
      "pydoc_data Package\n",
      "queue Module\n",
      "quopri Module\n",
      "random Module\n",
      "re Module\n",
      "reprlib Module\n",
      "rlcompleter Module\n",
      "runpy Module\n",
      "sched Module\n",
      "secrets Module\n",
      "selectors Module\n",
      "shelve Module\n",
      "shlex Module\n",
      "shutil Module\n",
      "signal Module\n",
      "site Module\n",
      "smtpd Module\n",
      "smtplib Module\n",
      "sndhdr Module\n",
      "socket Module\n",
      "socketserver Module\n",
      "sqlite3 Package\n",
      "sre_compile Module\n",
      "sre_constants Module\n",
      "sre_parse Module\n",
      "ssl Module\n",
      "stat Module\n",
      "statistics Module\n",
      "string Module\n",
      "stringprep Module\n",
      "struct Module\n",
      "subprocess Module\n",
      "sunau Module\n",
      "symtable Module\n",
      "sysconfig Module\n",
      "tabnanny Module\n",
      "tarfile Module\n",
      "telnetlib Module\n",
      "tempfile Module\n",
      "test Package\n",
      "textwrap Module\n",
      "this Module\n",
      "threading Module\n",
      "timeit Module\n",
      "tkinter Package\n",
      "token Module\n",
      "tokenize Module\n",
      "trace Module\n",
      "traceback Module\n",
      "tracemalloc Module\n",
      "tty Module\n",
      "turtle Module\n",
      "turtledemo Package\n",
      "types Module\n",
      "typing Module\n",
      "unittest Package\n",
      "urllib Package\n",
      "uu Module\n",
      "uuid Module\n",
      "venv Package\n",
      "warnings Module\n",
      "wave Module\n",
      "weakref Module\n",
      "webbrowser Module\n",
      "wsgiref Package\n",
      "xdrlib Module\n",
      "xml Package\n",
      "xmlrpc Package\n",
      "zipapp Module\n",
      "zipfile Module\n",
      "zipimport Module\n",
      "zoneinfo Package\n",
      "IPython Package\n",
      "_distutils_hack Package\n",
      "_yaml Package\n",
      "adodbapi Package\n",
      "aiohappyeyeballs Package\n",
      "aiohttp Package\n",
      "aiosignal Package\n",
      "annotated_types Package\n",
      "anyio Package\n",
      "arxiv Package\n",
      "asttokens Package\n",
      "async_timeout Package\n",
      "attr Package\n",
      "attrs Package\n",
      "bs4 Package\n",
      "certifi Package\n",
      "charset_normalizer Package\n",
      "colorama Package\n",
      "comm Package\n",
      "dataclasses_json Package\n",
      "dateutil Package\n",
      "debugpy Package\n",
      "decorator Module\n",
      "dotenv Package\n",
      "exceptiongroup Package\n",
      "executing Package\n",
      "feedparser Package\n",
      "fitz Package\n",
      "frozenlist Package\n",
      "greenlet Package\n",
      "h11 Package\n",
      "httpcore Package\n",
      "httpx Package\n",
      "httpx_sse Package\n",
      "idna Package\n",
      "ipykernel Package\n",
      "ipykernel_launcher Module\n",
      "isapi Package\n",
      "jedi Package\n",
      "jsonpatch Module\n",
      "jsonpointer Module\n",
      "jupyter Module\n",
      "jupyter_client Package\n",
      "jupyter_core Package\n",
      "langchain Package\n",
      "langchain_community Package\n",
      "langchain_core Package\n",
      "langchain_text_splitters Package\n",
      "langsmith Package\n",
      "marshmallow Package\n",
      "matplotlib_inline Package\n",
      "multidict Package\n",
      "mypy_extensions Module\n",
      "nest_asyncio Module\n",
      "numpy Package\n",
      "orjson Package\n",
      "packaging Package\n",
      "parso Package\n",
      "pip Package\n",
      "pkg_resources Package\n",
      "platformdirs Package\n",
      "prompt_toolkit Package\n",
      "propcache Package\n",
      "psutil Package\n",
      "pure_eval Package\n",
      "pydantic Package\n",
      "pydantic_core Package\n",
      "pydantic_settings Package\n",
      "pygments Package\n",
      "pymupdf Package\n",
      "pypdf Package\n",
      "pythoncom Module\n",
      "requests Package\n",
      "requests_toolbelt Package\n",
      "setuptools Package\n",
      "sgmllib Module\n",
      "six Module\n",
      "sniffio Package\n",
      "soupsieve Package\n",
      "sqlalchemy Package\n",
      "stack_data Package\n",
      "tenacity Package\n",
      "tornado Package\n",
      "traitlets Package\n",
      "typing_extensions Module\n",
      "typing_inspect Module\n",
      "typing_inspection Package\n",
      "urllib3 Package\n",
      "wcwidth Package\n",
      "win32com Package\n",
      "yaml Package\n",
      "yarl Package\n",
      "zmq Package\n",
      "zstandard Package\n",
      "_win32sysloader Module\n",
      "_winxptheme Module\n",
      "mmapfile Module\n",
      "odbc Module\n",
      "perfmon Module\n",
      "servicemanager Module\n",
      "timer Module\n",
      "win32api Module\n",
      "win32clipboard Module\n",
      "win32console Module\n",
      "win32cred Module\n",
      "win32crypt Module\n",
      "win32event Module\n",
      "win32evtlog Module\n",
      "win32file Module\n",
      "win32gui Module\n",
      "win32help Module\n",
      "win32inet Module\n",
      "win32job Module\n",
      "win32lz Module\n",
      "win32net Module\n",
      "win32pdh Module\n",
      "win32pipe Module\n",
      "win32print Module\n",
      "win32process Module\n",
      "win32profile Module\n",
      "win32ras Module\n",
      "win32security Module\n",
      "win32service Module\n",
      "win32trace Module\n",
      "win32transaction Module\n",
      "win32ts Module\n",
      "win32wnet Module\n",
      "winxpgui Module\n",
      "_win32verstamp_pywin32ctypes Module\n",
      "afxres Module\n",
      "commctrl Module\n",
      "mmsystem Module\n",
      "netbios Module\n",
      "ntsecuritycon Module\n",
      "pywin32_bootstrap Module\n",
      "pywin32_testutil Module\n",
      "pywintypes Module\n",
      "rasutil Module\n",
      "regcheck Module\n",
      "regutil Module\n",
      "sspi Module\n",
      "sspicon Module\n",
      "win2kras Module\n",
      "win32con Module\n",
      "win32cryptcon Module\n",
      "win32evtlogutil Module\n",
      "win32gui_struct Module\n",
      "win32inetcon Module\n",
      "win32netcon Module\n",
      "win32pdhquery Module\n",
      "win32pdhutil Module\n",
      "win32rcparser Module\n",
      "win32serviceutil Module\n",
      "win32timezone Module\n",
      "win32traceutil Module\n",
      "win32verstamp Module\n",
      "winerror Module\n",
      "winioctlcon Module\n",
      "winnt Module\n",
      "winperf Module\n",
      "winxptheme Module\n",
      "dde Module\n",
      "pywin Package\n",
      "start_pythonwin Module\n",
      "win32ui Module\n",
      "win32uiole Module\n"
     ]
    }
   ],
   "source": [
    "for importer, modname, ispkg in pkgutil.iter_modules():\n",
    "    print(modname, \"Package\" if ispkg else \"Module\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bf7462",
   "metadata": {},
   "source": [
    "## html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1676493e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Heading 1': 'This is Heading 1'}, page_content='This is Heading 1'),\n",
       " Document(metadata={'Heading 1': 'This is Heading 1', 'Heading 2': 'This is Heading 2'}, page_content='This is Heading 2'),\n",
       " Document(metadata={'Heading 1': 'This is Heading 1', 'Heading 2': 'This is Heading 2', 'Heading 3': 'This is Heading 3'}, page_content='This is Heading 3'),\n",
       " Document(metadata={'Heading 1': 'This is Heading 1', 'Heading 2': 'This is Heading 2', 'Heading 3': 'This is Heading 3'}, page_content='This is a paragraph inside a div.  \\nHere is another line. This text comes after a line break.')]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "\n",
    "html_code = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "  <meta charset=\"UTF-8\">\n",
    "  <title>Simple HTML Test</title>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>This is Heading 1</h1>\n",
    "  <h2>This is Heading 2</h2>\n",
    "  <h3>This is Heading 3</h3>\n",
    "\n",
    "  <div>\n",
    "    <p>This is a paragraph inside a div.</p>\n",
    "    <p>Here is another line.<br>This text comes after a line break.</p>\n",
    "  </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "header_to_split_on = [\n",
    "    (\"h1\", \"Heading 1\"),\n",
    "    (\"h2\", \"Heading 2\"),\n",
    "    (\"h3\", \"Heading 3\"),\n",
    "   \n",
    "]\n",
    "\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=header_to_split_on)\n",
    "html_docs = html_splitter.split_text(html_code)\n",
    "html_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7514592f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='End container NOTE: Script required for drop-down button to work (mirrors).  \\nEnd header wrapper End content End footer  \\nEnd header  \\nEnd navigation End search  \\nStanford Encyclopedia of Philosophy  \\nMenu  \\nBrowse  \\nTable of Contents  \\nWhat\\'s New  \\nRandom Entry  \\nChronological  \\nArchives  \\nAbout  \\nEditorial Information  \\nAbout the SEP  \\nEditorial Board  \\nHow to Cite the SEP  \\nSpecial Characters  \\nAdvanced Tools  \\nContact  \\nSupport SEP  \\nSupport the SEP  \\nPDFs for SEP Friends  \\nMake a Donation  \\nSEPIA for Libraries  \\nBegin article sidebar End article sidebar NOTE: Article content must have two wrapper divs: id=\"article\" and id=\"article-content\" End article NOTE: article banner is outside of the id=\"article\" div. End article-banner  \\nEntry Navigation  \\nEntry Contents  \\nBibliography  \\nAcademic Tools  \\nFriends PDF Preview  \\nAuthor and Citation Info  \\nBack to Top  \\nEnd article-content  \\nBEGIN ARTICLE HTML #aueditable DO NOT MODIFY THIS LINE AND BELOW END ARTICLE HTML  \\nDO NOT MODIFY THIS LINE AND ABOVE'),\n",
       " Document(metadata={'Heading 1': 'Kurt Gödel'}, page_content='Kurt Gödel'),\n",
       " Document(metadata={'Heading 1': 'Kurt Gödel'}, page_content='First published Tue Feb 13, 2007; substantive revision Fri Dec 11, 2015  \\nKurt Friedrich Gödel (b. 1906, d. 1978) was one of the principal\\nfounders of the modern, metamathematical era in mathematical logic. He\\nis widely known for his Incompleteness Theorems, which are among the\\nhandful of landmark theorems in twentieth century mathematics, but his\\nwork touched every field of mathematical logic, if it was not in most\\ncases their original stimulus. In his philosophical work Gödel\\nformulated and defended mathematical Platonism, the view that\\nmathematics is a descriptive science, or alternatively the view that\\nthe concept of mathematical truth is objective. On the basis of that\\nviewpoint he laid the foundation for the program of conceptual\\nanalysis within set theory (see below). He adhered to Hilbert’s\\n“original rationalistic conception” in mathematics (as he\\ncalled\\n it); and he was prophetic in anticipating and emphasizing the importance\\nof large cardinals in set theory before their importance became\\nclear.  \\n[ ]  \\n1  \\nEntry Contents Entry Contents  \\n1. Biographical Sketch  \\n2. Gödel’s Mathematical Work  \\n2.1 The Completeness Theorem  \\n2.1.1 Introduction  \\n2.1.2 Proof of the Completeness Theorem  \\n2.1.3 An Important Consequence of the Completeness Theorem  \\n2.2 The Incompleteness Theorems  \\n2.2.1 The First Incompleteness Theorem  \\n2.2.2 The proof of the First Incompleteness Theorem  \\n2.2.3 The Second Incompleteness Theorem  \\nSupplementary Document: Did the Incompleteness Theorems Refute Hilbert’s Program?  \\n2.3 Speed-up Theorems  \\n2.4 Gödel’s Work in Set theory  \\n2.4.1 The consistency of the Continuum Hypothesis and the Axiom of Choice  \\n2.4.2 Gödel’s Proof of the Consistency of the Continuum Hypothesis and the Axiom of Choice with the Axioms of Zermelo-Fraenkel Set Theory  \\n2.4.3 Consequences of Consistency  \\n2.4.4 Gödel’s view of the Axiom of Constructibility  \\n2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic  \\n2.5.1 Intuitionistic Propositional Logic is not Finitely-Valued  \\n2.5.2 Classical Arithmetic is Interpretable in Heyting Arithmetic  \\n2.5.3 Intuitionistic Propositional Logic is Interpretable in  \\nS4  \\n2.5.4 Heyting Arithmetic is Interpretable into Computable Functionals of Finite Type.  \\nSupplement Document: Gödel’s Documents  \\n3. Gödel’s Philosophical Views  \\n3.1 Gödel’s Rationalism  \\n3.2 Gödel’s Realism  \\nSupplementary Document: Gödel’s Turn to Phenomenology  \\nSupplementary Document: A Philosophical Argument About the Content of Mathematics  \\nBibliography  \\nPrimary Sources  \\nGödel’s Writings  \\nThe Collected Papers of Kurt Gödel  \\nSelected Works of Kurt Gödel  \\nSecondary Sources  \\nAcademic Tools  \\nOther Internet Resources  \\nRelated Entries  \\n1. Biographical Sketch  \\nKurt Gödel was born on April 28, 1906 in what was then the\\nAustro-Hungarian city of Brünn, and what is now Brno in the Czech\\nRepublic.  \\nGödel’s father Rudolf August was a businessman, and his\\nmother Marianne was a well-educated and cultured woman to whom\\nGödel remained close throughout his life, as witnessed by the\\nlong and wide-ranging correspondence between them. The family was well\\noff, and Gödel’s childhood was an uneventful one, with one\\nimportant exception; namely, from about the age of four Gödel\\nsuffered frequent episodes of poor health, and the health problems he\\nsuffered then as well as others of various kinds were to plague him\\nhis entire life.  \\nHealth problems notwithstanding, Gödel proved to be an exemplary\\nstudent at primary school and later the Gymnasium, excelling\\nespecially in mathematics, languages and religion. Upon his graduation\\nfrom the Gymnasium in Brno in 1924 Gödel enrolled in the\\nUniversity of Vienna, attending lectures on physics, his initial field\\nof interest, lectures on philosophy given by Heinrich Gomperz, and\\nlectures on mathematics. Gödel took a number of physics courses\\nduring his undergraduate years, as witnessed by his university\\ntranscript; this is notable in view of Gödel’s subsequent\\ncontributions to relativity in 1947. Philipp Furtwängler, cousin\\nof the great German conductor Wilhelm Furtwängler, was one of his\\nmathematics professors, and indeed Furtwängler’s course on\\nclass field theory almost tempted Gödel to pursue his studies in\\nthat area. Gödel learned his logic from Rudolph Carnap and from\\nHans Hahn, eventually graduating under Hahn with a Dr.phil. in\\nmathematics in 1929. The main theorem of his dissertation was the\\ncompleteness theorem for first order logic (Gödel\\n 1929).  \\n[ ]  \\n2  \\nGödel’s university years also marked the beginning of his\\nattendance at meetings of the Vienna Circle, a group around Moritz\\nSchlick that quickly became known as “logical\\npositivists,” a term coined by Feigl and Blumberg in their 1931\\n“Logical positivism: A new movement in European\\nphilosophy” (Feigl and Blumberg 1931). Though Gödel was not\\nhimself a logical positivist, those discussions were a crucial\\nformative influence.  \\nThe 1930s were a prodigious decade for Gödel. After publishing\\nhis 1929 dissertation in 1930, he published his groundbreaking\\nincompleteness theorems in 1931, on the basis of which he was granted\\nhis Habilitation in 1932 and a Privatdozentur at the University of\\nVienna in 1933.  \\nAmong his mathematical achievements at the decade’s close is the\\nproof of the consistency of both the Axiom of Choice and\\nCantor’s Continuum Hypothesis with the Zermelo-Fraenkel axioms\\nfor set theory, obtained in 1935 and 1937, respectively. Gödel\\nalso published a number of significant papers on modal and\\nintuitionistic logic and arithmetic during this period, principal\\namong which is his “On intuitionistic arithmetic and number\\ntheory,” (Gödel 1933e), in which he showed that classical\\nfirst order arithmetic is interpretable in Heyting arithmetic by a\\nsimple translation. Other publications of the 1930s include those on\\nthe decision problem for the predicate calculus, on the length of\\nproofs, and on differential and projective geometry.  \\nBy the end of the decade both Gödel’s advisor Hans Hahn and\\nMoritz Schlick had died (the latter was assassinated by an\\nex-student), two events which led to a personal crisis for Gödel.\\nAlso, his appointment at the University, that of Privatdozentur, was\\ncancelled, being replaced by the position “Dozentur neuer\\nOrdnung,” granted to candidates only after they had passed a\\nracial\\n test. Gödel’s three trips the United States during that decade\\ntriggered an investigation. (See Sigmund 2006.) Finally, Gödel\\nwas found fit for military service by the Nazi government in 1939.  \\n[ ]  \\n3  \\nAll of these events were decisive in influencing his decision to leave\\nAustria in 1940, when he and his wife Adele emigrated to the United\\nStates. This long and difficult episode in their life is recounted by\\nJohn Dawson in his biography of Gödel called “Logical\\nDilemmas,” (Dawson 1997) as well as by Solomon Feferman in\\n“Gödel’s Life and Work,” (Feferman 1986) to\\nboth of which the reader is referred.  \\nUpon arrival Gödel took up an appointment as an ordinary member\\nat the Institute for Advanced Study; he would become a permanent\\nmember of the Institute in 1946 and would be granted his professorship\\nin 1953. (Gödel and his wife were granted American citizenship in\\nApril 1948.) He would remain at the Institute until his retirement in\\n1976. The Gödels never returned to Europe.  \\nGödel’s early years at the Institute were notable for his\\nclose friendship with his daily walking partner Albert Einstein, as\\nwell as for his turn to philosophy of mathematics, a field on which\\nGödel began to concentrate almost exclusively from about 1943.\\nThe initial period of his subsequent lifelong involvement with\\nphilosophy was a fruitful one (in terms of publications): in 1944 he\\npublished his first philosophical paper, entitled “On\\nRussell’s Mathematical Logic” (Gödel 1944), and in\\n1947 he published his second, entitled “What is Cantor’s\\nContinuum Hypothesis?” (Gödel 1947). In 1949 he published\\nhis third, entitled “A Remark on the Relationship between\\nRelativity Theory and Idealistic Philosophy.” (Gödel\\n1949a). The latter paper coincided with results on rotating universes\\nin relativity he had obtained in 1949, which were first published in\\nan article entitled: “An Example of a New Type of Cosmological\\nSolutions of Einstein’s Field Equations of Gravitation.”\\n(Gödel 1949).  \\nAmong Gödel’s other significant philosophical works of the\\n1940s must be counted his 1941 lecture entitled “In What Sense\\nis Intuitionistic Logic Constructive?” (Gödel *1941) in\\nwhich the notion: “computable function of finite type” is\\nintroduced. A paper based on the ideas in the lecture entitled\\n“Über eine bisher noch nicht benützte Erweiterung des\\nfiniten Standpunktes,” was published only in 1958, and the\\ninterpretation of Heyting arithmetic into the quantifier free calculus in it became known as the “Dialectica\\nInterpretation,” after the journal in which the article was\\npublished (Gödel 1958). (For the revision of it from 1972, see\\nGödel 1995.) Finally the decade saw the beginning of\\nGödel’s intensive study of Leibniz, which, Gödel\\nreports, occupied the period from 1943 to\\n 1946.  \\nT  \\n[ ]  \\n4  \\nThe 1950s saw a deepening of Gödel’s involvement with\\nphilosophy: In 1951 Gödel delivered a philosophical lecture at\\nBrown University, usually referred to as the Gibbs Lecture, entitled\\n“Some Basic Theorems on the Foundations of Mathematics and Their\\nPhilosophical Implications” (Gödel *1951). From 1953 to\\n1959 Gödel worked on a submission to the Schilpp volume on Rudolf\\nCarnap entitled “Is Mathematics a Syntax of Language?”\\n(Gödel *1953/9-III, Gödel *1953/9-V). Gödel published\\nneither of these two important manuscripts in his lifetime, although\\nboth would appear on two lists which were found in the Gödel\\nNachlass, entitled “Was ich publizieren könnte.” (In\\nEnglish: “What I could publish.” Both manuscripts\\neventually appeared in Gödel 1995.) By the decade’s close\\nGödel developed a serious interest in\\n phenomenology.  \\n[ ]  \\n5  \\nGödel’s final years are notable for his circulation of two\\nmanuscripts: “Some considerations leading to the probable\\nconclusion that the true power of the continuum is\\nℵ ,” (Gödel *1970a, *1970b) his attempt\\nto derive the value of the continuum from the so-called scale axioms\\nof Hausdorff, and his “Ontologischer Beweis,” (Gödel\\n*1970) which he entrusted to Dana Scott in 1970 (though it appears to\\nhave been written earlier). Taken together, the two manuscripts are\\nthe fitting last words of someone who, in a fifty year involvement\\nwith mathematics and philosophy, pursued, or more precisely, for pursuing those two subjects under the\\nsingle heading: “strenge Wissenschaft”—a turn of\\nmind that had been in place from Gödel’s start in 1929,\\nwhen at the age of twenty-three he opened his doctoral thesis with\\nsome philosophical remarks.  \\n2  \\nsought the grounds  \\nGödel died in Princeton on January 14, 1978 at the age of 71. His\\ndeath certificate records the cause of death as “starvation and\\ninanition, due to personality disorder.” His wife Adele survived\\nhim by three years.  \\nFor further biographical material, see Gödel 1987, Kleene 1987,\\nKreisel 1980, Taussky-Todd 1987 and Yourgrau 2005.  \\n2. Gödel’s Mathematical Work  \\nBelow is an examination of some of Gödel’s main\\ncontributions in logic and set theory. This treatment of\\nGödel’s technical work is not exhaustive, omitting\\ndiscussion of Gödel’s work in physics and his work on the\\ndecision problem. These will be treated in the sequel to this\\nentry.  \\nFor a complete chronology of Gödel’s work the reader is\\nreferred to that compiled by John Dawson in volume I of\\nGödel’s Collected Works (Gödel 1986, p. 37).  \\n2.1 The Completeness Theorem  \\n2.1.1 Introduction  \\nThe completeness question for the first order predicate calculus was\\nstated precisely and in print for the first time in 1928 by Hilbert\\nand Ackermann in their text (Hilbert and Ackermann 1928), a text with which Gödel\\nwould have been quite\\n familiar.  \\nGrundzüge der theoretischen\\nLogik  \\n[ ]  \\n6  \\nThe question Hilbert and Ackermann pose is whether a certain\\nexplicitly given axiom system for the first order predicate calculus\\n“…is complete in the sense that from it all logical\\nformulas that are correct for each domain of individuals can be\\nderived…” (van Heijenoort 1967, p. 48).  \\n2.1.2 Proof of the Completeness Theorem  \\nWe give an outline of Gödel’s own proof in his doctoral\\nthesis (Gödel 1929). An essential difference with earlier efforts\\n(discussed below and elsewhere, e.g. in Zach 1999), is that Gödel\\ndefines meticulously all the relevant basic concepts.  \\nA “logical expression” in Gödel’s terminology\\nis a well-formed first order formula without identity. An expression\\nis “refutable” if its negation is provable,\\n“valid” if it is true in every interpretation and\\n“satisfiable” if it is true in some interpretation. The\\nCompleteness Theorem is stated as follows:  \\n. Every valid logical expression is provable. Equivalently, every\\nlogical expression is either satisfiable or refutable.  \\nTheorem 1  \\nGödel’s proof calculus is that of Hilbert and\\nAckermann’s text. An expression is in normal form if all the\\nquantifiers occur at the beginning. The degree of an expression or\\nformula is the number of alternating blocks of quantifiers at the\\nbeginning of the formula, assumed to begin with universal quantifiers.\\nGödel shows that if the completeness theorem holds for formulas\\nof degree it must hold for formulas of degree +\\n1. Thus the question of completeness reduces to formulas of degree 1.\\nThat is, it is to be shown that any normal formula ( )φ\\nof degree 1 is either satisfiable or refutable, where\\n“( )” stands for a (non-empty) block of universal\\nquantifiers followed by a (possibly empty) block of existential\\nones.  \\nk  \\nk  \\nQ  \\nQ  \\nGödel defines a book-keeping device, a well-ordering of all\\ntuples of variables arising from a need to satisfy φ as dictated\\nby ( ). For example, if ( )φ is\\n∀ ∃ ψ( , ), we list the quantifier-free formulas\\nψ( , ). (Or more precisely, finite\\nconjunctions of these in increasing length. See below.) Then in any\\ndomain consisting of the values of the different , in which each\\nψ( , ) is\\ntrue, the sentence ( )φ is clearly true. A crucial lemma\\nclaims the provability, for each , of the formula\\n( )φ →\\n( )φ , where the\\nquantifier free formula φ asserts the truth\\nof ψ for all tuples up to the kth tuple of variables arising from\\n( ), and\\n( )φ is the\\nexistential closure of φ . (See the example\\nbelow where the definition of the φ s\\nis given.) This lemma is the main step missing from the various\\nearlier attempts at the proof due to Löwenheim and Skolem, and,\\nin the context of the completeness theorem for first order logic,\\nrenders the connection between syntax and semantics completely\\nexplicit.  \\nQ  \\nQ  \\nx  \\n0  \\nx  \\n1  \\nx  \\n0  \\nx  \\n1  \\nx  \\nn  \\nx  \\n+1  \\nn  \\nx  \\nn  \\nx  \\nn  \\nx  \\nn+1  \\nQ  \\nk  \\nQ  \\nQ  \\nk  \\nk  \\nk  \\nQ  \\nQ  \\nk  \\nk  \\nk  \\n′  \\nk  \\nLet us consider an example of how a particular formula would be found\\nto be either satisfiable or its negation provable, following\\nGödel’s method: Consider φ =\\n∀ ∃ ψ( , ), where ψ( , ) is quantifier-free. We show that this is\\neither refutable or satisfiable. We make the following\\ndefinitions:  \\nx  \\n0  \\nx  \\n1  \\nx  \\n0  \\nx  \\n1  \\nx  \\n0  \\nx  \\n1  \\nφ is the expression\\nψ( , )  \\n0  \\nx  \\n0  \\nx  \\n1  \\nφ is the expression\\nψ( , ) ∧\\nψ( , )  \\n1  \\nx  \\n0  \\nx  \\n1  \\nx  \\n1  \\nx  \\n2  \\n…  \\nφ is the expression\\nψ( , ) ∧\\n…∧ ψ( , ).  \\nn  \\nx  \\n0  \\nx  \\n1  \\nx  \\nn  \\nx  \\n+1  \\nn  \\nThe crucial lemma, referred to above, shows that from φ we can\\nderive for each ,\\n∃ …∃ φ .  \\nn  \\nx  \\n0  \\nx  \\n+1  \\nn  \\nn  \\nFor some ,\\nφ is not satisfiable. Then, Gödel\\nargued, using the already known completeness theorem for propositional\\n logic, that ¬φ is provable, and hence so is\\n∀ ,…, ¬φ . Thus\\n¬∃ …∃ φ is provable and therefore the ¬φ is provable, i.e., φ is\\nrefutable in the Hilbert-Ackermann system. (Some partial results about\\npropositional logic in addition to those already mentioned include the\\nsemantic completeness of the propositional calculus due to Post\\n(1921), as well as a more general completeness theorem for the same\\ndue to Bernays in 1918; the latter appears in Bernays’\\nunpublished of 1918; see also Bernays\\n1926.)  \\nCase 1:  \\nn  \\nn  \\n[ ]  \\n7  \\nn  \\nx  \\n0  \\nx  \\n+1  \\nn  \\nn  \\nx  \\n0  \\nx  \\n+1  \\nn  \\nn  \\nHabilitationsschrift  \\nEach φ is\\nsatisfiable. There are only finitely many possible models with\\nuniverse { ,…, }.\\nGödel orders them as a tree by defining a model to be\\nbelow a model ′ if is a submodel of ′. In this way we obtain a tree which is finitely\\nbranching but infinite. By König’s Lemma there is an\\ninfinite branch . (In the proof, Gödel explicitly\\nconstructs the branch given by König’s Lemma rather than\\nciting it by name.) The union of the models on forms a\\nmodel with universe { , ,…}. Since satisfies each\\nφ , the original formula φ holds in . So φ is satisfiable and we are done.  \\nCase 2:  \\nn  \\nx  \\n0  \\nx  \\nn+1  \\nM  \\nM  \\nM  \\nM  \\nB  \\nB  \\nM  \\nx  \\n0  \\nx  \\n1  \\nM  \\nn  \\nM  \\nNote that the model, in the satisfiability case of Gödel’s\\nproof, is always countable. Thus this proof of the Completeness\\nTheorem gives also the Löweheim-Skolem Theorem (see below).\\nGödel extends the result to countably many formulas and to the\\ncase of first order logic with identity. He also proves the\\nindependence of the axioms.  \\nIn 1930 Gödel published the paper based on his thesis (Gödel\\n1930) notable also for the inclusion of the compactness theorem, which\\nis only implicitly stated in the thesis. The theorem as stated by\\nGödel in Gödel 1930 is as follows: a countably infinite set\\nof quantificational formulas is satisfiable if and only if every\\nfinite subset of those formulas is satisfiable. Gödel uses\\ncompactness to derive a generalization of the completeness\\ntheorem.  \\nThe Compactness Theorem was extended to the case of uncountable\\nvocabularies by Maltsev in 1936 (see Mal’cev 1971), from which\\nthe Upward Löwenheim-Skolem theorem immediately follows. The\\nCompactness Theorem would become one of the main tools in the then\\nfledgling subject of model theory.  \\n2.1.3 An Important Consequence of the Completeness Theorem  \\nA theory is said to be categorical if it has only one model up to\\nisomorphism; it is λ-categorical if it has only one model of\\ncardinality λ, up to isomorphism. One of the main consequences\\nof the completeness theorem is that categoricity fails for Peano\\narithmetic and for Zermelo-Fraenkel set theory.  \\nIn detail, regarding the first order Peano axioms (henceforth ), the existence of non-standard models of them actually\\nfollows from completeness together with compactness. One constructs\\nthese models, which contain infinitely large integers, as follows: add\\na new constant symbol to the language of arithmetic. Extend to a new theory * by adding to it the infinite\\ncollection of axioms: { > , > , …}, where, e.g., is S(S(S(0))). *\\nis finitely consistent (i.e., every finite subset of * is\\nconsistent) hence consistent, hence by the Completeness Theorem it has\\na model.  \\nPA  \\nc  \\nPA  \\nPA  \\nc  \\n0  \\nc  \\n1  \\n3  \\nPA  \\nPA  \\nThis simple fact about models of Peano arithmetic was not pointed out\\nby Gödel in any of the publications connected with the\\nCompleteness Theorem from that time, and it seems not to have been\\nnoticed by the general logic community until much later.\\nSkolem’s definable ultrapower construction from 1933 (see Skolem\\n1933) gives a direct construction of a non-standard model of True\\nArithmetic (which extends Peano arithmetic, being the set of\\narithmetic sentences true in the natural numbers). But Skolem never\\nmentions the fact that the existence of such models follows from the\\ncompleteness and compactness theorems. Gödel in his review\\n(1934c) of Skolem’s paper also does not mention this fact,\\nrather observing that the failure of categoricity for arithmetic\\nfollows from the theorem.  \\nincompleteness  \\nAs for set theory, the failure of categoricity was already taken note\\nof by Skolem in 1923, because it follows from the\\nLöwenheim-Skolem Theorem (which Skolem arrived at that year; see\\nSkolem 1923, based on Löwenheim 1915 and Skolem 1920): any first\\norder theory in a countable language that has a model has a countable\\nmodel.  \\nSkolem’s observation that categoricity fails for set theory\\nbecause it has countable models is now known as the Skolem\\n paradox. The\\n observation is strongly emphasized in Skolem’s paper, which is\\naccordingly entitled ‘An Observation on the Axiomatic\\nFoundations of Set Theory’ As he wrote in the conclusion of it,\\nhe had not pointed out the relativity in set theory already in 1915\\nbecause:  \\n[ ]  \\n8  \\n… first, I have in the meantime been occupied with other\\nproblems; second, I believed that it was so clear that axiomatization\\nin terms of sets was not a satisfactory ultimate foundation of\\nmathematics that mathematicians would, for the most part, not be very\\nmuch concerned with it. But in recent times I have seen to my surprise\\nthat so many mathematicians think that these axioms of set theory\\nprovide the ideal foundation for mathematics; therefore it seemed to\\nme that the time had come to publish a critique. (English translation\\ntaken from van Heijenoort 1967, p. 300.)  \\nAs an aside, in the proof of the Löwenheim-Skolem theorem,\\nspecifically that part of the theorem in which one constructs a model\\nfor a satisfiable sentence, Löwenheim and Skolem’s tree\\nconstruction was more or less the same as appears in\\nGödel’s thesis. In a 1967 letter to Hao Wang, Gödel\\ntakes note of the fact that his completeness proof had almost been\\nobtained by Skolem in 1923. Though van Heijenoort and Dreben (Dreben\\nand van Heijenoort 1986) remark that “Throughout much of the\\n1920s it was not semantic completeness but the decision problem for\\nquantificational validity, a problem originating from the work of\\nSchröder and Löwenheim, that was the dominant concern in\\nstudying quantification theory” (examples of such results would\\ninclude the decision procedure for the first order monadic predicate\\ncalculus due to Behmann, (Behmann 1922)), according to Gödel, the\\nreasons that Skolem did not obtain the complete proof are different\\nand philosophically important, having to do with the then dominant\\nbias against semantics and against infinitary methods:  \\nThe Completeness Theorem, mathematically, is indeed an almost trivial\\nconsequence of Skolem 1923. However, the fact is that, at that time,\\nnobody (including Skolem himself) drew this conclusion neither from\\nSkolem 1923 nor, as I did, from similar considerations of his own\\n…This blindness (or prejudice, or whatever you may call it) of\\nlogicians is indeed surprising. But I think the explanation is not\\nhard to find. It lies in the widespread lack, at that time, of the\\nrequired epistemological attitude toward metamathematics and toward\\nnon-finitary reasoning. (Gödel 2003b).  \\nThe matter of Skolem’s contribution to the Completeness Theorem\\nhas been extensively discussed in van Atten and Kennedy 2009, as well\\nas in van Atten 2005.  \\n2.2 The Incompleteness Theorems  \\nGödel mentioned the possibility of the unsolvability of a\\nquestion about the reals already in his 1929 thesis, in arguing\\nagainst the formalist principle of Hilbert’s, that consistency\\nis a criterion for existence. In fact, giving a finitary proof of the\\nconsistency of analysis was a key desideratum of what was then known\\nas the Hilbert program, along with proving its completeness.\\nAccordingly it was Gödel’s turn to these questions,\\nespecially the first, which led him to the two incompleteness\\ntheorems. (For a discussion of the Hilbert Program the reader is\\nreferred to the standard references: Sieg 1990, 1988, 1999; Mancosu\\n1998, Zach 2003, Tait 1981 and Tait 2002.)  \\nThe First Incompleteness Theorem provides a counterexample to\\ncompleteness by exhibiting an arithmetic statement which is neither\\nprovable nor refutable in Peano arithmetic, though true in the\\nstandard model. The Second Incompleteness Theorem shows that the\\nconsistency of arithmetic cannot be proved in arithmetic itself. Thus\\nGödel’s theorems demonstrated the infeasibility of the\\nHilbert program, if it is to be characterized by those particular\\ndesiderata, consistency and completeness.  \\nAs an aside, von Neumann understood the two theorems this way, even\\nbefore Gödel did. In fact von Neumann went much further in taking\\nthe view that they showed the infeasibility of classical mathematics\\naltogether. As he wrote to Carnap in June of 1931:  \\nThus today I am of the opinion that 1. Gödel has shown the\\nunrealizability of Hilbert’s program. 2. There is no more reason\\nto reject intuitionism (if one disregards the aesthetic issue, which\\nin practice will also for me be the decisive factor). Therefore I\\nconsider the state of the foundational discussion in Königsberg\\nto be outdated, for Gödel’s fundamental discoveries have\\nbrought the question to a completely different\\n level.  \\n[ ]  \\n9  \\nAnd the previous fall von Neumann had written to Gödel in even\\nstronger terms:  \\nThus, I think that your result has solved negatively the foundational\\nquestion: there is no rigorous justification for classical\\nmathematics. (Gödel 2003b, p. 339)  \\nIt would take Gödel himself a few years to see that those aspects\\nof the Hilbert Program had been decisively refuted by his results\\n(Mancosu 2004).  \\n2.2.1 The First Incompleteness Theorem  \\nIn his (Wang 1996) Hao Wang published the\\nfull text of material Gödel had written (at Wang’s request)\\nabout his discovery of the incompleteness theorems. This material had\\nformed the basis of Wang’s “Some Facts about Kurt\\nGödel,” and was read and approved by Gödel:  \\nLogical Journey  \\nIn the summer of 1930 I began to study the consistency problem of\\nclassical analysis. It is mysterious why Hilbert wanted to prove\\ndirectly the consistency of analysis by finitary methods. I saw two\\ndistinguishable problems: to prove the consistency of number theory by\\nfinitary number theory and to prove the consistency of analysis by\\nnumber theory … Since the domain of finitary number theory was\\nnot well-defined, I began by tackling the second half… I\\nrepresented real numbers by predicates in number theory… and\\nfound that I had to use the concept of truth (for number theory) to\\nverify the axioms of analysis. By an enumeration of symbols, sentences\\nand proofs within the given system, I quickly discovered that the\\nconcept of arithmetic truth cannot be defined in arithmetic. If it\\nwere possible to define truth in the system itself, we would have\\nsomething like the liar paradox, showing the system to be\\ninconsistent… Note that this argument can be formalized to show\\nthe existence of undecidable propositions without giving any\\nindividual instances. (If there were no undecidable propositions, all\\n(and only) true propositions would be provable within the system. But\\nthen we would have a contradiction.)… In contrast to truth,\\nprovability in a given formal system is an explicit combinatorial\\nproperty of certain sentences of the system, which is formally\\nspecifiable by suitable elementary means…  \\nWe see that Gödel first tried to reduce the consistency problem\\nfor analysis to that of arithmetic. This seemed to require a truth\\ndefinition for arithmetic, which in turn led to paradoxes, such as the\\nLiar paradox (“This sentence is false”) and Berry’s\\nparadox (“The least number not defined by an expression\\nconsisting of just fourteen English words”). Gödel then\\nnoticed that such paradoxes would not necessarily arise if truth were\\nreplaced by provability. But this means that arithmetic truth and\\narithmetic provability are not co-extensive — whence the First\\nIncompleteness Theorem.  \\nThis account of Gödel’s discovery was told to Hao Wang very\\nmuch after the fact; but in Gödel’s contemporary\\ncorrespondence with Bernays and Zermelo, essentially the same\\ndescription of his path to the theorems is given. (See Gödel\\n2003a and Gödel 2003b respectively.) From those accounts we see\\nthat the undefinability of truth in arithmetic, a result credited to\\nTarski, was likely obtained in some form by Gödel by 1931. But he\\nneither publicized nor published the result; the biases logicians had\\nexpressed at the time concerning the notion of truth, biases which\\ncame vehemently to the fore when Tarski announced his results on the\\nundefinability of truth in formal systems 1935, may have served as a\\ndeterrent to Gödel’s publication of that theorem.  \\n2.2.2 The proof of the First Incompleteness Theorem  \\nWe now describe the proof of the two theorems, formulating\\nGödel’s results in Peano arithmetic. Gödel himself\\nused a system related to that defined in Principia Mathematica, but\\ncontaining Peano arithmetic. In our presentation of the First and\\nSecond Incompleteness Theorems we refer to Peano arithmetic as , following Gödel’s notation.  \\nP  \\nBefore proceeding to the details of the formal proof, we define the\\nnotion of ω-consistency used by Gödel in the First\\nIncompleteness Theorem: is if ⊢ ¬φ( ) for all implies ⊬ ∃ φ( ).\\nNaturally this implies consistency and follows from the assumption\\nthat the natural numbers satisfy the axioms of Peano arithmetic.  \\nP  \\nω-consistent  \\nP  \\nn  \\nn  \\nP  \\nx  \\nx  \\nOne of the main technical tools used in the proof is , a mechanism which assigns natural numbers to terms and\\nformulas of our formal theory . There are different ways of\\ndoing this. The most common is based on the unique representation of\\nnatural numbers as products of powers of primes. Each symbol of number theory is assigned a positive natural number\\n#( ) in a fixed but arbitrary way, e.g.  \\nGödel\\nnumbering  \\nP  \\ns  \\ns  \\n#(0) = 1  \\n#(=) = 5  \\n#(¬) = 9  \\n#(1) = 2  \\n#(\\u2009(\\u2009) = 6  \\n#(∀) = 10  \\n#(+) = 3  \\n#(\\u2009)\\u2009) = 7  \\n#( ) = 11 +  \\nv  \\ni  \\ni  \\n#(×) = 4  \\n#(∧) = 8  \\nThe natural number corresponding to a sequence = < ,…, >\\nof symbols is  \\nw  \\nw  \\n0  \\nw  \\nk  \\n=\\n2 ·\\n3 · … · ,  \\n⌈  \\nw  \\n⌉  \\n#( )  \\nw  \\n0  \\n#( )  \\nw  \\n1  \\np  \\nk  \\n#( )  \\nw  \\nk  \\nwhere is the +1st prime. It\\nis called its Gödel number and denoted by . In this way we can\\nassign Gödel numbers to formulas, sequences of formulas (once a\\nmethod for distinguishing when one formula ends and another begins has\\nbeen adopted), and most notably, proofs.  \\np  \\nk  \\nk  \\n⌈  \\nw  \\n⌉  \\nAn essential point here is that when a formula is construed as a\\nnatural number, then the numeral corresponding to that natural number\\ncan occur as the argument of a formula, thus enabling the syntax to\\n“refer” to itself, so to speak (i.e., when a numeral is\\nsubstituted into a formula the Gödel number of which the numeral\\nrepresents). This will eventually allow Gödel to formalize the\\nLiar paradox (with “provability” in place of\\n“truth”) by substituting into the formula which says,\\n‘the formula, whose code is , is unprovable,’\\nits own natural number code (or more precisely the corresponding\\nnumeral).  \\nx  \\nAnother concept required to carry out the formalization is the concept\\nof numeralwise expressibility of number theoretic predicates. A\\nnumber-theoretic formula φ( , …, ) is in if for each tuple of natural numbers\\n( , …, ):  \\nn  \\n1  \\nn  \\nk  \\nnumeralwise expressible  \\nP  \\nn  \\n1  \\nn  \\nk  \\n⊨\\nφ( , …, )  \\nN  \\nn  \\n1  \\nn  \\nk  \\n⇒  \\n⊢\\nφ( , …, )  \\nP  \\nn  \\n1  \\nn  \\nk  \\n⊨\\n¬φ( , …, )  \\nN  \\nn  \\n1  \\nn  \\nk  \\n⇒  \\n⊢\\n¬φ( , …, )  \\nP  \\nn  \\n1  \\nn  \\nk  \\nwhere is the formal term which denotes the natural\\nnumber . (In , this is ( (… (0)…), where is the number of iterations of the successor function applied to the\\nconstant symbol 0.) One of the principal goals is to numeralwise\\nexpress the predicate  \\nn  \\nn  \\nP  \\nS  \\nS  \\nS  \\nn  \\nPrf( , ): ‘the sequence with Gödel\\nnumber is a proof of the sentence with Gödel number .’  \\nx  \\ny  \\nx  \\ny  \\nReaching this goal involves defining forty-five relations, each\\ndefined in terms of the preceding ones. These relations are all\\nprimitive\\n recursive. Relations needed are, among others, those which assert of a natural\\nnumber that it codes a sequence, or a formula, or an axiom, or that it\\nis the code, denoted by\\nSb( ),\\nof a formula obtained from a formula with code by\\nsubstituting for its free variable the th numeral for = 1,\\n…, . The forty-fifth primitive recursive relation\\ndefined is Prf( , ), and the forty-sixth is  \\n[ ]  \\n10  \\nr  \\n…  \\nu  \\n1  \\nu  \\nn  \\n( )… ( )  \\nZ  \\nx  \\n1  \\nZ  \\nx  \\nn  \\nr  \\nu  \\ni  \\nx  \\ni  \\ni  \\nn  \\nx  \\ny  \\nProv( ): ‘the sentence with Gödel number is provable in ’  \\ny  \\ny  \\nP  \\nwhich without being primitive recursive, is however obtained from\\nPrf( , ) by existentially quantifying .\\n(Prov( ) satisfies only the ‘positive’ part of\\nnumeralwise expressibility, and not the negative part; but the\\nnegative part is not needed.)  \\nx  \\ny  \\nx  \\ny  \\nIn Theorem V of his paper, Gödel proves that any number theoretic\\npredicate which is primitive recursive is numeralwise expressible in . Thus since Prf( , ) and substitution\\nare primitive recursive, these are decided by when closed\\nterms are substituted for the free variables and . This is the heart of the matter as we will see. Another\\nkey point about numeralwise expressibility is that although we\\ninformally interpret, for example,\\nProv(Sb( )),\\nby: ‘the formula with Gödel number is provable\\nif the Gödel number for the th numeral is\\nsubstituted in place of the th variable,’ neither the\\nformal statement within the theory nor anything we prove\\nabout it appeals to such meanings. On the contrary\\nProv(Sb( )),\\nis a meaningless string of logical and arithmetical symbols. As\\nGödel puts it in his introduction to his theorem V, ‘The\\nfact that can be formulated vaguely by saying that every recursive\\nrelation is definable in the system (if the usual meaning\\nis given to the formulas of this system) is expressed in precise\\nlanguage, reference to any interpretation of the\\nformulas of , by the following Theorem (V) (Gödel 1986,\\np. 171, italics Gödel’s).  \\nP  \\nx  \\ny  \\nP  \\nx  \\ny  \\nr  \\n…  \\nu  \\n1  \\nu  \\nn  \\n( )… ( )  \\nZ  \\nx  \\n1  \\nZ  \\nx  \\nn  \\nr  \\nx  \\ni  \\ni  \\nP  \\nr  \\n…  \\nu  \\n1  \\nu  \\nn  \\n( )… ( )  \\nZ  \\nx  \\n1  \\nZ  \\nx  \\nn  \\nP  \\nwithout  \\nP  \\nGödel in his incompleteness theorems uses a method given in what\\nis called nowadays Gödel’s Fixed Point Theorem. Although\\nGödel constructs a fixed point in the course of proving the\\nincompleteness theorem, he does not state the fixed point theorem\\nexplicitly. The fixed point theorem is as follows:  \\n(Gödel’s Fixed Point Theorem) If φ( ) is a formula of number theory, then\\nthere is a sentence ψ such that ⊢ ψ ↔\\nφ( ), where is the formal term\\ncorresponding to the natural number code of ψ .  \\nTheorem 2  \\nv  \\n0  \\nP  \\n⌈  \\nψ  \\n⌉  \\n⌈  \\nψ  \\n⌉  \\n⌈  \\n⌉  \\nLet σ( , , ) be a\\nformula that numeralwise expresses the number theoretic predicate\\n‘ is the Gödel number of the formula obtained by\\nreplacing the variable in the formula whose\\nGödel number is by the term ’.\\nLet θ( ) be the formula\\n∃ (φ( ) ∧\\nσ( , , )). Let = θ( ) and ψ = θ( ). Now directly by the construction ⊢ ψ ↔\\nφ( ψ ).  \\nProof:  \\nx  \\ny  \\nz  \\ny  \\nv  \\n0  \\nx  \\nz  \\nv  \\n0  \\nv  \\n1  \\nv  \\n1  \\nv  \\n0  \\nv  \\n1  \\nv  \\n0  \\nk  \\n⌈  \\nv  \\n0  \\n⌉  \\nk  \\nP  \\n⌈  \\n⌉  \\nA sentence is refutable from a theory if its negation is provable. The\\nFirst Incompleteness Theorem as Gödel stated it is as\\nfollows:  \\n(Gödel’s First Incompleteness\\nTheorem) If is ω-consistent, then there is a sentence which is\\nneither provable nor refutable from .  \\nTheorem 3  \\nP  \\nP  \\nBy judicious coding of syntax referred to above, write\\na formula\\n Prf( , ) of number theory, representable in , so that  \\nProof:  \\nx  \\ny  \\n[ ]  \\n11  \\nP  \\ncodes a proof of φ ⇒ ⊢\\nPrf( , ).  \\nn  \\nP  \\nn  \\n⌈  \\nφ  \\n⌉  \\nand  \\ndoes not code a proof of φ ⇒ ⊢ ¬Prf( , ).  \\nn  \\nP  \\nn  \\n⌈  \\nφ  \\n⌉  \\nLet Prov( ) denote the formula ∃ Prf( , ) .\\n By Theorem 2 there is a sentence φ with the property  \\ny  \\nx  \\nx  \\ny  \\n[ ]  \\n12  \\n⊢ (φ ↔\\n¬Prov( )).  \\nP  \\n⌈  \\nφ  \\n⌉  \\nThus φ says ‘I am not provable.’ We now observe, if ⊢ φ, then by (1) there is such that ⊢ Prf( , ), hence ⊢ Prov( ), hence,\\nby (3) ⊢ ¬φ, so is inconsistent.\\nThus  \\nP  \\nn  \\nP  \\nn  \\n⌈  \\nφ  \\n⌉  \\nP  \\n⌈  \\nφ  \\n⌉  \\nP  \\nP  \\n⊬ φ  \\nP  \\nFurthermore, by (4) and (2), we have ⊢\\n¬Prf( , ) for all natural\\nnumbers . By ω-consistency ⊬\\n∃ Prf( , ). Thus (3) gives ⊬ ¬φ. We have shown that if is\\nω-consistent, then φ is independent of .  \\nP  \\nn  \\n⌈  \\nφ  \\n⌉  \\nn  \\nP  \\nx  \\nx  \\n⌈  \\nφ  \\n⌉  \\nP  \\nP  \\nP  \\nOn concluding the proof of the first theorem, Gödel remarks,\\n“we can readily see that the proof just given is constructive;\\nthat is … proved in an intuitionistically unobjectionable\\nmanner…” (Gödel 1986, p. 177). This is because, as\\nhe points out, all the existential statements are based on his theorem\\nV (giving the numeralwise expressibility of primitive recursive\\nrelations), which is intuitionistically unobjectionable.  \\n2.2.3 The Second Incompleteness Theorem  \\nThe Second Incompleteness Theorem establishes the unprovability, in\\nnumber theory, of the consistency of number theory. First we have to\\nwrite down a number-theoretic formula that expresses the consistency\\nof the axioms. This is surprisingly simple. We just let\\nCon( ) be the sentence ¬Prov( ).  \\nP  \\n⌈  \\n0 =\\n1  \\n⌉  \\n(Gödel’s Second Incompleteness\\nTheorem) If is consistent, then Con( ) is not\\nprovable from .  \\nTheorem 4  \\nP  \\nP  \\nP  \\nLet φ be as in (3). The reasoning used to infer\\n‘if ⊢ φ, then ⊢ 0 ≠\\n1‘ does not go beyond elementary number theory, and can\\ntherefore, albeit with a lot of effort (see below), be formalized in . This yields: ⊢\\n(Prov( ) →\\n¬Con( )), and thus by (3), ⊢\\n(Con( ) → φ). Since ⊬ φ, we\\nmust have ⊬ Con( ).  \\nProof:  \\nP  \\nP  \\nP  \\nP  \\n⌈  \\nφ  \\n⌉  \\nP  \\nP  \\nP  \\nP  \\nP  \\nP  \\nThe above proof (sketch) of the Second Incompleteness Theorem is\\ndeceptively simple as it avoids the formalization. A rigorous proof\\nwould have to establish the proof of ‘if ⊢\\nφ, then ⊢ 0 ≠ 1’ in .  \\nP  \\nP  \\nP  \\nIt is noteworthy that ω-consistency is not needed in the proof\\nof Gödel’s Second Incompleteness Theorem. Also note that\\nneither is ¬Con( ) provable, by the consistency of and the fact, now known as Löb’s theorem, that ⊢\\nProv( ) implies ⊢ φ.  \\nP  \\nP  \\nP  \\n⌈  \\nφ  \\n⌉  \\nP  \\nThe assumption of ω-consistency in the First Incompleteness\\nTheorem was eliminated by Rosser in 1936, and replaced by the weaker\\nnotion of consistency. Rosser’s generalization involves applying\\nthe fixed point theorem to the formula ( ):\\n‘for all : either is not the Gödel\\nnumber of a proof of the formula with Gödel number or\\nthere is a proof shorter than of the negation of (the\\nformula with Gödel number) ’ (see Rosser\\n1936).  \\nR  \\nx  \\nz  \\nz  \\nx  \\nz  \\nx  \\nWith regard to the Second Incompleteness Theorem, the argument relies\\nin part on formalizing the proof of the First Incompleteness Theorem\\nas we saw. This step is omitted in Gödel 1931. He planned to\\ninclude the step in what would have been a second part II (see\\nfootnote 48a of Gödel 1931). But instead of writing it he turned\\nto the continuum\\n problem. (Part II was to elaborate on other points too: the ‘true reason\\nfor incompleteness,’ and the applicability of the two theorems\\nto other systems.) He perhaps did not feel compelled to attend to what\\nlooked like an exercise in formalization, relying instead on the\\ninformal argument to convince (in which it succeeded). However this\\nstep turned out to be somewhat non-trivial. As Kleene puts it in his\\nintroduction to Gödel 1931, of the informal presentation,\\n“Certainly the idea of the argument for Theorem XI (consistency)\\nwas very convincing; but it turned out that the execution of the\\ndetails required somewhat more work and care than had been\\nanticipated.” (See pp. 126–141 of Gödel 1986.)\\nEventually a complete proof of the Second Theorem was given by Hilbert\\nand Bernays in some seventy pages in their Hilbert and Bernays 1939. A\\nmuch more compact treatment of the theorem was given by Löb in\\nhis Löb 1956, and subsequently Feferman, in his 1960\\n“Arithmetization of Metamathematics in a General Setting”\\n(Feferman 1960/1961), gave a succinct and completely general treatment\\nof both the First and Second Theorems. But see the supplementary\\ndocument:  \\n[ ]  \\n13  \\nDid the Incompleteness Theorems Refute Hilbert’s Program?  \\nFor more detailed discussion, see the entry on .  \\nGödel’s incompleteness theorems  \\n2.3 Speed-up Theorems  \\nGödel’s 1936 ‘Speed-up’ theorem, published in\\nan abstract “On the length of proofs”, Gödel 1936\\nsays that while some sentences of arithmetic are true but unprovable,\\nthere are other sentences which are provable, but even the shortest\\nproof is longer than any bound given in advance as a recursive\\nfunction of the sentence. More exactly:  \\n. Given any recursive function there are provable sentences\\nφ of arithmetic such that the shortest proof is greater than ( φ ) in length.  \\nTheorem 5  \\nf  \\nf  \\n⌈  \\n⌉  \\nThe proof we will outline is sensitive to the particular concept we\\nuse for the length of a proof. Another possibility, and the one that\\nGödel has in mind, is the number of formulas in the proof. Buss\\n(see below) proves the theorem in either case, so both cases are\\nresolved.  \\nLet be total recursive function. By\\nGödel’s Fixed Point theorem there is a formula\\nφ( ) stating ‘φ( ) has no proof in PA\\nshorter than ( )’. This is tenable if the\\nlength is measured by number of symbols, because we only need to\\nsearch through finitely many proofs shorter than ( ). Note that φ( ) is true for all , for if φ( ) were false, then there would be a\\nshort proof of φ( ), and hence by soundness\\nφ( ) would be true, a contradiction: φ( )\\nwould both true and false. This can be formalized in PA and thus we\\nget the result that for each the sentence φ( )\\nis provable in PA. Since φ( ) is true for all ,\\nit cannot have a proof in PA which is shorter than ( ).  \\nProof:  \\nf  \\nn  \\nn  \\nf  \\nn  \\nf  \\nn  \\nn  \\nn  \\nn  \\nn  \\nn  \\nn  \\nn  \\nn  \\nn  \\nn  \\nf  \\nn  \\nThe Speed-up Theorem is the result of contemplating and elaborating\\nthe proof of the incompleteness theorem. It applies the fixed-point\\ntechnique to the concept of unprovability by a short proof, as opposed\\nto the original idea of applying the fixed-point theorem to mere\\nunprovability. The proof has very much the same flavor as the proof of\\nthe incompleteness theorem. Interestingly, it dates from the same year\\nas the construction, due to Rosser, that eliminates the use of\\nω-consistency in the first Incompleteness Theorem; like the\\nSpeed-up Theorem of Gödel, Rosser’s construction exploits\\nthe issue of short and long proofs. Gödel never submitted a proof\\nfor the Speed-up Theorem. Over the years several related proofs were\\npublished, but the first full proof of Gödel’s original\\nresult was given only in 1994 by Sam Buss in his ‘On\\nGödel’s theorems on lengths of proofs I: Number of lines\\nand speedups for arithmetic.’ (Buss 1994). Buss also gives a\\nsecond proof of the theorem which avoids self-reference, following a\\ntechnique due to Statman. Gödel measures the length of proofs by\\nthe number of formulas; but there are also other possibilities, such\\nas the number of symbols in the proof. The case of the Speed-up\\nTheorem where the length of proof is measured by the number of symbols\\nwas proved by Mostowski in 1952 (Mostowski 1982). For proofs of\\nsimilar results see Ehrenfeucht and Mycieleski 1971, and Parikh 1971.\\nThough both measures may be equally natural candidates for measuring\\nthe length of a proof, proving the theorem for length measured by the\\nnumber of symbols avoids a technical complication introduced by the\\nother measure: there are only finitely many proofs with a given number\\nof symbols, whereas there are infinitely many proofs with a given\\nnumber of formulas.  \\nGödel states the Speed-up Theorem differently from the above. Let be the system of logic of the -th\\norder, the variables of the first level being thought of as ranging\\nover natural numbers. In this setting, variables of the second level\\nrange over sets of natural numbers and so on. Gödel’s\\nformulation is:  \\nS  \\nn  \\nn  \\n. Let be a natural number > 0. If is a\\ncomputable function, then there are infinitely many formulas , provable in , such that if is the length of the shortest proof of in and is the length of the\\nshortest proof of in ,\\nthen > ( ).  \\nTheorem 6  \\nn  \\nf  \\nA  \\nS  \\nn  \\nk  \\nA  \\nS  \\nn  \\nl  \\nA  \\nS  \\n+1  \\nn  \\nk  \\nf  \\nl  \\nThe idea is the following: Let\\nφ( ) be a formula, like above, for which\\nφ( ) does not have a short proof in for any . Suppose we have a\\nhigher type system in which we can\\nprove ∀ φ( ). This proof is of constant\\nlength. Thus each φ( ) is derivable from this universal\\nstatement by one application of the logical rule\\n∀ φ( ) → φ( ). Thus\\nφ( ) has in that system for all a short\\nproof.  \\nProof sketch:  \\nx  \\nm  \\nS  \\nn  \\nm  \\nS  \\n+1  \\nn  \\nx  \\nx  \\nm  \\nx  \\nx  \\nt  \\nm  \\nm  \\nWhat kind of stronger system can we have in which\\n∀ φ( ) is provable? We may consider\\nsecond order logic in which we can define a predicate ( ) for the set of natural numbers and furthermore\\ncan prove of a new predicate symbol ( ) that it\\nsatisfies the inductive clauses of the truth definition of first order\\nformulas of arithmetic, relativized to . Then the stronger\\nsystem can prove that provable first order sentences of arithmetic\\nsatisfy the predicate . By the above argument, we can\\nprove in the stronger system that ∀ φ( )\\nsatisfies . Then by adding a few lines we can prove each\\nφ( ) satisfies . Because of the nature of\\nφ( ), this implies the stronger system has a (short)\\nproof of φ( ). An alternative system is Peano’s\\naxioms PA in an extended language where we have a new predicate symbol and axioms stating that the predicate codes\\nthe satisfaction relation for all sentences of the vocabulary not\\ncontaining .  \\nx  \\nx  \\nN  \\nx  \\nTr  \\nx  \\nN  \\nTr  \\nx  \\nx  \\nTr  \\nn  \\nTr  \\nn  \\nn  \\nTr  \\nTr  \\nTr  \\n2.4 Gödel’s Work in Set theory  \\n2.4.1 The consistency of the Continuum Hypothesis and the Axiom of Choice  \\nGödel’s proof of the consistency of the continuum\\nhypothesis with the axioms of Zermelo-Fraenkel set theory is a tour de\\nforce and arguably the greatest achievement of his mathematical life.\\nThis is because aside from the arithmetization, virtually all of the\\ntechnical machinery used in the proof had to be invented ab\\ninitio.  \\nThe Continuum Hypothesis (henceforth ) was formulated by\\nGeorg Cantor, and was the first problem on Hilbert’s list of\\ntwenty-three unsolved problems as given in his famous address to the\\nInternational Mathematical Congress in Paris in 1900. The problem as\\nstated by Hilbert is as follows: Let be an infinite set of\\nreal numbers. Then is either countable, or has cardinality\\n2 , i.e., is in one-to-one\\ncorrespondence either with the set of natural numbers or with the set\\nof all real numbers (otherwise known as the continuum). Another way to\\nstate the continuum hypothesis is that (the first uncountably infinite\\ncardinal) ℵ =\\n2 .  \\nCH  \\nA  \\nA  \\nℵ  \\n0  \\nA  \\n1  \\nℵ  \\n0  \\nAs early as 1922 Skolem speculated that the was\\nindependent of the axioms for set theory given by Zermelo in 1908.\\nNevertheless Hilbert published a (false) proof of the in\\nHilbert 1926. In 1937 Gödel proved its consistency with the\\naxioms of set theory. (Henceforth we use the standard\\nabbreviations for Zermelo-Fraenkel set theory, , and\\nZermelo-Fraenkel set theory with the Axiom of Choice, .)\\nThe consistency of the negation of the was shown by Paul\\nCohen in 1961 (see Cohen 1963) and hence together with\\nGödel’s result one infers that the is\\nindependent of (and ).  \\nCH  \\nCH  \\nZF  \\nZF  \\nZFC  \\nCH  \\nCH  \\nZF  \\nZFC  \\nCohen invented an important new technique called forcing in the course\\nof proving his result; this technique is at present the main method\\nused to construct models of set theory. Forcing led to a revival of\\nformalism among set theorists, the plurality of models being an\\nindication of the “essential variability in set theory,”\\n(Dehornoy 2004) and away from the notion that there is an intended\\nmodel of set theory—a perspective Gödel advocated since at\\nleast 1947, if not\\n earlier. Recently there have been signs that the may again be\\ncoming to be regarded as a problem to be solved mathematically (with\\nthe help of course of some new evident axioms extending ZF). (See for\\nexample Woodin 2001a, 2002, 2001b, and Foreman 1998.) If any of the\\nproposed solutions gain acceptance, this would confirm\\nGödel’s view that the would eventually be\\ndecided by finding an evident extension of the ZF axioms for set\\ntheory. The program associated with this view is called\\n“Gödel’s Large Cardinal Program.”  \\n[ ]  \\n14  \\nCH  \\nCH  \\n2.4.2 Gödel’s Proof of the Consistency of the Continuum Hypothesis and the Axiom of Choice with the Axioms of Zermelo-Fraenkel Set Theory  \\nThe continuum problem is shown to be consistent with ZF by finding an\\nenumeration of the reals which is indexed by the countable ordinals, a\\nstrategy which had been recognized as a promising one already by\\n Hilbert. The problem, and the intuition behind the proof, is to build a\\n“small” model, one in which the absolute minimum number of\\nreals is allowed, while at the same time the model is large enough to\\nbe closed under all the operations the axioms assert to\\nexist.  \\n[ ]  \\n15  \\nZF  \\nGödel’s is a relative consistency proof, obtained by\\nconstructing a so-called “inner model” for together with the . An inner model is a subcollection of the collection of all sets (see below) which\\nsatisfies the axioms of when only sets in are\\nconsidered. Gödel’s inner model is called the (see below) and is denoted by . Whatever is true in an inner model is consistent with for the same reason that any theory with a model is\\nconsistent. An artifact of the construction is that the Axiom of\\nChoice (henceforth ) is satisfied in Gödel’s\\ninner model and hence the consistency of the with was established by Gödel. Later on it was shown by\\nSierpinski that the is actually a consequence of the\\nGeneralized Continuum Hypothesis or the which states\\nthat for each κ, 2 = κ (see\\nSierpinski 1947).  \\nZF  \\nCH  \\nM  \\nV  \\nZF  \\nM  \\ninner\\nmodel of constructible sets  \\nL  \\nZF  \\nAC  \\nAC  \\nZF  \\nAC  \\nGCH,  \\nκ  \\n+  \\nGödel published two versions of these theorems, in 1939 and in\\n1940, entitled “Consistency Proof for the Generalized Continuum\\nHypothesis,” and “The Consistency of the Axiom of Choice\\nand of the Generalized Continuum Hypothesis with the Axioms of Set\\nTheory,” respectively. Though completely definitive, the 1939\\nversion is lacking in a great many details, most notably the arguments\\nshowing that if is built inside itself, the same results; that is to say, the so-called absoluteness\\narguments are missing. Also missing are the details of the proofs that\\nthe axioms hold in . Unlike the case of the\\nSecond Incompleteness Theorem, however, Gödel subsequently gave a\\ncompletely detailed proof of the two theorems in the 1940 monograph.\\n(The 1940 proof differs substantially from the first version. For\\ndetails about the two proofs and the difference between them the\\nreader is referred to Solovay 1990 and Kanamori 2006.)  \\nL  \\nL  \\nL  \\nZF  \\nL  \\nWe now sketch the proof of the consistency of and of with , using modern terminology. Some\\npreliminary concepts before sketching the proof: We first define the\\nstratified set theoretic universe, denoted . ( is\\nalso known as the cumulative hierarchy.) It is obtained by iteration\\nof the power set operation (℘) beginning with the null set:  \\nCH  \\nAC  \\nZFC  \\nV  \\nV  \\nV  \\n0  \\n=  \\n∅,  \\nV  \\nα+1  \\n=  \\n℘( ),  \\nV  \\nα  \\nV  \\nγ  \\n=  \\n,  \\n∪  \\nβ<γ  \\nV  \\nβ  \\nwhere α, β are any ordinals, γ is a limit ordinal and\\n℘( ) denotes the power set of . Finally  \\nx  \\nx  \\nV  \\n=  \\n,  \\n∪  \\nα∈  \\nOrd  \\nV  \\nα  \\nwhere denotes the class of all ordinals.  \\nOrd  \\nThe constructible hierarchy is likewise defined by\\nrecursion on ordinals. But whereas the full power set operation is\\niterated to obtain the cumulative hierarchy, the levels of the\\nconstructible hierarchy are defined strictly predicatively, that is by\\nincluding at the next level only those sets which are first order\\ndefinable using parameters from the previous level. More exactly, let ( ) denote the set of all subsets of definable in the structure < , ∈ > by first order\\nformulas with parameters in . (For more on definability see\\nthe entry on in this encyclopedia.)  \\nL  \\nDef  \\nA  \\nA  \\nA  \\nA  \\nmodel theory  \\nWith this notation the constructible hierarchy is defined by induction\\nover the ordinals as follows:  \\nL  \\n0  \\n=  \\n∅,  \\nL  \\nα+1  \\n=  \\n( ),  \\nDef  \\nL  \\nα  \\nL  \\nγ  \\n=  \\n,  \\n∪  \\nα<γ  \\nL  \\nα  \\nL  \\n=  \\n,  \\n∪  \\nα∈  \\nOrd  \\nL  \\nα  \\nA set is said to be if ∈ . The axiom which states that all sets are\\nconstructible is denoted = and is called the\\nAxiom of Constructibility. Note that is a proper class and\\nnot a set; although as we will see, each is a set, and the predicate “ is constructible”\\nis actually a definable term of the language.  \\nx  \\nconstructible  \\nx  \\nL  \\nV  \\nL  \\nL  \\nL  \\nα  \\nx  \\nOur next task is to show that is a model of . A\\nset or a class is if elements of it are also\\nsubsets. By a meticulous transfinite induction, can be shown to be transitive for each α; and therefore\\nso is itself. This fact, together with the observation that\\nsome elementary closure properties hold in is enough to show that is a model of . (Indeed,\\nas it turns out, is the minimal transitive model of the axioms containing all the ordinals, and is therefore in\\nthis sense canonical.)  \\nL  \\nZF  \\ntransitive  \\nL  \\nα  \\nL  \\nL  \\n[ ]  \\n16  \\nL  \\nZF  \\nL  \\nZF  \\nIn detail, proving that the axioms, apart from the\\ncomprehension axiom, are true in , amounts to showing that,\\nroughly speaking, any set with a property that a axiom asserts to exist, can be seen to exist in by considering the relativization of the\\nproperty to . (A property is\\nrelativized to an inner model by replacing every quantifier\\n∃ φ by ∃ ( ∈ ∧ φ) and every quantifier ∀ φ\\nby ∀ ( ∈ → φ).) As\\nfor the comprehension axiom, verifying it requires showing that the\\nset asserted to exist is constructed at a particular successor level . Proving this requires an important\\nprinciple of set theory which in modern terminology is called the Levy\\n(or ) Reflection Principle. This principle says that any\\nstatement in the language of which is true in is already true on some level of any continuously increasing hierarchy\\nsuch as . (For the history of this principle, see Kanamori\\n2006.) The Levy Reflection Principle gives the level α at which\\nthe elements of the set are all constructed. Gödel did not\\nactually have the Levy Reflection Principle but used the argument\\nbehind the proof of the principle.  \\nZF  \\nL  \\nP  \\nZF  \\nL  \\nP  \\nL  \\nP  \\nL  \\nP  \\nM  \\nx  \\nx  \\nx  \\nM  \\nx  \\nx  \\nx  \\nM  \\nL  \\nα + 1  \\nZF  \\nZF  \\nV  \\nL  \\nOnce it is established that is a model of , one\\ncan now prove that both the and the hold in . To this end, one first shows that the definition of is for , where absoluteness is\\ndefined as follows: given a class , a predicate ( ) is said to be absolute for if and\\nonly if for all ∈ , ( )\\n↔ ( ).  \\nL  \\nZF  \\nCH  \\nAC  \\nL  \\nL  \\nabsolute  \\nL  \\nM  \\nP  \\nx  \\nM  \\nx  \\nM  \\nP  \\nx  \\nP  \\nM  \\nx  \\nProving that the predicate “ is constructible”\\nis absolute requires formalizing the notion of definability, which in\\nturn requires formalizing the notion of satisfaction. This is because\\nthe predicate “ is constructible” says of a set,\\nthat for some ordinal α, and for some formula φ with\\nparameters in , = { ∈ | ⊨ φ( )}. This part of the proof is tedious but\\nunproblematic.  \\nx  \\nx  \\nL  \\nα  \\nx  \\ny  \\nL  \\nα  \\nL  \\nα  \\ny  \\nOnce the absoluteness of is established, it follows that satisfies the axiom of constructibility if it is\\nrelativized to ; that is, ⊢\\n(V=L) . In particular, the axiom = is\\nconsistent if is.  \\nL  \\nZF  \\nL  \\nZF  \\nL  \\nV  \\nL  \\nZF  \\nWe now give the idea of the proof of and in + = . (For a detailed exposition of\\nthe proof, the reader is referred to the standard sources. See for\\nexample Devlin’s chapter on constructibility in Barwise 1977;\\nsee also Kunen 1983, and Jech 2003.)  \\nCH  \\nAC  \\nZF  \\nV  \\nL  \\nAs concerns the , the idea behind the proof of it in is simply the following: Gödel showed that assuming = , every real number occurs on some countable\\nlevel of the -hierarchy. Since every countable level is\\nitself countable (after all, there are only countably many possible\\ndefining formulas), and there are ω countable\\nlevels, there must be only ω real numbers.  \\nCH  \\nL  \\nV  \\nL  \\nL  \\n1  \\n1  \\nThe difficulty here, if not of the whole proof altogether, lies in\\nshowing that every real is constructed already on a countable level of\\nthe -hierarchy. To show this Gödel argued as follows:\\nSuppose is a real number thought of as a set of natural\\nnumbers. By a combination of the Levy Reflection principle and the\\nLöwenheim-Skolem Theorem there is a countable submodel < , ∈ > of < , ∈ > satisfying a\\nsufficiently large part of the axioms + = , such that belongs to .\\nBy a simple procedure < , ∈ > can be converted\\ninto a transitive model < , ∈ >. This procedure,\\nused by Gödel already in 1937, was explicitly isolated by\\nMostowski (Mostowski 1949). The resulting model is referred to as the\\nMostowski Collapse.  \\nL  \\nA  \\nM  \\nL  \\nfinite  \\nZF  \\nV  \\nL  \\nA  \\nM  \\nM  \\nN  \\nLet us pause to discuss this important technique. Suppose < , > is a well-founded model of the axiom of\\nextensionality. It is a consequence of the well-foundedness of the\\nbinary predicate on , and of the principle of\\ntransfinite recursion, that the equation π( ) =\\n{π( )\\u2009| ∈ ∧ } defines a unique function on . The range of π is transitive, for if π( ) ∈ and ∈ π( ), then =\\nπ( ) for some ∈ with , whence π( ) ∈ . The fact that\\nπ is an isomorphism between < , > and\\n< , ∈ > can be proved by transfinite induction on\\nelements on , based again on the well-foundedness of . The well-foundedness of < , > is\\nin practice often the consequence of < , >\\nbeing a submodel of some < , ε\\n>.  \\nM  \\nE  \\nE  \\nM  \\nx  \\ny  \\ny  \\nM  \\nyEx  \\nM  \\nN  \\na  \\nN  \\ny  \\na  \\ny  \\nb  \\nb  \\nM  \\nbEa  \\nb  \\nN  \\nM  \\nE  \\nN  \\nM  \\nE  \\nM  \\nE  \\nM  \\nE  \\nV  \\nα  \\nWe now return to the proof of the in . We used\\nthe Mostowski Collapse to construct the transitive set . As\\nit turns out, the real number is still an element of < , ∈ > . By basic properties of , < , ∈ > must be < ,\\n∈ > for some α . Since is countable, α\\nis countable too. (It can be shown that | |\\n= |α| + ℵ .) Thus is constructible\\non a countable level, which was to have been shown.  \\nCH  \\nL  \\nN  \\nA  \\nN  \\nL  \\nN  \\nL  \\nα  \\nN  \\nL  \\nα  \\n0  \\nA  \\nAs for the , Gödel exhibits a definable well-ordering,\\nthat is, a formula of set theory which defines, in , a\\nwell-ordering of all of . The formula is tedious to write\\ndown but the idea is a simple one: A set precedes a set in the well-ordering if and only if either occurs in the -hierarchy on an earlier level than , or else they occur on\\nthe same level but is defined by a shorter formula than , or else they are defined by the same formula but the\\nparameters in the definition of occur in earlier\\nthan the parameters of . This well-ordering of shows that the holds in .  \\nAC  \\nL  \\nL  \\nx  \\ny  \\nx  \\nL  \\nL  \\nα  \\ny  \\nx  \\ny  \\nx  \\nL  \\ny  \\nL  \\nAC  \\nL  \\nThis concludes the proof of the consistency of and the in .  \\nAC  \\nCH  \\nL  \\nWe note that Gödel proved more in his 1939 and 1940 than what was\\nshown here, namely he proved the Generalized Continuum Hypothesis in and hence that its consistency with .  \\nL  \\nZF  \\n2.4.3 Consequences of Consistency  \\nAs noted above, it was suggested already in the 1920s that the might be independent of or . After\\nfirst conjecturing that the Axiom of Constructibility might be\\n“absolutely consistent,” meaning not falsifiable by any\\nfurther extension of models of + = , in his 1947 “What is Cantor’s Continuum\\nHypothesis?” Gödel conjectured that the would\\nbe shown to be independent. The main consequence of Gödel’s\\nresult, then, as far as the problem of proving the independence of the is concerned, was that it pointed mathematicians in the\\ndirection of adding non-constructible sets to a model of set theory in\\norder to establish the consistency of the negation of the .\\nIn 1961 Dana Scott proved that the failure of the Axiom of\\nConstructibility follows from the existence of a measurable cardinal,\\ncontrary to a conjecture Gödel had made in 1940. (See Scott 1961.\\nA cardinal κ is said to be measurable if there is a\\nnon-principal κ-complete ultrafilter in the power-set Boolean\\nalgebra of κ.) In 1963, as noted, Paul Cohen proved the\\nconsistency of the negation of the by adding\\nnon-constructible sets to an inner model.  \\nCH  \\nZF  \\nZFC  \\nZF  \\nV  \\nL  \\n[ ]  \\n17  \\nCH  \\nCH  \\nCH  \\nCH  \\nWhat other open questions of set theory could be solved by\\nGödel’s method? Gödel himself noted some consequences.\\nThey are related to so called projective sets of real numbers and\\nfinite sequences of real numbers. The simplest projective sets are the\\nclosed sets, also called Π -sets. A set is\\nΣ if it is the projection of\\na Π -subset of the real plane. A\\nset is Δ if it and its\\ncomplement are Σ . Gödel\\nobserved that there is both a non-Lebesgue measurable\\nΔ -set and an uncountable\\nΠ -set without a perfect subset in . (A set of reals is perfect if it is closed, non-empty, and\\nhas no isolated points. Such sets have the size of the continuum.)\\nGödel gave a sketch of the proof in the 1951 second printing of\\nGödel 1940.  \\n1  \\n0  \\n1  \\n+1  \\nn  \\n1  \\nn  \\n1  \\n+1  \\nn  \\n1  \\n+1  \\nn  \\n1  \\n2  \\n1  \\n1  \\nL  \\nIt has turned out subsequently that the axiom = gives a virtually complete extension of . This means that,\\napart from sentences arising from Gödel’s incompleteness\\ntheorems, essentially all set-theoretical questions can be decided by\\nmeans of the axioms = . This is not to imply that\\nsuch results are in any way trivial. Indeed, it has turned out that is quite a complicated structure, despite its relatively\\nsimple description. As for settling open set-theoretical questions in the main step was the emergence of Jensen’s fine\\nstructure theory of (Jensen 1972). Recalling that the\\nsuccessor step in the definition of\\nthe constructible hierarchy adds to all subsets of definable by first order formulas φ\\nover ( , ∈), fine structure theory,\\nroughly speaking, ramifies the step from to into smaller steps according to the\\ncomplexity of the defining formula φ. Jensen established by means\\nof his fine structure a strengthening, denoted by ◊, of , that he used to construct a Souslin tree in ,\\nand a combinatorial principle □ that he used to show that the\\nSouslin Hypothesis is consistent with .  \\nV  \\nL  \\nZFC  \\nV  \\nL  \\nL  \\nL,  \\nL  \\nL  \\nα +1  \\nL  \\nL  \\nα  \\nL  \\nα  \\nL  \\nα  \\nL  \\nα+1  \\nCH  \\nL  \\nCH  \\n2.4.4 Gödel’s view of the Axiom of Constructibility  \\nIf he did not think this way from the outset, Gödel soon came to\\nadopt the view that the Axiom of Constructibility was implausible. As\\nhe remarked at the end of his 1947 “What is Cantor’s\\nContinuum Hypothesis?”  \\n…it is very suspicious that, as against the numerous plausible\\npropositions which imply the negation of the continuum hypothesis, not\\none plausible proposition is known which would imply the continuum\\nhypothesis. (Gödel 1990, p. 186)  \\nGödel was compelled to this view of by the\\n Leibnizian idea that, rather than the universe being “small,” that\\nis, one with the minimum number of sets, it is more natural to think\\nof the set theoretic universe as being as large as\\n possible. This\\n idea would be reflected in his interest in maximality principles,\\ni.e., principles which are meant to capture the intuitive idea that\\nthe universe of set theory is maximal in the sense that nothing can be\\nadded; and in his conviction that maximality principles would\\neventually settle statements like the . As Gödel put\\nit in a letter to Ulam in the late 1950s, about a maximality principle\\nof von Neumann:  \\nL  \\n[ ]  \\n18  \\n[ ]  \\n19  \\nCH  \\nThe great interest which this axiom has lies in the fact that it is a\\nmaximality principle, somewhat similar to Hilbert’s axiom of\\ncompleteness in geometry. For, roughly speaking, it says that any set\\nwhich does not, in a certain well defined way, imply an inconsistency\\nexists. Its being a maximum principle also explains the fact that this\\naxiom implies the axiom of choice. I believe that the basic problems\\nof set theory, such as Cantor’s continuum problem, will be\\nsolved satisfactorily only with the help of stronger axioms of this\\nkind, which in a sense are opposite or complimentary to the\\nconstructivistic interpretation of mathematics. (Ulam 1958, as quoted\\nin Gödel 1990, p. 168; original emphasis. Note that this is\\ndifferent from the very similar passage Gödel 2003b, p.295.)  \\nTwenty years earlier, in 1938, Gödel had written seemingly\\ndifferently about the Axiom of Constructibility:  \\nThe proposition (i.e., = ) added as a\\nnew axiom seems to give a natural completion of the axioms of set\\ntheory, in so far as it determines the vague notion of an arbitrary\\ninfinite set in a definite way. (Gödel 1986, p.27)  \\nA  \\nV  \\nL  \\nGödel may have meant by “natural completion” here\\n“the correct completion,” or he may have meant to say no\\nmore than that the Axiom of Constructibility determines the notion of\\nset in a definite way. In any case he used the term\\n“natural” differently in a conversation with Wang on\\nconstructibility in 1972 (Wang 1996, p. 144):  \\nGödel talked more about the relation between axioms of infinity\\nand the constructible universe…(he observed that) preliminary\\nconcepts such as that of constructible sets are necessary to arrive at\\nthe natural concept, such as that of set.  \\nThis is reminiscent of a remark of Hugh Woodin, that studying forcing\\nleads to a better understanding of — the general\\nprinciple being that studying the models of a theory is not only\\nuseful to understand the theory itself, but useful to obtain a better\\npicture of (Woodin 1988).  \\nV  \\nV  \\nFor more on Gödel’s program and on Gödel’s\\nprogram relative to the the reader is referred e.g., to\\nSteel forthcoming and Feferman . 2000. For more on\\nGödel’s result, its history , and its significance the\\nreader is referred to Floyd/Kanamori 2006 and Kennedy 2006.  \\nCH  \\net al  \\n2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic  \\nGödel’s interest in intuitionism was deep and long-lasting.\\nAlthough he himself did not subscribe to that view, he made a number\\nof important contributions to intuitionistic logic. Perhaps the\\nimportance he placed on the concept of evidence (see below) led to his\\nclose consideration of it.  \\nWe discuss Gödel’s results on intuitionistic logic in their\\nchronological order.  \\n2.5.1 Intuitionistic Propositional Logic is not Finitely-Valued  \\nBoth many-valued logic, introduced by Łukasiewicz in the twenties\\n(Łukasiewicz 1970) and intuitionistic logic, formalized by\\nHeyting in 1930, fail to satisfy the law of excluded middle. It was\\ntherefore natural to ask whether intuitionistic logic can be presented\\nas a many-valued logic, and indeed a number of logicians in the 1920s\\nhad suggested just that. In his 1932 Gödel gave a simple argument\\nwhich shows that intuitionistic propositional logic cannot be thought\\nof as a finitely-valued logic. Precisely, Gödel proved two\\ntheorems:  \\n. There is no realization with finitely many elements (truth values) for\\nwhich the formulas provable in , and only those, are\\nsatisfied (that is, yield designated values for an arbitrary\\nassignment).  \\nTheorem 7  \\nH  \\n( is intuitionistic propositional logic, after\\nHeyting.)  \\nH  \\n. Infinitely many systems lie between and the system of the ordinary propositional calculus, that is,\\nthere is a monotonically decreasing sequence of systems all of which\\ninclude as a subset and are included in as subsets.  \\nTheorem 8  \\nH  \\nA  \\nH  \\nA  \\nIn his proof he considered for each natural number > 0\\nthe sentence  \\nn  \\n= ≡ .  \\nF  \\nn  \\n∨  \\n1\\n≤ < ≤  \\ni  \\nj  \\nn  \\np  \\ni  \\np  \\nj  \\nHe observed that in an -valued logic the sentences , for > ,\\nshould be derivable. However, Gödel showed, is not derivable from Heyting’s\\naxioms for any .  \\nn  \\nF  \\nm  \\nm  \\nn  \\nF  \\nn  \\nn  \\nSubsequently Jaśkowski (Jaśkowski 1936) showed that\\nintuitionistic propositional logic can be given a many-valued\\nsemantics in terms of infinitely many truth-values. For further\\ndiscussion of many-valued logics, see for example the entry on in this encyclopedia as well as van Stigt’s article on\\nintuitionistic logic in Mancosu 1998.  \\nmany-valued logic  \\n2.5.2 Classical Arithmetic is Interpretable in Heyting Arithmetic  \\nWe now consider Gödel 1933e, in which Gödel showed, in\\neffect, that intuitionistic or Heyting arithmetic is only apparently\\nweaker than classical first-order arithmetic. This is because the\\nlatter can be interpreted within the former by means of a simple\\ntranslation, and thus to be convinced of the consistency of classical\\narithmetic, it is enough to be convinced of the consistency of Heyting\\narithmetic. Heyting arithmetic is defined to be the same as classical\\narithmetic, except that the underlying predicate logic is given by\\nintuitionistic axioms and rules of inference (see below).  \\nThis result extends the same assertion for the propositional case. Let denote the intuitionistic propositional logic, and denote its classical counterpart (as above).\\nInductively define:  \\nH  \\nA  \\n′  \\nA  \\n≡  \\n¬¬ ( atomic)  \\nA  \\nA  \\n(¬ )′  \\nA  \\n≡  \\n¬ ′  \\nA  \\n( → )′  \\nA  \\nB  \\n≡  \\n¬( ′ ∧\\n¬ ′)  \\nA  \\nB  \\n( ∨ )′  \\nA  \\nB  \\n≡  \\n¬(¬ ′ ∧\\n¬ ′)  \\nA  \\nB  \\n( ∧ )′  \\nA  \\nB  \\n≡  \\n′ ∧ ′  \\nA  \\nB  \\nThen,  \\n. Let be a propositional formula. Then ⊢ if and only if ⊢ ′,  \\nTheorem 9  \\nF  \\nH  \\nF  \\nA  \\nF  \\nThe theorem follows easily from the result of Glivenko (1929) that\\n¬ follows from if and only if\\n¬ follows from , for any propositional\\nformula .  \\nF  \\nH  \\nF  \\nA  \\nF  \\nGödel’s so-called double negation interpretation extends\\nTheorem 9 to a reduction of classical first order logic to\\nintuitionistic predicate logic. The translation in this case can be\\ntaken to map ′ to for atomic .\\nMoreover, we let ∀ ( )′ =\\n∀ ′( ) :  \\nA  \\nA  \\nA  \\nxA  \\nx  \\nxA  \\nx  \\n. Suppose is a first order formula. If is provable\\nin classical first order logic, then ′ is provable in\\nintuitionistic first order logic.  \\nTheorem 10  \\nA  \\nA  \\nA  \\nThe above result had been obtained independently by Gentzen (with\\nBernays), but upon hearing of Gödel’s result Gentzen\\nwithdrew his paper from publication. It had also been anticipated by\\nKolmogorov in his 1925 “On the Principle of the Excluded\\nMiddle,” (English translation van Heijenoort 1967) but that\\npaper was largely unknown to logicians who were outside of\\nKolmogorov’s circle.  \\nBernays has written (see Bernays’ entry on David Hilbert in\\nEdwards 1967) that this result of Gödel’s drew the\\nattention of the Hilbert school to two observations: first, that\\nintuitionistic logic goes beyond finitism, and secondly, that finitist\\nsystems may not be the only acceptable ones from the foundational\\npoint of view.  \\nThe following theorem for the case of arithmetic follows from Theorem\\n10:  \\n. Suppose is a first order formula of arithmetic. If is provable in classical Peano arithmetic, then ′ is provable in intuitionistic first order\\narithmetic.  \\nTheorem 11  \\nA  \\nA  \\nA  \\nFor a list of the axioms and rules of intuitionistic first order logic\\nsee Gödel 1958, reprinted with detailed introductory note by A.S.\\nTroelstra in Gödel 1990. See also Troelstra 1973, and\\nTroelstra’s “Aspects of constructive mathematics” in\\nBarwise 1977. For a detailed proof of the above theorem the reader is\\nreferred also to the latter.  \\n2.5.3 Intuitionistic Propositional Logic is Interpretable in  \\nS4  \\nThis result of Gödel’s (Gödel 1933f), which marks the\\nbeginning of provability logic, makes exact the difference between the\\nconcept of “provability in a specified formal system” and\\nthat of “provability by any correct means.”  \\nGödel had already noted this difference in the introduction to\\nhis 1929 thesis. The context was the following: Gödel entertains\\nthere the possibility that his proof of the Completeness Theorem might\\nbe circular, since the law of excluded middle was used to prove it.\\nThis is because while the Completeness Theorem asserts ‘a kind\\nof decidability,’ namely every quantificational formula is\\neither provable or a counterexample to it can be given, ‘the\\nprinciple of the excluded middle seems to express nothing other than\\nthe decidability of every problem’:  \\n… what is affirmed (by the law of excluded middle) is the\\nsolvability not at all through specified means but only through all\\nmeans that are …  \\nin any way imaginable  \\n[ ]  \\n20  \\nGödel considers intuitionistic propositional logic (henceforth\\nIPL); he also considers a second system, classical propositional logic\\nenriched by an operator “B”, where the intended meaning of\\n“B” is “provable.” The axiom system now known\\nas (for a list of these axioms see for example the\\nentry on in this encyclopedia) is added to the standard axioms for classical\\npropositional logic together with a new rule of proof: from , B may be inferred. Let us call this second\\nsystem . Gödel’s theorem states that is interpretable in via the following\\ntranslation:  \\nS4  \\nmodal logic  \\nA  \\nA  \\nG  \\nIPL  \\nG  \\n¬  \\np  \\n≡  \\n~B  \\np  \\n⊃  \\np  \\nq  \\n≡  \\nB → B  \\np  \\nq  \\n∨  \\np  \\nq  \\n≡  \\nB ∨ B  \\np  \\nq  \\n∧  \\np  \\nq  \\n≡  \\nB ∧ B  \\np  \\nq  \\nThat is,  \\n. Let be a formula of , and let ′\\nbe its translation. Then ⊢ implies ⊢ ′.  \\nTheorem 12  \\nA  \\nIPL  \\nA  \\nIPL  \\nA  \\nG  \\nA  \\nGödel conjectures that the converse implication must be true, and\\nindeed this was shown in McKinsey and Tarski 1948.  \\nThe difference between the two notions of provability: “provable\\nin a given formal system ” and provability by any\\ncorrect means — manifests itself as a consequence of\\nGödel’s Second Incompleteness Theorem, as follows. Let contain Peano arithmetic, and let the operator B be\\ninterpreted as “provable in ”. If the axioms of were valid for this interpretations of ,\\nthen from (0 ≠ 1) → (0 ≠ 1), the sentence\\n¬ (0 ≠ 1) would be provable, contradicting the Second\\nIncompleteness Theorem.  \\nS  \\nS  \\nS  \\nS4  \\nB  \\nB  \\nB  \\nFor further discussion of Gödel’s theorem, its antecedents\\nand its extensions, as well as its philosophical significance, the\\nreader is referred to A.S Troelstra’s introduction to .  \\n1933f  \\n2.5.4 Heyting Arithmetic is Interpretable into Computable Functionals of Finite Type.  \\nGödel’s so-called Dialectica intepretation (Gödel\\n1958) delivers a relative consistency proof and justification for\\nHeyting arithmetic by means of a concrete interpretation involving a\\nsystem of computable functionals of finite type. Taken\\ntogether with his 1933e, which reduces classical first order\\narithmetic to Heyting arithmetic, a justification in these terms is\\nalso obtained for classical first order arithmetic.  \\nT  \\nGödel’s inductive definition of the notion “function\\nof finite type” is as follows: (Gödel 1990, p. 245).  \\nThe functionals of type 0 are the natural numbers.  \\nIf ,…, are types and we have already defined\\nwhat functionals of types ,…, are,\\nthen ( ,…, ) is a type and a functional of that\\ntype assigns to every -tuple of functionals of respective\\ntypes ,…, , a functional of type .  \\nt  \\n0  \\nt  \\nk  \\nt  \\n0  \\nt  \\nk  \\nt  \\n0  \\nt  \\nk  \\nk  \\nt  \\n1  \\nt  \\nk  \\nt  \\n0  \\nGödel considers the quantifier free theory of these functionals\\nof finite type, denoted by . has the following\\nfeatures: the language of contains variables of each type,\\nconstants for distinguished types, and a ternary predicate\\n= for equality for type σ. Equality between\\nterms of the same type is decidable. The non-logical axioms and rules\\nfor include the classical arithmetic axioms for 0 and\\nsuccessor, and the induction rule:  \\nT  \\nT  \\nT  \\nσ  \\nT  \\n( (0) ∧ ( ( ) → ( ( )))) → ( )  \\nF  \\nF  \\nx  \\n0  \\nF  \\nS  \\nx  \\n0  \\nF  \\nx  \\n0  \\nfor quantifier-free formulas ( ). As\\nGödel remarks (Gödel 1990, p. 247), the axioms for are essentially those of primitive recursive arithmetic,\\nexcept that the variables can be of any finite type.  \\nF  \\nx  \\n0  \\nT  \\nGödel’s translation associates with every formula ( ) of the language of Peano arithmetic a\\nformula ′( ) =\\n∃ ∀ ( , , ) of the language of the theory , where is quantifier free and the (boldface)\\nbound variables are finite sequences of variables thought to range\\nover functionals of a finite type determined by the type of the\\nvariable. Intuitively, is a concrete analogue of\\nthe abstract notion of a construction constituting the meaning of .  \\nF  \\nx  \\nF  \\nx  \\ny  \\nz  \\nA  \\ny  \\nz  \\nx  \\nT  \\nA  \\ny  \\nF  \\nGödel’s theorem is as follows:  \\n. Suppose ′ =\\n∃ ∀ ( , , ). If is provable in\\nintuitionistic first order arithmetic, then there are computable\\nfunctionals of finite type such that ( ( ), , ) is provable in .  \\nTheorem 13  \\nF  \\ny  \\nz  \\nA  \\ny  \\nz  \\nx  \\nF  \\nQ  \\nA  \\nQ  \\nx  \\nz  \\nx  \\nT  \\nThe proof is by induction on the structure of the proof of in intuitionistic first order arithmetic. (For a treatment of the\\nproof in detail, the reader is referred to Troelstra 1986.)  \\nF  \\nThe importance of the theorem for foundations cannot be\\n overstated. A discussion of its generalizations, of ensuing work on functional\\ninterpretations stimulated by the theorem due to Kreisel, Tait,\\nHoward, Feferman and others; its foundational and philosophical\\nsignificance; and finally its relation particularly to the earlier,\\ninformal, proof interpretation, so-called, given by\\nHeyting-Kolmogorov, will not be attempted here. Accordingly the reader\\nis referred to the large literature on the subject, e.g., the\\nabovementioned Troelstra 1986, Tait 1967, Feferman 1993 and Avigad\\n& Feferman 1998. For interesting recent developments, e.g., in the\\narea of relating Gödel’s Dialectica interpretation and\\nKreisel’s modified realizability, see Oliva 2006. See also van\\nOosten 2008.  \\n[ ]  \\n21  \\nA remark concerning the philosophical context in which Gödel\\npresented his translation, namely finitism. The question addressed in\\nthe introduction to the paper is what notions must\\nbe added to finitary mathematics in order to obtain a consistency\\nproof for arithmetic. Equivalently: what does the finitary view\\npresuppose, which must be given up in the light of the Second\\nIncompleteness Theorem, if the consistency proof is to be\\nobtained:  \\nabstract  \\nIn any case Bernays’ remark teaches us to distinguish two\\ncomponents of the finitary attitude; namely, first, the constructive\\nelement, which consists in our being allowed to speak of mathematical\\nobjects only insofar as we can exhibit them or actually produce them\\nby means of a construction; second, the specifically finitistic\\nelement, which makes the further demand that the objects about which\\nwe make statements, with which the constructions are carried out and\\nwhich we obtain by means of these constructions, are\\n‘intuitive’, that is, are in the last analysis\\nspatiotemporal arrangements of elements whose characteristics other\\nthan their identity or nonidentity are irrelevant.… It is the\\nsecond requirement that must be dropped. This fact has hitherto been\\ntaken into account by our adjoining to finitary mathematics parts of\\nintuitionistic logic and the theory of ordinals. In what follows we\\nshall show that, for the consistency proof of number theory, we can\\nuse, instead, the notion of computable function of finite type on the\\nnatural numbers and certain rather elementary principles of\\nconstruction for such functions. (Gödel 1990, p.245).  \\nAside from its technical contribution, then, Gödel’s\\n1958/72 is one of Gödel’s most important philosophical\\nworks; notable for its analysis of the nature of finitary mathematics,\\nas well as its analysis of the notions of “intuitive,” as\\nin “intuitive knowledge,” and that of abstract versus\\nconcrete evidence.  \\nIn the next section, we turn to Gödel’s philosophical\\nviews. But interested readers may wish to read a brief discussion\\nabout Gödel’s Nachlass, important source of philosophical\\nmaterial by Gödel:  \\nSupplement Document: Gödel’s Documents  \\n3. Gödel’s Philosophical Views  \\nGödel’s philosophical views can be broadly characterized by\\ntwo points of focus, or, in modern parlance, commitments. These are:\\nrealism, namely the belief that mathematics is a descriptive science\\nin the way that the empirical sciences are. The second commitment is\\nto a form of Leibnizian rationalism in philosophy; and in fact\\nGödel’s principal philosophical influences, in this regard\\nparticularly but also many others, were Leibniz, Kant and Husserl.\\n(For further discussion of how these philosophers influenced\\nGödel, see van Atten and Kennedy 2003.)  \\nThe terms “Gödel’s realism” and\\n“Gödel’s rationalism” must be prefaced with a\\ndisclaimer: there is no single view one could associate with each of\\nthese terms. Gödel’s realism underwent a complex\\ndevelopment over time, in both the nature of its ontological claims as\\nwell as in Gödel’s level of commitment to those claims.\\nSimilarly Gödel’s rationalism underwent a complex\\ndevelopment over time, from a tentative version of it at the\\nbeginning, to what was adjudged to be a fairly strong version of it in\\nthe 1950s. Around 1959 and for some time afterward Gödel fused\\nhis rationalistic program of developing exact philosophy with the\\nphenomenological method as developed by Husserl.  \\nWe examine these two strains of Gödel’s thinking below:  \\n3.1 Gödel’s Rationalism  \\nGödel’s rationalism has its roots in the Leibnizian thought\\nthat the world, not that which we immanently experience but that which\\nitself gives rise to immanent experience, is perfect and beautiful,\\nand therefore rational and ordered. Gödel’s justification\\nof this belief rests partly on an inductive generalization from the\\nperfection and beauty of mathematics:  \\nRationalism is connected with Platonism because it is directed to the\\nconceptual aspect rather than toward the (real) world. One uses\\ninductive evidence…Mathematics has a form of\\nperfection…We may expect that the conceptual world is perfect,\\nand, furthermore, that objective reality is beautiful, good, and\\nperfect. (Wang 1996, 9.4.18)  \\nOur total reality and total experience are beautiful and\\nmeaningful—this is also a Leibnizian thought. We should judge\\nreality by the little which we truly know of it. Since that part which\\nconceptually we know fully turns out to be so beautiful, the real\\nworld of which we know so little should also be beautiful.\\n(9.4.20)  \\nAlthough the roots of Gödel’s belief in rationalism are\\nmetaphysical in nature, his long-standing aspirations in that domain\\nhad always been practical ones. Namely, to develop exact methods in\\nphilosophy; to transform it into an exact science, or , to use Husserl’s term.  \\nstrenge\\nWissenschaft  \\nWhat this means in practice is taking the strictest view possible of\\nwhat constitutes the grounds for the acceptance\\nof an assertion; put another way, a level of rigor is aspired to in\\nphilosophical arguments approaching that which is found in\\nmathematical proofs. A formulation of the view—one which is\\nsomewhat phenomenologically colored (see below)—can be found in\\na document in the Gödel Nachlass. This is a fourteen item list\\nGödel drew up in about 1960, entitled “My Philosophical\\nViewpoint.” Two items on the list are relevant here:  \\ndialectical  \\nThere are systematic methods for the solution of all problems\\n(also art, etc.).  \\nThere is a scientific (exact) philosophy and theology, which deals\\nwith concepts of the highest abstractness; and this is also most\\nhighly fruitful for science.  \\n(The list was transcribed by Cheryl Dawson and was published in , p. 316.)  \\nWang 1996  \\nGödel’s earlier conception of rationalism refers to\\nmathematical rigor and includes the concept of having a genuine proof,\\nand is therefore in some sense a more radical one than that to which\\nhe would later subscribe. One can see it at work at the end of the\\nGibbs lecture, after a sequence of arguments in favor of realism are\\ngiven:  \\nOf course I do not claim that the foregoing considerations amount to a\\nreal proof of this view about the nature of mathematics. The most I\\ncould assert would be to have disproved the nominalistic view, which\\nconsiders mathematics to consist solely in syntactical conventions and\\ntheir consequences. Moreover, I have adduced some strong arguments\\nagainst the more general view that mathematics is our own creation.\\nThere are, however, other alternatives to Platonism, in particular\\npsychologism and Aristotelian realism. In order to establish Platonic\\nrealism, these theories would have to be disproved one after the\\nother, and then it would have to be shown that they exhaust all\\npossibilities. I am not in a position to do this now; however I would\\nlike to give some indications along these lines. (Gödel 1995, p.\\n321–2).  \\n(For a penetrating analysis of this passage see Tait 2001.) Such an\\nanalysis must be based on conceptual analysis:  \\nI am under the impression that after sufficient clarification of the\\nconcepts in question it will be possible to conduct these discussions\\nwith mathematical rigour and that the result will then be…that\\nthe Platonistic view is the only one tenable. (Gödel 1995, p.\\n322).  \\nAlong with the methodological component, as can be seen from the items\\non Gödel’s list, there was also an “optimistic”\\ncomponent to Gödel’s rationalism: once the appropriate\\nmethods have been developed, philosophical problems such as, for\\nexample, those in ethics (e.g., item 9 on the list is: “Formal\\nrights comprise a real science.”) can be decisively solved. As\\nfor mathematical assertions, such as the Continuum Hypothesis in set\\ntheory, once conceptual analysis has been carried out in the right\\nway, that is, once the basic concepts, such as that of\\n“set,” have been completely clarified, the Continuum\\nHypothesis should be able to be decided.  \\nAlthough at the time of the Gibbs lecture the analogy in\\nGödel’s mind between philosophical and mathematical\\nreasoning may have been a very close one, Gödel’s view at\\nother periods was that the envisaged methods will not be mathematical\\nin nature. What was wanted was a general, informal science of\\nconceptual analysis.  \\nPhilosophy is more general than science. Already the theory of\\nconcepts is more general than mathematics…True philosophy is\\nprecise but not specialized.  \\nPerhaps the reason why no progress is made in mathematics (and there\\nare so many unsolved problems), is that one confines oneself to the\\next[ensional]—thence also the feeling of disappointment in the\\ncase of many theories, e.g., propositional logic and formalisation\\naltogether. (Wang 1996, 9.3.20,\\n 9.3.21)  \\n[ ]  \\n22  \\n(See notebook Max IV, p. 198 (Gödel Nachlaß, Firestone\\nLibrary, Princeton, item 030090). Transcription Cheryl Dawson;\\ntranslation from the German ours; amendment ours. Gödel’s\\ndating of Max IV indicates that it is from May 1941 to April 1942. See\\nalso Gödel’s letter to Bernays, Gödel 2003a, p.\\n283.)  \\nAn important source for understanding Gödel’s advance\\ntoward a general theory of concepts are Gödel’s remarks on\\nconceptual analysis published by Hao Wang in .\\nIn remark 8.6.10 for example, Gödel expresses the belief that\\nextensionality fails for concepts, contrary to what he said in his\\n1944 “Russell’s Mathematical Logic,” a remark which\\nhe now wishes to retract:  \\nLogical Journey  \\nI do not (no longer) believe that generally sameness of range is\\nsufficient to exclude the distinctness of two concepts.  \\nIn some of Gödel’s later discussions another component of\\nconceptual analysis emerges, namely the project of finding the\\nso-called primitive terms or concepts, and their relations. These are\\nroughly terms or concepts which comprise a theoretical “starting\\npoint,” on the basis of their meaning being completely definite\\nand clear. For example, the concept of “the application of a\\nconcept to another concept” is a primitive term, along with\\n“force”. (Wang 1996, 9.1.29).  \\nHe spoke to Wang about the general project in 1972:  \\nPhenomenology is not the only approach. Another approach is to find a\\nlist of the main categories (e.g., causation, substance, action) and\\ntheir interrelations, which, however, are to be arrived at\\nphenomenologically. The task must be done in the right manner. (Wang\\n1996, 5.3.7).  \\nGödel spoke with Sue Toledo between 1972 and 1975 about the\\nproject of finding primitive terms, as well as other aspects of\\nphenomenology. See Toledo 2011. We discuss Gödel’s\\ninvolvement with phenomenology further in the supplementary document .  \\nGödel’s Turn to Phenomenology  \\nThe judgement levied upon Gödel’s rationalism by\\ncontemporary philosophers was a harsh one. (See for example Gödel\\n1995, pp. 303–4). Nevertheless Gödel himself remained\\noptimistic. As he commented to Wang:  \\nIt is not appropriate to say that philosophy as rigorous science is\\nnot realizable in the foreseeable future. Time is not the main factor;\\nit can happen anytime when the right idea appears. (Wang 1996,\\n4.3.14).  \\nGödel concluded his 1944 on a similarly optimistic note.  \\n3.2 Gödel’s Realism  \\nGödel’s realist views were formulated mostly in the context\\nof the foundations of mathematics and set theory.  \\nWe referred above the list “What I believe,” thought to\\nhave been written in 1960 or thereabouts. Out of 14 items, only two\\nrefer to realism, remarks 10 and 12:  \\nMaterialism is false.  \\nConcepts have an objective existence.  \\nGödel published his views on realism for the first time in his\\n1944. The following is one of his most quoted passages on the\\nsubject:  \\nClasses and concepts may, however, also be conceived as real objects,\\nnamely classes as “pluralities of things,” or as\\nstructures consisting of a plurality of things and concepts as the\\nproperties and relations of things existing independently of our\\ndefinitions and constructions.  \\nIt seems to me that the assumption of such objects is quite as\\nlegitimate as the assumption of physical bodies and there is quite as\\nmuch reason to believe in their existence. They are in the same sense\\nnecessary to obtain a satisfactory system of mathematics as physical\\nbodies are necessary for a satisfactory theory of our sense\\nperceptions and in both cases it is impossible to interpret the\\npropositions one wants to assert about these entities as propositions\\nabout the “data,” i.e., in the latter case the actually\\noccurring sense perceptions.  \\nGödel’s reference to the impossibility of interpreting\\nempirical laws, or more precisely, instantiations of them—the\\nstatements “one wants to assert,”—as statements\\nabout sense perceptions, is likely an endorsement of the (then)\\ncontemporary critique of phenomenalism. The critique was based on the\\nobservation that sense data are so inextricably bound up with the\\nconditions under which they are experienced, that no correspondence\\nbetween statements about those and the statements “we want to\\nassert” can be given (see Chisholm 1948 for example). More\\ngenerally Gödel was against verificationism, namely the idea that\\nthe meaning of a statement is its mode of verification.  \\nThe analogical point in the first part of the passage was amplified by\\nGödel in the draft manuscript “Is Mathematics a Syntax of\\nLanguage?”:  \\nIt is arbitrary to consider “This is red” an immediate\\ndatum, but not so to consider the proposition expressing modus ponens\\nor complete induction (or perhaps some simpler propositions from which\\nthe latter follows). (Gödel 1995, p. 359)  \\nSome writers have interpreted Gödel in this and similar passages\\npragmatically, attributing to him the view that because empirical\\nstatements are paradigmatic of successful reference, reference in the\\ncase of abstract concepts should be modelled causally. (See Maddy\\n1990.) Interpreting reference to objects this way,\\nit is argued, addresses the main difficulty associated with realism,\\nthe problem how we can come to have knowledge of abstract objects.\\nOthers have argued that Gödel had no paradigm case in mind; that\\nfor him both the empirical and the abstract case are either equally\\nproblematic, or equally unproblematic. (See Tait 1986.) The latter\\nview is referred to as epistemological parity in van Atten and Kennedy\\n2003. (See also Kennedy and van Atten 2004.)  \\nabstract  \\nIn his 1947 “What is Cantor’s Continuum Problem?”,\\nGödel expounds the view that in the case of meaningful\\npropositions of mathematics, there is always a fact of the matter to\\nbe decided in a yes or no fashion. This is a direct consequence of\\nrealism, for if there exists a domain of mathematical objects or\\nconcepts, then any meaningful proposition concerning them must be\\neither true or\\n false. The Continuum Hypothesis is Gödel’s example of a\\nmeaningful question. The concept “how many” leads\\n“unambiguously” to a definite meaning of the hypothesis,\\nand therefore it should be decidable—at least in principle. Most\\nstrikingly Gödel does not leave the matter there but goes on to\\noffer a practical strategy for determining the value of the continuum,\\nas well as the truth value of other axioms extending .\\nSpecifically, he offers two criteria for their decidability: the first\\ninvolves conceptual analysis and is associated with Gödel’s\\nrationalistic program. (See the above section on Gödel’s\\nrationalism.) Secondly one must keep an eye on the so-called success\\nof the axiom, as a check or indicator of which direction to look to\\nfor the solution of its truth. For example, Gödel notes in the\\npaper that none of the consequences of the Axiom of Constructibility\\nare very plausible. It is, then, likely false. See Maddy 2011 and\\nKoellner 2014 for discussion of intrinsic vs extrinsic justifications\\nfor new axioms of set theory.  \\n[ ]  \\n23  \\nZFC  \\nFor further discussion of Gödel’s philosophical views see\\nthe supplementary documents:  \\nGödel’s Turn to Phenomenology  \\nand  \\nA Philosophical Argument About the Content of Mathematics  \\nBibliography  \\nPrimary Sources  \\nGödel’s Writings  \\nThe Gödel Nachlass is located at Firestone Library of Princeton\\nUniversity with the exception of Gödel’s preprint\\ncollection, which is housed at the library of the Institute for\\nAdvanced Study. The Nachlass itself is the property of the Institute\\nbut a microfilm copy of it may be purchased from Brill. All of\\nGödel’s published work, together with a large number of the\\nunpublished material from the Nachlass, together with a selection of\\nGödel’s correspondence is published in .  \\nKurt Gödel,\\nCollected Works, Volumes I-V  \\nThe Collected Papers of Kurt Gödel  \\n1986, .\\nS. Feferman, S. Kleene, G. Moore, R. Solovay, and J. van Heijenoort\\n(eds.), Oxford: Oxford University Press.  \\nCollected Works. I: Publications 1929–1936  \\n1990, .\\nS. Feferman, J. Dawson, S. Kleene, G. Moore, R. Solovay, and J. van\\nHeijenoort (eds.), Oxford: Oxford University Press.  \\nCollected Works. II: Publications 1938–1974  \\n1995, . S. Feferman, J. Dawson, S. Kleene, G. Moore, R.\\nSolovay, and J. van Heijenoort (eds.), Oxford: Oxford University\\nPress.  \\nCollected Works. III: Unpublished essays and\\nlectures  \\n2003a, . S.\\nFeferman, J. Dawson, S. Kleene, G. Moore, R. Solovay, and J. van\\nHeijenoort (eds.), Oxford: Oxford University Press.  \\nCollected Works. IV: Correspondence A-G  \\n2003b, . S.\\nFeferman, J. Dawson, S. Kleene, G. Moore, R. Solovay, and J. van\\nHeijenoort (eds.), Oxford: Oxford University Press.  \\nCollected Works. V: Correspondence H-Z  \\nSelected Works of Kurt Gödel  \\n[1929]  \\n“I”, . Reprinted in Gödel 1986, pp. 60–101.  \\nDissertation, University of\\nVienna  \\n[1930]  \\n“Die Vollständigkeit der Axiome des\\nlogischen Funktionenkalküls”, , 37: 349–360. Reprinted in Gödel\\n1986, pp. 102–123.  \\nMonatshefte für\\nMathematik und Physik  \\n[1931]  \\n“Über formal unentscheidbare Sätze\\nder Principia Mathematica und verwandter Systeme, I”, , 38:\\n173–198. Reprinted in Gödel 1986, pp. 144–195.  \\nMonatshefte für Mathematik und Physik  \\n[1932]  \\n“Zum intuitionistischen\\nAussagenkalkül”, , 69: 65–66. Reprinted in Gödel\\n1986, pp. 222–225.  \\nAnzeiger der Akademie der\\nWissenschaften in Wien  \\n[1933e]  \\n“Zur intuitionistischen Arithmetik und\\nZahlentheorie”, , 4: 34–38. Reprinted in Gödel 1986, pp.\\n286–295.  \\nErgebnisse eines mathematischen\\nKolloquiums  \\n[1933f]  \\n“Eine Interpretation des intuitionistischen\\nAussagenkalküls”, 4, 39–40. Reprinted in Gödel 1986, pp.\\n300–301.  \\nErgebnisse eines mathematischen\\nKolloquiums  \\n[1933i]  \\n“Zum Entscheidungsproblem des logischen\\nFunctionenkalküls”, , 40: 433–443. Reprinted in Gödel 1986, pp.\\n306–326.  \\nMonatshefte für Mathematik und\\nPhysik  \\n[*1933o]  \\n“The present situation in the foundations of\\nmathematics”, manuscript. Printed in Gödel 1995, pp.\\n45–53.  \\n[1934c]  \\nReview of Skolem (1933). , 7: 193–194. Reprinted in\\nGödel 1986, pp. 379–380.  \\nZentralblatt für\\nMathematik und ihre Grenzgebiete  \\n[1936a]  \\n“Über die Länge von\\nBeweisen”, ,\\n7: 23–24. Reprinted in Gödel 1986, pp. 395–399.  \\nErgebnisse eines mathematischen Kolloquiums  \\n[1939a]  \\n“Consistency proof for the generalized\\ncontinuum hypothesis”, , 25: 220–224. Reprinted in Gödel\\n1990, pp. 28–32.  \\nProceedings of the National Academy\\nof Sciences, U.S.A.  \\n[1940]  \\n“The Consistency of the Continuum\\nHypothesis”, , Volume 3,\\nPrinceton: Princeton University Press. Reprinted in Gödel 1990,\\npp. 33–101.  \\nAnnals of Mathematics Studies  \\n[*1941]  \\n“In what sense is intuitionistic logic\\nconstructive?”, lecture manuscript. Printed in Gödel 1995,\\npp. 189–200.  \\n[1944]  \\n“Russell’s mathematical logic”, (Library of Living\\nPhilosophers), P. Schilpp (ed.), New York: Tudor, 1951, pp.\\n123–153. Reprinted in Gödel 1990, pp. 119–141.  \\nThe Philosophy of Bertrand Russell  \\n[*1946/9-B2]  \\n“Some observations about the relationship\\nbetween theory of relativity and Kantian philosophy”,\\nmanuscript. Printed in Gödel 1995, pp. 230–246.  \\n[*1946/9-C1]  \\n“Some observations about the relationship\\nbetween theory of relativity and Kantian philosophy”,\\nmanuscript. Printed in Gödel 1995, pp. 247–259.  \\n[1947]  \\n“What is Cantor’s continuum\\nproblem?”, , 54: 515–525.\\nReprinted in Gödel 1990, pp. 176–187.  \\nAmer. Math. Monthly  \\n[1949a]  \\n“A remark on the relationship between\\nrelativity theory and idealistic philosophy”, (Library of Living Philosophers),\\nP. Schilpp (ed.), La Salle, IL: Open Court, 1949, pp. 555–562.\\nReprinted in Gödel 1990, pp. 202–207.  \\nAlbert\\nEinstein: Philosopher-Scientist  \\n[1949]  \\n“An Example of a New Type of Cosmological\\nSolutions of Einstein’s Field Equations of Gravitation,” , 21: 447–450. Reprinted in\\nGödel 1990, pp. 190–198.  \\nReviews of Modern Physics  \\n[*1951]  \\n“Some basic theorems on the foundations of\\nmathematics and their implications”, lecture manuscript. Printed\\nin Gödel 1995, pp. 304–323.  \\n[*1953/9-III]  \\n“Is mathematics a syntax of language?”,\\nlecture manuscript. Printed in Gödel 1995, pp.\\n334–356.  \\n[*1953/9-V]  \\n“Is mathematics a syntax of language?,”\\nlecture manuscript. Printed in Gödel 1995, pp.\\n356–362.  \\n[1958]  \\n“Über eine bisher noch nicht\\nbenützte Erweiterung des finiten Standpunktes”, , 12: 280–287. Reprinted in Gödel 1990,\\npp. 240–251.  \\nDialectica  \\n[*1961/?]  \\n“The modern development of the foundations of\\nmathematics in light of philosophy”, manuscript. Printed in\\nGödel 1995, pp. 374–387.  \\n[1964]  \\n“What is Cantor’s continuum\\nproblem? , revised version of Gödel 1947, in\\nBenacerraf, P. and Putnam, H. (eds.), 1983, , Cambridge: Cambridge\\nUniversity Press. Reprinted in Gödel 1990, pp.\\n254–270.  \\n”  \\nPhilosophy of\\nmathematics: selected readings (2nd ed.)  \\n[*1970]  \\n“Ontological proof”, manuscript.\\nPrinted in Gödel 1995, pp. 403–404.  \\n[*1970a]  \\n“Some considerations leading to the probable\\nconclusion that the true power of the continuum is\\nℵ ”, manuscript. Printed in Gödel 1995,\\npp. 420–422.  \\n2  \\n[*1970b]  \\n“A proof of Cantor’s continuum\\nhypothesis from a highly plausible axioms about orders of\\ngrowth”, manuscript. Printed in Gödel 1995, pp.\\n422–423.  \\nSecondary Sources  \\nAvigad, J. and S. Feferman, 1998, “Gödel’s\\nFunctional (‘Dialectica’) Interpretation”, in (Studies in Logic and the\\nFoundations of Mathematics, Volume 137), Samuel Buss (ed.), Amsterdam:\\nNorth-Holland, pp. 337-405.  \\nHandbook of Proof Theory  \\nAwodey, S. and A. W. Carus, 2010, “Gödel and\\nCarnap”, in ,\\nSolomon Feferman, Charles Parsons & Stephen G. Simpson (eds.),\\nCambridge: Cambridge University Press.  \\nKurt Gödel: Essays for his Centennial  \\nBaaz, M., and C. Papadimitriou, D.Scott, H. Putnam, and C. Harper\\n(eds.), 2011, , Cambridge: Cambridge University Press.  \\nKurt Gödel and the Foundations of Mathematics:\\nHorizons of Truth  \\nBadesa, C., and P. Mancosu, and R. Zach, 2009, “The\\nDevelopment of Mathematical Logic from Russell to Tarski,\\n1900–1935”, in Leila Haaparanta (ed.), . New York and Oxford: Oxford University\\nPress:318–470..  \\nThe History of\\nModern Logic  \\nBarwise, Jon (ed.), 1977, (Studies in Logic and the Foundations of Mathematics, Volume 90),\\nAmsterdam: North-Holland Publishing Co.  \\nHandbook of Mathematical Logic  \\nBehmann, Heinrich, 1922, “Beiträge, Algebra, Logik,\\ninsbesodere zum Entscheidungsproblem”, , 86: 419–432.  \\nMathematische\\nAnnalen  \\nBenacerraf, P. and H. Putnam (eds.), 1983, , Cambridge: Cambridge University\\nPress, 2nd edition.  \\nPhilosophy of\\nMathematics: Selected Readings  \\nBernays, Paul, 1926, “Axiomatische Untersuchung des\\nAussagen-Kalkuls der ‘Principia Mathematica’”, , 25(1): 305–320.  \\nMathematisches Zeitschrift  \\nBezboruah, A., and J.C. Sheperdson, 1976,\\n“Gödel’s second incompleteness theorem for\\n\\\\(Q\\\\)”, , 41 (2):\\n503–512.  \\nJournal of Symbolic Logic  \\nBolzano, Bernard, 1969, , Sections\\n349–391, in ,\\nReihe I/Band 13, edited and with an introduction by Jan Berg,\\nStuttgart-Bad Cannstatt: Frommann Holzboog.  \\nWissenschaftslehre  \\nBernard Bolzano — Gesamtausgabe  \\nBurgess, John, 2009, “”Intuitions of Three Kinds in\\nGödel’s Views on the Continuum“”, in Kennedy, J. (ed.) Cambridge: Cambridge\\nUniversity Press, 2014.  \\nInterpreting Gödel  \\nBuss, Samuel R., 1994, “On Gödel’s Theorems on\\nLengths of Proofs. I. Number of Lines and Speedup for\\nArithmetics”, , 59(3):\\n737–756.  \\nJournal of Symbolic Logic  \\nChisholm, R., 1948, “The Problem of Empiricism”, , 45: 512–7.  \\nThe Journal of Philosophy  \\nCohen, Paul, 1963, “The Independence of the Continuum\\nHypothesis”, , 50: 1143–1148.  \\nProceedings of the National Academy of Sciences\\nof the U.S.A.  \\nCrocco, G., 2003, “Gödel, Carnap and the Fregean\\nHeritage”, , 27:\\n171–191.  \\nHistory and Philosophy of Logic  \\n–––, 2006, “Gödel on Concepts”, , 137(1,2): 21–41.  \\nSynthese  \\nDawson, Jr., John W., 1997, , Wellesley, MA: A. K. Peters, Ltd.  \\nLogical dilemmas: The Life and\\nWork of Kurt Gödel  \\nDehornoy, Patrick, 2004, “Progrès récents sur\\nl’hypothèse du continu (d’après\\nWoodin)”, , 294: viii,\\n147–172.  \\nAstérisque  \\nDetlefsen, Michael, 1986, , Dordrecht: D. Reidel.  \\nHilbert’s Program: An essay on\\nmathematical instrumentalism  \\n–––, 2001, “What Does Gödel’s\\nSecond theorem Say?”, , 9(1):\\n37–71.  \\nPhilosophia Mathemathica  \\n–––, 2014, “Completeness and the Ends of\\nAxiomatization”, in , Kennedy,\\nJ. (ed.) Cambridge: Cambridge University Press, 2014.  \\nInterpreting Gödel  \\nDreben, B. and J. van Heijenoort, 1986, “Introductory Note\\nto 1929, 1930 and 1930a”, in Gödel 1986, pp.\\n44–59.  \\nEdwards, Paul (ed.), 1967, , New York: MacMillan.  \\nThe Encyclopedia of\\nPhilosophy  \\nEhrenfeucht, A. and J. Mycielski, 1971, “Abbreviating Proofs\\nby Adding New Axioms”, , 77: 366–367.  \\nBulletin of the American Mathematical\\nSociety  \\nFeferman, Solomon, 1960/1961, “Arithmetization of\\nMetamathematics in a General Setting”, , 49: 35–92.  \\nFundamenta\\nMathematicae  \\n–––, 1993, “Gödel’s Dialectica\\nInterpretation and Its Two-way Stretch”, in (Lecture Notes in Computer Science, Volume\\n713), G. Gottlob, A. Leitsch, and D. Mundici (eds.), Berlin: Springer,\\npp. 23–40.  \\nComputational\\nLogic and Proof Theory  \\n–––, 1986, “Gödel’s Life and\\nWork”, in Gödel 1986, pp. 1–34.  \\n–––, 1988, “Hilbert’s Program\\nRelativized: Proof-Theoretical and Foundational Reductions”, , 53: 364–384.  \\nJournal of Symbolic Logic  \\n–––, 1996, “Proof Theory”, in , D. Borchrt (ed.),\\nNew York: MacMillan, pp. 466–469.  \\nThe Encyclopedia of Philosophy Supplement  \\nFeferman, S., and H. Friedman, P. Maddy, and J. Steel, 2000,\\n“Does Mathematics Need New Axioms?”, , 6(4): 401–446.  \\nBulletin of\\nSymbolic Logic  \\nFeferman, S., C. Parsons, and S. Simpson (eds.), 2010, (Lecture Notes in Logic,\\n33), Cambridge: Cambridge University Press.  \\nKurt\\nGödel: Essays for his Centennial  \\nFeigl, H. and A. Blumberg, 1931, “Logical Positivism. A New\\nMovement in European Philosophy”, , 28: 281–296.  \\nJournal of\\nPhilosophy  \\nFloyd, J. and A. Kanamori, 2006, “How Gödel Transformed\\nSet Theory”, , 53(4): 419–427.  \\nNotices of the American Mathematical\\nSociety  \\nFolina, Janet, 2014, “Gödel on How to Have your\\nMathematics and Know it Too”, in , Kennedy, J. (ed.) Cambridge: Cambridge University\\nPress, 2014.  \\nInterpreting\\nGödel  \\nFøllesdal, Dagfinn, 1995, “Gödel and\\nHusserl”, in (Synthese\\nLibrary, Volume 251), J. Hintikka (ed.), Dordrecht, Boston: Kluwer,\\npp. 427–446.  \\nFrom Dedekind to Gödel  \\nForeman, Matthew, 1998, “Generic Large Cardinals: New Axioms\\nfor Mathematics?”, in , Extra\\nVolume, Proceedings of the International Congress of Mathematicians,\\nII, pp. 11–21\\n [ (in compressed Postscript)].  \\nDocumenta Mathematica  \\navailable online  \\nFranks, Curtis, 2009, “The Autonomy of Mathematical\\nKnowledge: Hilbert’s Program Revisited”, Cambridge:\\nCambridge University Press.  \\n–––, 2011, “Stanley Tennenbaum’s\\nSocrates”, in , Kennedy, J. and Kossak, R.,\\n(eds.), Lecture Notes in Logic, 36, Cambridge: Cambridge University\\nPress, 2011.  \\nSet Theory, Arithmetic and Foundations of\\nMathematics: Theorems, Philosophies  \\n–––, 2014, “Logical Completeness, Form and\\nContent: An Archaeology”, in ,\\nKennedy, J. (ed.) Cambridge: Cambridge University Press, 2014.  \\nInterpreting Gödel  \\nGaifman, H., 2000, “What Godel’s Incompleteness Result\\nDoes and Does Not Show”, , 97 (8):\\n462–471.  \\nJournal of Philosophy  \\nGarson, James, 2003, “Modal Logic”, in , Fall 2003 Edition, Edward N.\\nZalta (ed.), URL =\\n < >.  \\nThe\\nStanford Encyclopedia of Philosophy  \\nhttps://plato.stanford.edu/archives/fall2003/entries/logic-modal/  \\nGlivenko, V., 1929, “Sur quelques points de la logique de m.\\nBrouwer.”, , 15: 183–188.  \\nAcadémie Royale de Belgique, Bulletin de\\nla Classe des Sciences  \\nGottwald, Siegfried, 2004, “Many-valued Logic”, in , Winter 2004 Edition,\\nEdward N. Zalta (ed.), URL =\\n < >.  \\nThe Stanford Encyclopedia of Philosophy  \\nhttps://plato.stanford.edu/archives/win2004/entries/logic-manyvalued/  \\nGödel, Rudolf, 1983, “History of the Gödel\\nFamily”, Susan Simonsin (trans.), in Weingartner and Schmetterer\\n1987, pp. 11–27.  \\nHauser, Kai, 2006, “Gödel’s Program Revisited,\\nPart 1: the Turn to Phenomenology”, , 12 (4): 529–590.  \\nBulletin of Symbolic\\nLogic  \\nHeyting, Arendt, 1930, “Die formalen Regeln der\\nintuitionistischen Logik”, ,\\nII, pp. 42–56.  \\nSitzungsberichte der Preussischen\\nAkademie der Wissenschaften, physikalisch-mathematische Klasse  \\nHilbert, David, 1926, “Über das Unendliche”, , 95: 161–190.  \\nMathematische Annalen  \\nHilbert, D. and W. Ackermann, 1928, , Berlin: Springer-Verlag.  \\nGrundzüge der\\ntheoretischen Logik  \\nHilbert, D. and P. Bernays, 1934, , Volume 1, Berlin: Springer-Verlag.  \\nGrundlagen der\\nMathematik  \\n–––, 1939, ,\\nVolume II, Berlin: Springer-Verlag.  \\nGrundlagen der Mathematik  \\nHodges, Wilfrid, 2005, “Model Theory”, in , Fall 2005 Edition, Edward N.\\nZalta (ed.), URL =\\n < >.  \\nThe\\nStanford Encyclopedia of Philosophy  \\nhttps://plato.stanford.edu/archives/fall2005/entries/model-theory/  \\nHusserl, Edmund, 1911, “Philosophie als strenge\\nWissenschaft”, , 1: 289–341.  \\nLogos  \\nJaśkowski, Stanisław, 1936, “Investigations into\\nthe System of Intuitionist Logic”, , 34(2)\\n(1975): 117–120. (Translated by S. McCall from the French\\n“Rechereches sur le système de la logique\\nintuitioniste” in , Volume VI, Hermann, Paris, 1936, pp.\\n58–61.)  \\nStudia Logica  \\nActes du Congrés International de\\nPhilosophie Scientifique  \\nJech, Thomas, 2003, , (Springer Monographs in\\nMathematics), Berlin: Springer-Verlag. 3rd millennium edition, revised\\nand expanded.  \\nSet theory  \\nJensen, R. Björn, 1972, “The Fine Structure of the\\nConstructible Hierarchy” (with a section by Jack Silver), , 4: 229–308; Erratum, 4\\n(1972): 443.  \\nAnnals of Mathematical Logic  \\nKanamori, Aki, 1996, “The Mathematical Development of Set\\ntheory from Cantor to Cohen.” , 2(1): 1–71.  \\nBulletin of Symbolic\\nLogic  \\n–––, 2006, “Levy and Set Theory”, , 140(3): 233–252.  \\nAnnals of Pure and Applied Logic  \\nKennedy, Juliette, 2006, “Incompleteness — A Book\\nReview,” ,\\n53(4): 448–455.  \\nNotices of the American Mathematical Societ  \\n–––, 2011, “Gödel’s Thesis: An\\nAppreciation” in , M. Baaz, C. Papadimitriou, D.\\nScott, H. Putnam, and C. Harper (eds.), Cambridge: Cambridge\\nUniversity Press 95–110.  \\nKurt Gödel and the Foundations of\\nMathematics: Horizons of Truth  \\n–––, 2013, “On Formalism Freeness:\\nImplementing Gödel’s 1946 Princeton Bicentennial\\nLecture”, , 19(3):\\n351–393.  \\nBulletin of Symbolic Logic  \\n–––, 2014, “Gödel’s 1946\\nPrinceton Bicentennial Lecture: An Appreciation”, in , Cambridge:\\nCambridge University Press.  \\nInterpreting Gödel: Critical Essays  \\nKennedy, Juliette (ed.), 2014, , Cambridge: Cambridge University Press.  \\nInterpreting Gödel:\\nCritical Essays  \\nKennedy, J. and van Atten, M., 2003, “On the Philosophical\\nDevelopment of Kurt Gödel”, , 9(4): 425–476. Reprinted in , Solomon Feferman, Charles Parsons and\\nStephen G. Simpson (eds.), Cambridge: Cambridge University Press.  \\nBulletin of Symbolic\\nLogic  \\nKurt Gödel:\\nEssays for his Centennial  \\n–––, 2004, “Gödel’s Modernism:\\nOn Set-theoretic Incompleteness”, , 25(2): 289–349. (See the Erratum in , 26(1) (2005), page\\nfacing contents.)  \\nGraduate Faculty\\nPhilosophy Journal  \\nGraduate Faculty Philosophy Journal  \\n–––, 2009, “Gödel’s Modernism:\\nOn Set-theoretic Incompleteness, Revisited”, in , S.\\nLinström, E. Palmgren, K. Segerberg, and V. Stoltenberg-Hansen\\n(eds.), Berlin: Springer: 303–356.  \\nLogicism,\\nIntuitionism and Formalism: What has become of them?  \\n–––, 2009, “Gödel’s\\nLogic”, in D. Gabbay and J. Woods (eds.), , Volume 5,\\nAmsterdam: Elsevier: 449–509.  \\nThe Handbook of\\nthe History of Logic: Logic from Russell to Gödel  \\nKleene, S. C., 1987, “Gödel’s Impression on\\nStudents of Logic in the 1930s”, in Weingartner and Schmetterer\\n1987, pp. 49–64.  \\nKoellner, Peter, 2014, “Large Cardinals and\\nDeterminacy”, (Spring Edition), Edward N. Zalta (ed.), URL =\\n < >.  \\nThe Stanford Encyclopedia of Philosophy  \\nhttps://plato.stanford.edu/archives/spr2014/entries/large-cardinals-determinacy/  \\nKreisel, Georg, 1980, “Kurt Gödel, 28 April 1906\\n– 14 January 1978”, , 26: 148–224. Corrigenda, 27 (1981): 697;\\nfurther corrigenda, 28 (1982): 697.  \\nBiographical Memoirs of Fellows of\\nthe Royal Society  \\n–––, 1988, “Review of Kurt Gödel: , Volume I”, , 29(1): 160–181.  \\nCollected works  \\nNotre Dame Journal of\\nFormal Logic  \\n–––, 1990, “Review of Kurt Gödel: , Volume II”, , 31(4): 602–641.  \\nCollected Works  \\nNotre Dame Journal of\\nFormal Logic  \\n–––, 1998, “Second Thoughts Around Some of\\nGödel’s Writings: A Non-academic Option”, , 114(1): 99–160.  \\nSynthese  \\nKripke, Saul, 2009, “The collapse of the Hilbert program:\\nwhy a system cannot prove its own 1-consistency”, , 15 (2): 229–231.  \\nBulletin\\nof Symbolic Logic  \\nKunen, Kenneth, 1983, , (Studies in Logic and the Foundations of\\nMathematics, Volume 102), Amsterdam: North-Holland Publishing Co.\\nReprint of the 1980 original.  \\nSet Theory: An Introduction to\\nIndependence Proofs  \\nLöb, M. H., 1956, “Formal Systems of Constructive\\nMathematics”, , 21:\\n63–75.  \\nJournal of Symbolic Logic  \\nLöwenheim, L., 1915, “Über Möglichkeiten im\\nRelativkalkül”, , 76(4):\\n447–470.  \\nMathematische Annalen  \\nŁukasiewicz, Jan, 1970, , (Studies in\\nLogic and the Foundations of Mathematics), L. Borkowski (ed.),\\nAmsterdam: North-Holland Publishing Co.  \\nSelected works  \\nMaddy, Penelope, 1990, , New York:\\nClarendon Press.  \\nRealism in Mathematics  \\nMaddy, Penelope, 2011, , Oxford:\\nOxford University Press.  \\nDefending the Axioms  \\nMal’cev, Anatoli Ivanovic, 1971, (Studies in\\nLogic and the Foundations of Mathematics, Volume 66), translated,\\nedited, and provided with supplementary notes by Benjamin Franklin\\nWells, III, Amsterdam: North-Holland Publishing Co.  \\nThe Metamathematics of\\nAlgebraic Systems. Collected Papers: 1936–1967  \\nMancosu, Paolo, 1998, , Oxford: Oxford\\nUniversity Press.  \\nFrom Brouwer to Hilbert. The Debate on\\nthe Foundations of Mathematics in the 1920s  \\n–––, 2004, “Review of Kurt Gödel, , Volumes IV and V”, , 45: 109–125.  \\nCollected Works  \\nNotre Dame\\nJournal of Formal Logic  \\nMartin, D.A., 2005, “Gödel’s Conceptual\\nRealism”, , 11:\\n207–224.  \\nBulletin of Symbolic Logic  \\nMcKinsey, J. C. C. and A. Tarski, 1948, “Some Theorems About\\nthe Sentential Calculi of Lewis and Heyting”, , 13: 1–15.  \\nJournal of\\nSymbolic Logic  \\nMostowski, Andrzej, 1949, “An Undecidable Arithmetical\\nStatement”, , 36:\\n143–164.  \\nFundamenta Mathematicae  \\n–––, 1982, , Westport, CT: Greenwood Press. Reprint of the 1952\\noriginal.  \\nSentences Undecidable in\\nFormalized Arithmetic: An Exposition of the Theory of Kurt\\nGödel  \\nOliva, Paulo, 2006, “Unifying Functional\\nInterpretations”, ,\\n47(2): 263–290.  \\nNotre Dame Journal of Formal Logic  \\nParikh, Rohit, 1971, “Existence and Feasibility in\\nArithmetic”, , 36:\\n494–508.  \\nJournal of Symbolic Logic  \\nParsons, Charles, 1995a, “Platonism and Mathematical\\nIntuition in Kurt Gödel’s Thought”, , 1(1): 44–74.  \\nBulletin of\\nSymbolic Logic  \\n–––, 1995b, “Quine and Gödel on\\nAnalyticity”, in , Cambridge:\\nCambridge University Press, pp. 297–313.  \\nOn Quine: New Essays  \\n–––, 2000, “Reason and Intuition”, , 125(3): 299–315.  \\nSynthese  \\n–––, 2002, “Realism and the Debate on\\nImpredicativity, 1917–1944”, in ,\\n(Lecture Notes in Logic, Volume 15), W. Sieg, R. Sommer, and C.\\nTalcott (eds.), Urbana, IL: Association of Symbolic Logic, pp.\\n372–389.  \\nReflections on the\\nFoundations of Mathematics: Essays in Honor of Solomon Feferman  \\n–––, 2010, “Gödel and Philosophical\\nIdealism” , 18 (2):\\n166–192.  \\nPhilosophia Mathematica  \\n–––, 2014, “Analyticity for\\nRealists”, in , Kennedy, J.\\n(ed.) Cambridge: Cambridge University Press, 2014.  \\nInterpreting Gödel  \\nPoonen, Bjorn, 2014, “Undecidable Problems: A\\nSampler”, in ,\\nCambridge: Cambridge University Press.  \\nInterpreting Gödel: Critical Essays  \\nPost, Emil L., 1921, “Introduction to a General Theory of\\nElementary Propositions”, , 43(3): 163–185.  \\nAmerican Journal of\\nMathematics  \\nPudlák, Pavel, 1996, “On the lengths of proofs of\\nconsistency: a survey of results”, , 2: 65-86.  \\nAnnals of the Kurt\\nGödel Society  \\nRaatikainen, P., 2005, “On the Philosophical Relevance of\\nGödel’s Incompleteness Theorems”, , 59 (4): 513–534.  \\nRevue\\nInternationale de Philosophie  \\nRogers, Jr., Hartley, 1967, , New York: McGraw-Hill Book Co.  \\nTheory of Recursive Functions and\\nEffective Computability  \\nRosser, J.B., 1936, “Extensions of Some Theorems of\\nGödel and Church”, ,\\n1(3): 87–91.  \\nJournal of Symbolic Logic  \\nScott, Dana, 1961, “Measurable Cardinals and Constructible\\nSets”, (Série des Science, Mathématiques,\\nAstronomiques et Physiques), 9: 521–524.  \\nBulleint de l’Academie Polonaise des\\nSciences  \\nShelah, Saharon, 2014, “Reflecting on Logical Dreams”,\\nin , Cambridge:\\nCambridge University Press.  \\nInterpreting Gödel: Critical Essays  \\nSieg, Wilfried, 1988, “Hilbert’s Program Sixty Years\\nLater”, , 53(2):\\n338–348.  \\nJournal of Symbolic Logic  \\n–––, 1990, “Relative Consistency and\\nAccessible Domains”, , 84(2):\\n259–297.  \\nSynthese  \\n–––, 1999, “Hilbert’s Programs:\\n1917–1922”, , 5(1):\\n1–44.  \\nBulletin of Symbolic Logic  \\n–––, 2006, “Gödel on\\nComputability”, , 14:\\n189–207.  \\nPhilosophia Mathematica  \\nSierpinski, Wacław, 1947, “L’hypothèse\\ngénéralisée du continu et l’axiome du\\nchoix”, , 34: 1–5.  \\nFundamenta Mathematicae  \\nSigmund, Karl, 2006, “Pictures at an Exhibition”, , 53(4):\\n428–432.  \\nNotices of the American Mathematical Society  \\nSkolem, Thoralf, 1920, “Logisch-kombinatorische\\nUntersuchungen über die Erfüllbarkeit oder Beweisbarkeit\\nmathematischer Sätze nebst einem Theoreme über dichte\\nMengen”, , I. ,\\nNumber 4, pp. 1–36. Reprinted in Skolem 1970, pp.\\n103–136.  \\nSkrifter utgit av Videnskappsselskapet i\\nKristiania  \\nMatematisk-naturvidenskabelig klasse  \\n–––, 1923, “Einige Bemerkungen zur\\naxiomatischen Begründung der Mengenlehre”, ,\\nHelsinki, pp. 217–232. Reprinted in Skolem 1970, pp.\\n137–152.  \\nMatematikerkongressen i Helsingfors den 4–7 Juli 1922, Den\\nfemte skandinaviska matematikerkongressen, Redogörelse  \\n–––, 1933, “Über die\\nUnmöglichkeit einer vollständigen Charakterisierung der\\nZahlenreihe mittels eines endlichen Axiomensystems”, , 10: 73–82.  \\nNorsk\\nMatematisk forenings skrifter  \\n–––, 1970, ,\\nJens Erik Fenstad (ed.), Oslo: Universitetsforlaget.  \\nSelected Works in Logic  \\nSmith, David Woodruff, 2005, “Phenomenology”, in (Winter Edition),\\nEdward N. Zalta (ed.), URL =\\n < >.  \\nThe Stanford Encyclopedia of Philosophy  \\nhttps://plato.stanford.edu/archives/win2005/entries/phenomenology/  \\nSolovay, Robert, 1990, “Introductory Note to 1938, 1939,\\n1939a, 1940”, in Gödel 1990, pp. 1–25.  \\nSteel, John, 2000, “Mathematics Needs New Axioms”, , 6(4): 422–433.  \\nBulletin of Symbolic Logic  \\nSteel, John, 2014, “Gödel’s Program”, in , Kennedy, J. (ed.) Cambridge:\\nCambridge University Press, 2014.  \\nInterpreting Gödel  \\nTait, William, 1967, “Intensional Interpretations of\\nFunctionals of Finite Type I,” , 32(2): 198–212.  \\nJournal of Symbolic\\nLogic  \\n–––, 1981, “Finitism”, , 78: 524–556. Reprinted in Tait 2005, pp.\\n21–42.  \\nJournal\\nof Philosophy  \\n–––, 1986, “Truth and Proof: The Platonism\\nof Mathematics”, , 69(3): 341–370.\\nReprinted in Tait 2005, pp. 61–88.  \\nSynthese  \\n–––, 2001, “Gödel’s Unpublished\\nPapers on Foundations of Mathematics”, , 9(1): 87–126. Reprinted in Tait 2005, pp.\\n276–313.  \\nPhilosophia\\nMathematica  \\n–––, 2002, “Remarks on Finitism”, in (Lecture Notes in Logic, Volume 15), W. Sieg, R.\\nSommer, and C. Talcott (eds.), Urbana, IL: Association of Symbolic\\nLogic, pp. 410–419. Reprinted in Tait 2005, pp.\\n43–53.  \\nReflections on the Foundations of Mathematics: Essays in Honor of\\nSolomon Feferman  \\n–––, 2005, (Logic\\nand Computation in Philosophy), New York: Oxford University\\nPress.  \\nThe Provenance of Pure Reason:\\nEssays in the Philosophy of Mathematics and its History  \\n–––, 2006, “Gödel’s\\ncorrespondence on proof theory and constructive\\nmathematics” , 14 (1):\\n76–111.  \\nPhilosophia Mathematica  \\n–––, 2006, “Gödel’s\\ninterpretation of intuitionism”, , 14 (2): 208–228.  \\nPhilosophia\\nMathematica  \\nTaussky-Todd, Olga, 1983, “Remembrances of Kurt\\nGödel”, in Weingartner and Schmetterer 1987, pp.\\n29–41.  \\nTieszen, Richard, 1992, “Kurt Gödel and\\nPhenomenology”, , 59(2):\\n176–194.  \\nPhilosophy of Science  \\n–––, 2002, “Gödel and the Intuition\\nof Concepts”, , 133 (3): 363–391.  \\nSynthese  \\n–––, 2005, , Cambridge: Cambridge University\\nPress.  \\nPhenomenology, Logic and the\\nPhilosophy of Mathematics  \\n–––, 2011, , Oxford: Oxford University\\nPress.  \\nAfter Gödel: Platonism and\\nRationalism in Mathematics and Logic  \\nToledo, Sue, 2011, “Sue Toledo’s Notes of her\\nConversations with Kurt Gödel in 1972-5”, in (Lecture Notes in Logic, 36), Kennedy, J. and\\nKossak, R., (eds.), Cambridge: Cambridge University Press,\\nforthcoming.  \\nSet\\nTheory, Arithmetic and Foundations of Mathematics: Theorems,\\nPhilosophies  \\nTragesser, Robert, 1977, , Ithaca:\\nCornell University Press.  \\nPhenomenology and Logic  \\n–––, 1984, , (Series: Modern European Philosophy), Cambridge:\\nCambridge University Press.  \\nHusserl and Realism in Logic and\\nMathematics  \\n–––, 1989, “Sense Perceptual Intuition,\\nMathematical Existence, and Logical Imagination”, , 4(2): 154–194.  \\nPhilosphia\\nMathematica  \\nTroelstra, A. S., 1986, “Note to and ”, in Gödel 1990, pp. 217–241.  \\n1958  \\n1972  \\nTroelstra, A. S. (ed.), 1973, , (Lecture Notes in\\nMathematics, Volume 344), Berlin: Springer-Verlag.  \\nMetamathematical Investigation\\nof Intuitionistic Arithmetic and Analysis  \\nTuring, A. M., 1937, “On Computable Numbers, with an\\nApplication to the Entscheidungsproblem”, (Series 2), 42: 230–265.  \\nProceedings of the\\nLondon Mathematical Society  \\nvan Atten, Mark, 2005, “On Gödel’s Awareness of\\nSkolem’s Helsinki Lecture”, , 26(4): 321–326.  \\nHistory and Philosophy of\\nLogic  \\n–––, 2006, “Two Draft Letters from\\nGödel on Self-knowledge of Reason”, , 14(2): 255–261.  \\nPhilosophia\\nMathematica  \\n–––, 2015, “Essays on Gödel’s\\nReception of Leibniz, Husserl and Brouwer”, Springer.  \\nvan Heijenoort, J. (ed.), 1967, , Cambridge, MA:\\nHarvard University Press.  \\nFrom Frege to Gödel: A\\nsourcebook in mathematical logic, 1879–1931  \\nvan Oosten, Jaap, 2008, (Studies in Logic and Foundations of\\nMathematics: Volume 152), Amsterdam: Elsevier.  \\nRealizability: An Introduction to its\\nCategorical Side  \\nvon Neumann, John, 2005, (History of Mathematics, Volume 27), foreword by P. Lax,\\nintroduction by Marina von Neumann Whitman, preface and introductory\\ncomments by Miklós Rédei (ed.), Providence, RI: American\\nMathematical Society.  \\nJohn von Neumann: Selected\\nLetters  \\nVäänänen, Jouko, 2014, “Multiverse Set Theory\\nand Absolutely Undecidable Propositions”, in , J. Kennedy (ed.), Cambridge: Cambridge University\\nPress, 2014.  \\nInterpreting\\nGödel  \\nWang, Hao, 1957, “The Axiomatization of Arithmetic”, , 22: 145–158.  \\nJournal of Symbolic Logic  \\n–––, 1973, , London: Routledge.  \\nFrom Mathematics to\\nPhilosophy  \\n–––, 1981, “Some Facts about Kurt\\nGödel”, , 46(3):\\n653–659.  \\nJournal of Symbolic Logic  \\n–––, 1987, , Cambridge, MA: MIT Press.  \\nReflections on Kurt\\nGödel  \\n–––, 1993, , New York: Dover Publications Inc., 2nd edition.  \\nPopular Lectures on Mathematical\\nLogic  \\n–––, 1996, (Representation and Mind), Cambridge,\\nMA: MIT Press.  \\nA Logical Lourney: From\\nGödel to Philosophy  \\nWeingartner, P., and L. Schmetterer (eds.), 1987, , (History of Logic,\\nNumber 4), Naples: Bibliopolis.  \\nGödel\\nRemembered: Salzburg 10–12 July 1983  \\nWilkie, Alex, and J.B. Paris, 1987, “On the scheme of\\ninduction for bounded arithmetic formulas”, 35:\\n261–302.  \\nWoodin, W. Hugh, 1988, “Supercompact Cardinals, Sets of\\nReals, and Weakly Homogeneous Trees”, , 85(18):\\n6587–6591.  \\nProceedings of the\\nNational Academy of Sciences of the U.S.A.  \\n–––, 2001a, “The Continuum Hypothesis.\\nI”, ,\\n48(6): 567–576.  \\nNotices of the American Mathematical Society  \\n–––, 2001b, “The Continuum Hypothesis.\\nII”, ,\\n48(7): 681–690.  \\nNotices of the American Mathematical Society  \\n–––, 2002, “Correction: ‘The\\nContinuum Hypothesis. II’”, , 49(1): 46.  \\nNotices of the American\\nMathematical Society  \\nYourgrau, Palle, 2005, , New York: Basic Books.  \\nA World Without Time. The Forgotten\\nLegacy of Gödel and Einstein  \\nZach, Richard, 1999, “Completeness Before Post: Bernays,\\nHilbert, and the Development of Propositional Logic”, , 5(3): 331–366.  \\nBulletin of Symbolic Logic  \\n–––, 2003, “Hilbert’s\\nProgram”, in (Fall Edition), Edward N. Zalta (ed.), URL =\\n < >.  \\nThe Stanford Encyclopedia of Philosophy  \\nhttps://plato.stanford.edu/archives/fall2003/entries/hilbert-program/'),\n",
       " Document(metadata={'Heading 1': 'Kurt Gödel', 'Heading 2': 'Academic Tools'}, page_content='Academic Tools'),\n",
       " Document(metadata={'Heading 1': 'Kurt Gödel', 'Heading 2': 'Academic Tools'}, page_content='.  \\nHow to cite this entry  \\nat the .  \\nPreview the PDF version of this entry  \\nFriends of the SEP Society  \\nat the Internet Philosophy Ontology Project (InPhO).  \\nLook up topics and thinkers related to this entry  \\nat , with links to its database.  \\nEnhanced bibliography for this entry  \\nPhilPapers  \\nOther Internet Resources  \\nAvigad, Jeremy,\\n “ ”,\\n manuscript in PDF available online.  \\nGödel and the metamathematical tradition  \\nKoellner, Peter,\\n “ ”,\\n manuscript in PDF available online.  \\nTruth in Mathematics:The question of Pluralism  \\n.  \\nThe Bernays Project  \\nRelated Entries  \\n| | | | | | | | | | | |  \\nGödel, Kurt: incompleteness theorems  \\nHilbert, David: program in the foundations of mathematics  \\nHusserl, Edmund  \\nLeibniz, Gottfried Wilhelm  \\nmathematics, philosophy of: intuitionism  \\nmathematics, philosophy of: Platonism  \\nmodel theory  \\nmodel theory: first-order  \\nphenomenology  \\nrealism  \\nset theory  \\nset theory: continuum hypothesis  \\nset theory: large cardinals and determinacy'),\n",
       " Document(metadata={'Heading 1': 'Kurt Gödel', 'Heading 2': 'Academic Tools', 'Heading 3': 'Acknowledgments'}, page_content='Acknowledgments'),\n",
       " Document(metadata={}, page_content='This entry was very much improved by discussion and correspondence\\nwith the following: Aki Kanamori, who made helpful corrections and\\ncomments to section 2.4; Jouko Väänänen, whose\\nexpertise in all areas of mathematical logic the author benefited from\\nin a great many invaluable discussions regarding the material in\\nsection 2; my sub-editor Richard Zach, whose many important and\\nhelpful suggestions led to a vast improvement of this entry, and an\\nanonymous referee for helpful comments and corrections. The author is\\ngrateful to the NWO for their support during the last period of the\\nwriting of this entry, to the Institute for Advanced Study for their\\nhospitality during the writing of this entry, and to Marcia Tucker of\\nthe IAS and the Rare Books and Special Collections department of\\nFirestone Library for all of their assistance over the years .  \\nby < >  \\nCopyright © 2015  \\nJuliette Kennedy  \\njuliette kennedy helsinki fi  \\n.  \\n@  \\n.  \\nOpen access to the SEP is made possible by a world-wide funding initiative. The Encyclopedia Now Needs Your Support Please Read How You Can Help Keep the Encyclopedia Free  \\nEnd footer menu End mirrors End site credits'),\n",
       " Document(metadata={'Heading 4': 'Browse'}, page_content='Browse'),\n",
       " Document(metadata={'Heading 4': 'Browse'}, page_content=\"Table of Contents  \\nWhat's New  \\nRandom Entry  \\nChronological  \\nArchives\"),\n",
       " Document(metadata={'Heading 4': 'About'}, page_content='About'),\n",
       " Document(metadata={'Heading 4': 'About'}, page_content='Editorial Information  \\nAbout the SEP  \\nEditorial Board  \\nHow to Cite the SEP  \\nSpecial Characters  \\nAdvanced Tools  \\nAccessibility  \\nContact'),\n",
       " Document(metadata={'Heading 4': 'Support SEP'}, page_content='Support SEP'),\n",
       " Document(metadata={'Heading 4': 'Support SEP'}, page_content='Support the SEP  \\nPDFs for SEP Friends  \\nMake a Donation  \\nSEPIA for Libraries'),\n",
       " Document(metadata={'Heading 4': 'Mirror Sites'}, page_content='Mirror Sites'),\n",
       " Document(metadata={}, page_content=\"View this site from another server:  \\nUSA (Main Site)  \\nPhilosophy, Stanford University  \\nInfo about mirror sites  \\nThe Stanford Encyclopedia of Philosophy is by , Department of Philosophy, Stanford University  \\ncopyright © 2023  \\nThe Metaphysics Research Lab  \\nLibrary of Congress Catalog Data: ISSN 1095-5054  \\n$('.dropdown-toggle').dropdown();\")]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://plato.stanford.edu/entries/goedel/\"\n",
    "header_to_split_on = [\n",
    "    (\"h1\", \"Heading 1\"),\n",
    "    (\"h2\", \"Heading 2\"),\n",
    "    (\"h3\", \"Heading 3\"),\n",
    "    (\"h4\", \"Heading 4\"),\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(header_to_split_on)\n",
    "html_header_splits = html_splitter.split_text_from_url(url)\n",
    "html_header_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18edb320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests\n",
    "json_data=requests.get(\"https://api.smith.langchain.com/openapi.json\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c44f7a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package requests:\n",
      "\n",
      "NAME\n",
      "    requests\n",
      "\n",
      "DESCRIPTION\n",
      "    Requests HTTP Library\n",
      "    ~~~~~~~~~~~~~~~~~~~~~\n",
      "    \n",
      "    Requests is an HTTP library, written in Python, for human beings.\n",
      "    Basic GET usage:\n",
      "    \n",
      "       >>> import requests\n",
      "       >>> r = requests.get('https://www.python.org')\n",
      "       >>> r.status_code\n",
      "       200\n",
      "       >>> b'Python is a programming language' in r.content\n",
      "       True\n",
      "    \n",
      "    ... or POST:\n",
      "    \n",
      "       >>> payload = dict(key1='value1', key2='value2')\n",
      "       >>> r = requests.post('https://httpbin.org/post', data=payload)\n",
      "       >>> print(r.text)\n",
      "       {\n",
      "         ...\n",
      "         \"form\": {\n",
      "           \"key1\": \"value1\",\n",
      "           \"key2\": \"value2\"\n",
      "         },\n",
      "         ...\n",
      "       }\n",
      "    \n",
      "    The other HTTP methods are supported - see `requests.api`. Full documentation\n",
      "    is at <https://requests.readthedocs.io>.\n",
      "    \n",
      "    :copyright: (c) 2017 by Kenneth Reitz.\n",
      "    :license: Apache 2.0, see LICENSE for more details.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __version__\n",
      "    _internal_utils\n",
      "    adapters\n",
      "    api\n",
      "    auth\n",
      "    certs\n",
      "    compat\n",
      "    cookies\n",
      "    exceptions\n",
      "    help\n",
      "    hooks\n",
      "    models\n",
      "    packages\n",
      "    sessions\n",
      "    status_codes\n",
      "    structures\n",
      "    utils\n",
      "\n",
      "FUNCTIONS\n",
      "    check_compatibility(urllib3_version, chardet_version, charset_normalizer_version)\n",
      "\n",
      "DATA\n",
      "    __author_email__ = 'me@kennethreitz.org'\n",
      "    __build__ = 143877\n",
      "    __cake__ = '✨ 🍰 ✨'\n",
      "    __copyright__ = 'Copyright Kenneth Reitz'\n",
      "    __description__ = 'Python HTTP for Humans.'\n",
      "    __license__ = 'Apache-2.0'\n",
      "    __title__ = 'requests'\n",
      "    __url__ = 'https://requests.readthedocs.io'\n",
      "    chardet_version = None\n",
      "    charset_normalizer_version = '3.4.3'\n",
      "    codes = <lookup 'status_codes'>\n",
      "\n",
      "VERSION\n",
      "    2.32.5\n",
      "\n",
      "AUTHOR\n",
      "    Kenneth Reitz\n",
      "\n",
      "FILE\n",
      "    e:\\ai langchain\\.venv\\lib\\site-packages\\requests\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AZLyricsLoader', 'AcreomLoader', 'AirbyteCDKLoader', 'AirbyteGongLoader', 'AirbyteHubspotLoader', 'AirbyteJSONLoader', 'AirbyteSalesforceLoader', 'AirbyteShopifyLoader', 'AirbyteStripeLoader', 'AirbyteTypeformLoader', 'AirbyteZendeskSupportLoader', 'AirtableLoader', 'AmazonTextractPDFLoader', 'ApifyDatasetLoader', 'ArcGISLoader', 'ArxivLoader', 'AssemblyAIAudioLoaderById', 'AssemblyAIAudioTranscriptLoader', 'AstraDBLoader', 'AsyncChromiumLoader', 'AsyncHtmlLoader', 'AthenaLoader', 'AzureAIDataLoader', 'AzureAIDocumentIntelligenceLoader', 'AzureBlobStorageContainerLoader', 'AzureBlobStorageFileLoader', 'BSHTMLLoader', 'BibtexLoader', 'BigQueryLoader', 'BiliBiliLoader', 'BlackboardLoader', 'Blob', 'BlobLoader', 'BlockchainDocumentLoader', 'BraveSearchLoader', 'BrowserbaseLoader', 'BrowserlessLoader', 'CSVLoader', 'CassandraLoader', 'ChatGPTLoader', 'CloudBlobLoader', 'CoNLLULoader', 'CollegeConfidentialLoader', 'ConcurrentLoader', 'ConfluenceLoader', 'CouchbaseLoader', 'CubeSemanticLoader', 'DataFrameLoader', 'DatadogLogsLoader', 'DedocAPIFileLoader', 'DedocFileLoader', 'DedocPDFLoader', 'DiffbotLoader', 'DirectoryLoader', 'DiscordChatLoader', 'DocugamiLoader', 'DocusaurusLoader', 'Docx2txtLoader', 'DropboxLoader', 'DuckDBLoader', 'EtherscanLoader', 'EverNoteLoader', 'FacebookChatLoader', 'FaunaLoader', 'FigmaFileLoader', 'FireCrawlLoader', 'FileSystemBlobLoader', 'GCSDirectoryLoader', 'GlueCatalogLoader', 'GCSFileLoader', 'GeoDataFrameLoader', 'GitHubIssuesLoader', 'GitLoader', 'GitbookLoader', 'GithubFileLoader', 'GoogleApiClient', 'GoogleApiYoutubeLoader', 'GoogleDriveLoader', 'GoogleSpeechToTextLoader', 'GutenbergLoader', 'HNLoader', 'HuggingFaceDatasetLoader', 'HuggingFaceModelLoader', 'IFixitLoader', 'ImageCaptionLoader', 'IMSDbLoader', 'IuguLoader', 'JoplinLoader', 'JSONLoader', 'KineticaLoader', 'LakeFSLoader', 'LarkSuiteDocLoader', 'LLMSherpaFileLoader', 'MastodonTootsLoader', 'MHTMLLoader', 'MWDumpLoader', 'MathpixPDFLoader', 'MaxComputeLoader', 'MergedDataLoader', 'ModernTreasuryLoader', 'MongodbLoader', 'NeedleLoader', 'NewsURLLoader', 'NotebookLoader', 'NotionDBLoader', 'NotionDirectoryLoader', 'OBSDirectoryLoader', 'OBSFileLoader', 'ObsidianLoader', 'OneDriveFileLoader', 'OneDriveLoader', 'OnlinePDFLoader', 'OpenCityDataLoader', 'OracleAutonomousDatabaseLoader', 'OracleDocLoader', 'OracleTextSplitter', 'OutlookMessageLoader', 'PDFMinerLoader', 'PDFMinerPDFasHTMLLoader', 'PDFPlumberLoader', 'PagedPDFSplitter', 'PebbloSafeLoader', 'PebbloTextLoader', 'PlaywrightURLLoader', 'PolarsDataFrameLoader', 'PsychicLoader', 'PubMedLoader', 'PyMuPDFLoader', 'PyPDFDirectoryLoader', 'PyPDFLoader', 'PyPDFium2Loader', 'PySparkDataFrameLoader', 'PythonLoader', 'RSSFeedLoader', 'ReadTheDocsLoader', 'RecursiveUrlLoader', 'RedditPostsLoader', 'RoamLoader', 'RocksetLoader', 'S3DirectoryLoader', 'S3FileLoader', 'ScrapflyLoader', 'ScrapingAntLoader', 'SQLDatabaseLoader', 'SRTLoader', 'SeleniumURLLoader', 'SharePointLoader', 'SitemapLoader', 'SlackDirectoryLoader', 'SnowflakeLoader', 'SpiderLoader', 'SpreedlyLoader', 'StripeLoader', 'SurrealDBLoader', 'TelegramChatApiLoader', 'TelegramChatFileLoader', 'TelegramChatLoader', 'TencentCOSDirectoryLoader', 'TencentCOSFileLoader', 'TensorflowDatasetLoader', 'TextLoader', 'TiDBLoader', 'ToMarkdownLoader', 'TomlLoader', 'TrelloLoader', 'TwitterTweetLoader', 'UnstructuredAPIFileIOLoader', 'UnstructuredAPIFileLoader', 'UnstructuredCHMLoader', 'UnstructuredCSVLoader', 'UnstructuredEPubLoader', 'UnstructuredEmailLoader', 'UnstructuredExcelLoader', 'UnstructuredFileIOLoader', 'UnstructuredFileLoader', 'UnstructuredHTMLLoader', 'UnstructuredImageLoader', 'UnstructuredMarkdownLoader', 'UnstructuredODTLoader', 'UnstructuredOrgModeLoader', 'UnstructuredPDFLoader', 'UnstructuredPowerPointLoader', 'UnstructuredRSTLoader', 'UnstructuredRTFLoader', 'UnstructuredTSVLoader', 'UnstructuredURLLoader', 'UnstructuredWordDocumentLoader', 'UnstructuredXMLLoader', 'VsdxLoader', 'WeatherDataLoader', 'WebBaseLoader', 'WhatsAppChatLoader', 'WikipediaLoader', 'XorbitsLoader', 'YoutubeAudioLoader', 'YoutubeLoader', 'YuqueLoader']\n"
     ]
    }
   ],
   "source": [
    "import langchain_community\n",
    "print(langchain_community.document_loaders.__all__ )\n",
    "from langchain_community.document_loaders import JSONLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "89eea809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - adapters\n",
      " - agent_toolkits\n",
      " - agents\n",
      " - cache\n",
      " - callbacks\n",
      " - chains\n",
      " - chat_loaders\n",
      " - chat_message_histories\n",
      " - chat_models\n",
      " - cross_encoders\n",
      " - docstore\n",
      " - document_compressors\n",
      " - document_loaders\n",
      " - document_transformers\n",
      " - embeddings\n",
      " - example_selectors\n",
      " - graph_vectorstores\n",
      " - graphs\n",
      " - indexes\n",
      " - llms\n",
      " - memory\n",
      " - output_parsers\n",
      " - query_constructors\n",
      " - retrievers\n",
      " - storage\n",
      " - tools\n",
      " - utilities\n",
      " - utils\n",
      " - vectorstores\n"
     ]
    }
   ],
   "source": [
    "import pkgutil\n",
    "for module in pkgutil.iter_modules(langchain_community.__path__):\n",
    "    print(\" -\", module.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b9c86956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConnectTimeout',\n",
       " 'ConnectionError',\n",
       " 'DependencyWarning',\n",
       " 'FileModeWarning',\n",
       " 'HTTPError',\n",
       " 'JSONDecodeError',\n",
       " 'NullHandler',\n",
       " 'PreparedRequest',\n",
       " 'ReadTimeout',\n",
       " 'Request',\n",
       " 'RequestException',\n",
       " 'RequestsDependencyWarning',\n",
       " 'Response',\n",
       " 'Session',\n",
       " 'Timeout',\n",
       " 'TooManyRedirects',\n",
       " 'URLRequired',\n",
       " '__author__',\n",
       " '__author_email__',\n",
       " '__build__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__cake__',\n",
       " '__copyright__',\n",
       " '__description__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__license__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__title__',\n",
       " '__url__',\n",
       " '__version__',\n",
       " '_check_cryptography',\n",
       " '_internal_utils',\n",
       " 'adapters',\n",
       " 'api',\n",
       " 'auth',\n",
       " 'certs',\n",
       " 'chardet_version',\n",
       " 'charset_normalizer_version',\n",
       " 'check_compatibility',\n",
       " 'codes',\n",
       " 'compat',\n",
       " 'cookies',\n",
       " 'delete',\n",
       " 'exceptions',\n",
       " 'get',\n",
       " 'head',\n",
       " 'hooks',\n",
       " 'logging',\n",
       " 'models',\n",
       " 'options',\n",
       " 'packages',\n",
       " 'patch',\n",
       " 'post',\n",
       " 'put',\n",
       " 'request',\n",
       " 'session',\n",
       " 'sessions',\n",
       " 'ssl',\n",
       " 'status_codes',\n",
       " 'structures',\n",
       " 'urllib3',\n",
       " 'utils',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79619a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "json_data=requests.get(\"https://api.smith.langchain.com/openapi.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2842711e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d25af2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 langchain_community.adapters\n",
      "  📄 langchain_community.adapters.openai\n",
      "📦 langchain_community.agent_toolkits\n",
      "  📦 langchain_community.agent_toolkits.ainetwork\n",
      "    📄 langchain_community.agent_toolkits.ainetwork.toolkit\n",
      "  📦 langchain_community.agent_toolkits.amadeus\n",
      "    📄 langchain_community.agent_toolkits.amadeus.toolkit\n",
      "  📄 langchain_community.agent_toolkits.azure_ai_services\n",
      "  📄 langchain_community.agent_toolkits.azure_cognitive_services\n",
      "  📄 langchain_community.agent_toolkits.base\n",
      "  📦 langchain_community.agent_toolkits.cassandra_database\n",
      "    📄 langchain_community.agent_toolkits.cassandra_database.toolkit\n",
      "  📦 langchain_community.agent_toolkits.clickup\n",
      "    📄 langchain_community.agent_toolkits.clickup.toolkit\n",
      "  📦 langchain_community.agent_toolkits.cogniswitch\n",
      "    📄 langchain_community.agent_toolkits.cogniswitch.toolkit\n",
      "  📦 langchain_community.agent_toolkits.connery\n",
      "    📄 langchain_community.agent_toolkits.connery.toolkit\n",
      "  📦 langchain_community.agent_toolkits.csv\n",
      "  📦 langchain_community.agent_toolkits.file_management\n",
      "    📄 langchain_community.agent_toolkits.file_management.toolkit\n",
      "  📦 langchain_community.agent_toolkits.financial_datasets\n",
      "    📄 langchain_community.agent_toolkits.financial_datasets.toolkit\n",
      "  📦 langchain_community.agent_toolkits.github\n",
      "    📄 langchain_community.agent_toolkits.github.toolkit\n",
      "  📦 langchain_community.agent_toolkits.gitlab\n",
      "    📄 langchain_community.agent_toolkits.gitlab.toolkit\n",
      "  📦 langchain_community.agent_toolkits.gmail\n",
      "    📄 langchain_community.agent_toolkits.gmail.toolkit\n",
      "  📦 langchain_community.agent_toolkits.jira\n",
      "    📄 langchain_community.agent_toolkits.jira.toolkit\n",
      "  📦 langchain_community.agent_toolkits.json\n",
      "    📄 langchain_community.agent_toolkits.json.base\n",
      "    📄 langchain_community.agent_toolkits.json.prompt\n",
      "    📄 langchain_community.agent_toolkits.json.toolkit\n",
      "  📄 langchain_community.agent_toolkits.load_tools\n",
      "  📦 langchain_community.agent_toolkits.multion\n",
      "    📄 langchain_community.agent_toolkits.multion.toolkit\n",
      "  📦 langchain_community.agent_toolkits.nasa\n",
      "    📄 langchain_community.agent_toolkits.nasa.toolkit\n",
      "  📦 langchain_community.agent_toolkits.nla\n",
      "    📄 langchain_community.agent_toolkits.nla.tool\n",
      "    📄 langchain_community.agent_toolkits.nla.toolkit\n",
      "  📦 langchain_community.agent_toolkits.office365\n",
      "    📄 langchain_community.agent_toolkits.office365.toolkit\n",
      "  📦 langchain_community.agent_toolkits.openapi\n",
      "    📄 langchain_community.agent_toolkits.openapi.base\n",
      "    📄 langchain_community.agent_toolkits.openapi.planner\n",
      "    📄 langchain_community.agent_toolkits.openapi.planner_prompt\n",
      "    📄 langchain_community.agent_toolkits.openapi.prompt\n",
      "    📄 langchain_community.agent_toolkits.openapi.spec\n",
      "    📄 langchain_community.agent_toolkits.openapi.toolkit\n",
      "  📦 langchain_community.agent_toolkits.playwright\n",
      "    📄 langchain_community.agent_toolkits.playwright.toolkit\n",
      "  📦 langchain_community.agent_toolkits.polygon\n",
      "    📄 langchain_community.agent_toolkits.polygon.toolkit\n",
      "  📦 langchain_community.agent_toolkits.powerbi\n",
      "    📄 langchain_community.agent_toolkits.powerbi.base\n",
      "    📄 langchain_community.agent_toolkits.powerbi.chat_base\n",
      "    📄 langchain_community.agent_toolkits.powerbi.prompt\n",
      "    📄 langchain_community.agent_toolkits.powerbi.toolkit\n",
      "  📦 langchain_community.agent_toolkits.slack\n",
      "    📄 langchain_community.agent_toolkits.slack.toolkit\n",
      "  📦 langchain_community.agent_toolkits.spark_sql\n",
      "    📄 langchain_community.agent_toolkits.spark_sql.base\n",
      "    📄 langchain_community.agent_toolkits.spark_sql.prompt\n",
      "    📄 langchain_community.agent_toolkits.spark_sql.toolkit\n",
      "  📦 langchain_community.agent_toolkits.sql\n",
      "    📄 langchain_community.agent_toolkits.sql.base\n",
      "    📄 langchain_community.agent_toolkits.sql.prompt\n",
      "    📄 langchain_community.agent_toolkits.sql.toolkit\n",
      "  📦 langchain_community.agent_toolkits.steam\n",
      "    📄 langchain_community.agent_toolkits.steam.toolkit\n",
      "  📦 langchain_community.agent_toolkits.xorbits\n",
      "  📦 langchain_community.agent_toolkits.zapier\n",
      "    📄 langchain_community.agent_toolkits.zapier.toolkit\n",
      "📦 langchain_community.agents\n",
      "  📦 langchain_community.agents.openai_assistant\n",
      "    📄 langchain_community.agents.openai_assistant.base\n",
      "📄 langchain_community.cache\n",
      "📦 langchain_community.callbacks\n",
      "  📄 langchain_community.callbacks.aim_callback\n",
      "  📄 langchain_community.callbacks.argilla_callback\n",
      "  📄 langchain_community.callbacks.arize_callback\n",
      "  📄 langchain_community.callbacks.arthur_callback\n",
      "  📄 langchain_community.callbacks.bedrock_anthropic_callback\n",
      "  📄 langchain_community.callbacks.clearml_callback\n",
      "  📄 langchain_community.callbacks.comet_ml_callback\n",
      "  📄 langchain_community.callbacks.confident_callback\n",
      "  📄 langchain_community.callbacks.context_callback\n",
      "  📄 langchain_community.callbacks.fiddler_callback\n",
      "  📄 langchain_community.callbacks.flyte_callback\n",
      "  📄 langchain_community.callbacks.human\n",
      "  📄 langchain_community.callbacks.infino_callback\n",
      "  📄 langchain_community.callbacks.labelstudio_callback\n",
      "  📄 langchain_community.callbacks.llmonitor_callback\n",
      "  📄 langchain_community.callbacks.manager\n",
      "  📄 langchain_community.callbacks.mlflow_callback\n",
      "  📄 langchain_community.callbacks.openai_info\n",
      "  📄 langchain_community.callbacks.promptlayer_callback\n",
      "  📄 langchain_community.callbacks.sagemaker_callback\n",
      "  📦 langchain_community.callbacks.streamlit\n",
      "    📄 langchain_community.callbacks.streamlit.mutable_expander\n",
      "    📄 langchain_community.callbacks.streamlit.streamlit_callback_handler\n",
      "  📦 langchain_community.callbacks.tracers\n",
      "    📄 langchain_community.callbacks.tracers.comet\n",
      "    📄 langchain_community.callbacks.tracers.wandb\n",
      "  📄 langchain_community.callbacks.trubrics_callback\n",
      "  📄 langchain_community.callbacks.upstash_ratelimit_callback\n",
      "  📄 langchain_community.callbacks.uptrain_callback\n",
      "  📄 langchain_community.callbacks.utils\n",
      "  📄 langchain_community.callbacks.wandb_callback\n",
      "  📄 langchain_community.callbacks.whylabs_callback\n",
      "📦 langchain_community.chains\n",
      "  📦 langchain_community.chains.ernie_functions\n",
      "    📄 langchain_community.chains.ernie_functions.base\n",
      "  📦 langchain_community.chains.graph_qa\n",
      "    📄 langchain_community.chains.graph_qa.arangodb\n",
      "    📄 langchain_community.chains.graph_qa.base\n",
      "    📄 langchain_community.chains.graph_qa.cypher\n",
      "    📄 langchain_community.chains.graph_qa.cypher_utils\n",
      "    📄 langchain_community.chains.graph_qa.falkordb\n",
      "    📄 langchain_community.chains.graph_qa.gremlin\n",
      "    📄 langchain_community.chains.graph_qa.hugegraph\n",
      "    📄 langchain_community.chains.graph_qa.kuzu\n",
      "    📄 langchain_community.chains.graph_qa.memgraph\n",
      "    📄 langchain_community.chains.graph_qa.nebulagraph\n",
      "    📄 langchain_community.chains.graph_qa.neptune_cypher\n",
      "    📄 langchain_community.chains.graph_qa.neptune_sparql\n",
      "    📄 langchain_community.chains.graph_qa.ontotext_graphdb\n",
      "    📄 langchain_community.chains.graph_qa.prompts\n",
      "    📄 langchain_community.chains.graph_qa.sparql\n",
      "  📄 langchain_community.chains.llm_requests\n",
      "  📦 langchain_community.chains.natbot\n",
      "    📄 langchain_community.chains.natbot.base\n",
      "    📄 langchain_community.chains.natbot.crawler\n",
      "    📄 langchain_community.chains.natbot.prompt\n",
      "  📦 langchain_community.chains.openapi\n",
      "    📄 langchain_community.chains.openapi.chain\n",
      "    📄 langchain_community.chains.openapi.prompts\n",
      "    📄 langchain_community.chains.openapi.requests_chain\n",
      "    📄 langchain_community.chains.openapi.response_chain\n",
      "  📦 langchain_community.chains.pebblo_retrieval\n",
      "    📄 langchain_community.chains.pebblo_retrieval.base\n",
      "    📄 langchain_community.chains.pebblo_retrieval.enforcement_filters\n",
      "    📄 langchain_community.chains.pebblo_retrieval.models\n",
      "    📄 langchain_community.chains.pebblo_retrieval.utilities\n",
      "📦 langchain_community.chat_loaders\n",
      "  📄 langchain_community.chat_loaders.base\n",
      "  📄 langchain_community.chat_loaders.facebook_messenger\n",
      "  📄 langchain_community.chat_loaders.gmail\n",
      "  📄 langchain_community.chat_loaders.imessage\n",
      "  📄 langchain_community.chat_loaders.langsmith\n",
      "  📄 langchain_community.chat_loaders.slack\n",
      "  📄 langchain_community.chat_loaders.telegram\n",
      "  📄 langchain_community.chat_loaders.utils\n",
      "  📄 langchain_community.chat_loaders.whatsapp\n",
      "📦 langchain_community.chat_message_histories\n",
      "  📄 langchain_community.chat_message_histories.astradb\n",
      "  📄 langchain_community.chat_message_histories.cassandra\n",
      "  📄 langchain_community.chat_message_histories.cosmos_db\n",
      "  📄 langchain_community.chat_message_histories.dynamodb\n",
      "  📄 langchain_community.chat_message_histories.elasticsearch\n",
      "  📄 langchain_community.chat_message_histories.file\n",
      "  📄 langchain_community.chat_message_histories.firestore\n",
      "  📄 langchain_community.chat_message_histories.in_memory\n",
      "  📄 langchain_community.chat_message_histories.kafka\n",
      "  📄 langchain_community.chat_message_histories.momento\n",
      "  📄 langchain_community.chat_message_histories.mongodb\n",
      "  📄 langchain_community.chat_message_histories.neo4j\n",
      "  📄 langchain_community.chat_message_histories.postgres\n",
      "  📄 langchain_community.chat_message_histories.redis\n",
      "  📄 langchain_community.chat_message_histories.rocksetdb\n",
      "  📄 langchain_community.chat_message_histories.singlestoredb\n",
      "  📄 langchain_community.chat_message_histories.sql\n",
      "  📄 langchain_community.chat_message_histories.streamlit\n",
      "  📄 langchain_community.chat_message_histories.tidb\n",
      "  📄 langchain_community.chat_message_histories.upstash_redis\n",
      "  📄 langchain_community.chat_message_histories.xata\n",
      "  📄 langchain_community.chat_message_histories.zep\n",
      "  📄 langchain_community.chat_message_histories.zep_cloud\n",
      "📦 langchain_community.chat_models\n",
      "  📄 langchain_community.chat_models.anthropic\n",
      "  📄 langchain_community.chat_models.anyscale\n",
      "  📄 langchain_community.chat_models.azure_openai\n",
      "  📄 langchain_community.chat_models.azureml_endpoint\n",
      "  📄 langchain_community.chat_models.baichuan\n",
      "  📄 langchain_community.chat_models.baidu_qianfan_endpoint\n",
      "  📄 langchain_community.chat_models.bedrock\n",
      "  📄 langchain_community.chat_models.cloudflare_workersai\n",
      "  📄 langchain_community.chat_models.cohere\n",
      "  📄 langchain_community.chat_models.coze\n",
      "  📄 langchain_community.chat_models.dappier\n",
      "  📄 langchain_community.chat_models.databricks\n",
      "  📄 langchain_community.chat_models.deepinfra\n",
      "  📄 langchain_community.chat_models.edenai\n",
      "  📄 langchain_community.chat_models.ernie\n",
      "  📄 langchain_community.chat_models.everlyai\n",
      "  📄 langchain_community.chat_models.fake\n",
      "  📄 langchain_community.chat_models.fireworks\n",
      "  📄 langchain_community.chat_models.friendli\n",
      "  📄 langchain_community.chat_models.gigachat\n",
      "  📄 langchain_community.chat_models.google_palm\n",
      "  📄 langchain_community.chat_models.gpt_router\n",
      "  📄 langchain_community.chat_models.huggingface\n",
      "  📄 langchain_community.chat_models.human\n",
      "  📄 langchain_community.chat_models.hunyuan\n",
      "  📄 langchain_community.chat_models.javelin_ai_gateway\n",
      "  📄 langchain_community.chat_models.jinachat\n",
      "  📄 langchain_community.chat_models.kinetica\n",
      "  📄 langchain_community.chat_models.konko\n",
      "  📄 langchain_community.chat_models.litellm\n",
      "  📄 langchain_community.chat_models.litellm_router\n",
      "  📄 langchain_community.chat_models.llama_edge\n",
      "  📄 langchain_community.chat_models.llamacpp\n",
      "  📄 langchain_community.chat_models.maritalk\n",
      "  📄 langchain_community.chat_models.meta\n",
      "  📄 langchain_community.chat_models.minimax\n",
      "  📄 langchain_community.chat_models.mlflow\n",
      "  📄 langchain_community.chat_models.mlflow_ai_gateway\n",
      "  📄 langchain_community.chat_models.mlx\n",
      "  📄 langchain_community.chat_models.moonshot\n",
      "  📄 langchain_community.chat_models.naver\n",
      "  📄 langchain_community.chat_models.oci_data_science\n",
      "  📄 langchain_community.chat_models.oci_generative_ai\n",
      "  📄 langchain_community.chat_models.octoai\n",
      "  📄 langchain_community.chat_models.ollama\n",
      "  📄 langchain_community.chat_models.openai\n",
      "  📄 langchain_community.chat_models.outlines\n",
      "  📄 langchain_community.chat_models.pai_eas_endpoint\n",
      "  📄 langchain_community.chat_models.perplexity\n",
      "  📄 langchain_community.chat_models.premai\n",
      "  📄 langchain_community.chat_models.promptlayer_openai\n",
      "  📄 langchain_community.chat_models.reka\n",
      "  📄 langchain_community.chat_models.sambanova\n",
      "  📄 langchain_community.chat_models.snowflake\n",
      "  📄 langchain_community.chat_models.solar\n",
      "  📄 langchain_community.chat_models.sparkllm\n",
      "  📄 langchain_community.chat_models.symblai_nebula\n",
      "  📄 langchain_community.chat_models.tongyi\n",
      "  📄 langchain_community.chat_models.vertexai\n",
      "  📄 langchain_community.chat_models.volcengine_maas\n",
      "  📄 langchain_community.chat_models.writer\n",
      "  📄 langchain_community.chat_models.yandex\n",
      "  📄 langchain_community.chat_models.yi\n",
      "  📄 langchain_community.chat_models.yuan2\n",
      "  📄 langchain_community.chat_models.zhipuai\n",
      "📦 langchain_community.cross_encoders\n",
      "  📄 langchain_community.cross_encoders.base\n",
      "  📄 langchain_community.cross_encoders.fake\n",
      "  📄 langchain_community.cross_encoders.huggingface\n",
      "  📄 langchain_community.cross_encoders.sagemaker_endpoint\n",
      "📦 langchain_community.docstore\n",
      "  📄 langchain_community.docstore.arbitrary_fn\n",
      "  📄 langchain_community.docstore.base\n",
      "  📄 langchain_community.docstore.document\n",
      "  📄 langchain_community.docstore.in_memory\n",
      "  📄 langchain_community.docstore.wikipedia\n",
      "📦 langchain_community.document_compressors\n",
      "  📄 langchain_community.document_compressors.dashscope_rerank\n",
      "  📄 langchain_community.document_compressors.flashrank_rerank\n",
      "  📄 langchain_community.document_compressors.infinity_rerank\n",
      "  📄 langchain_community.document_compressors.jina_rerank\n",
      "  📄 langchain_community.document_compressors.llmlingua_filter\n",
      "  📄 langchain_community.document_compressors.openvino_rerank\n",
      "  📄 langchain_community.document_compressors.rankllm_rerank\n",
      "  📄 langchain_community.document_compressors.volcengine_rerank\n",
      "📦 langchain_community.document_loaders\n",
      "  📄 langchain_community.document_loaders.acreom\n",
      "  📄 langchain_community.document_loaders.airbyte\n",
      "  📄 langchain_community.document_loaders.airbyte_json\n",
      "  📄 langchain_community.document_loaders.airtable\n",
      "  📄 langchain_community.document_loaders.apify_dataset\n",
      "  📄 langchain_community.document_loaders.arcgis_loader\n",
      "  📄 langchain_community.document_loaders.arxiv\n",
      "  📄 langchain_community.document_loaders.assemblyai\n",
      "  📄 langchain_community.document_loaders.astradb\n",
      "  📄 langchain_community.document_loaders.async_html\n",
      "  📄 langchain_community.document_loaders.athena\n",
      "  📄 langchain_community.document_loaders.azlyrics\n",
      "  📄 langchain_community.document_loaders.azure_ai_data\n",
      "  📄 langchain_community.document_loaders.azure_blob_storage_container\n",
      "  📄 langchain_community.document_loaders.azure_blob_storage_file\n",
      "  📄 langchain_community.document_loaders.baiducloud_bos_directory\n",
      "  📄 langchain_community.document_loaders.baiducloud_bos_file\n",
      "  📄 langchain_community.document_loaders.base\n",
      "  📄 langchain_community.document_loaders.base_o365\n",
      "  📄 langchain_community.document_loaders.bibtex\n",
      "  📄 langchain_community.document_loaders.bigquery\n",
      "  📄 langchain_community.document_loaders.bilibili\n",
      "  📄 langchain_community.document_loaders.blackboard\n",
      "  📦 langchain_community.document_loaders.blob_loaders\n",
      "    📄 langchain_community.document_loaders.blob_loaders.cloud_blob_loader\n",
      "    📄 langchain_community.document_loaders.blob_loaders.file_system\n",
      "    📄 langchain_community.document_loaders.blob_loaders.schema\n",
      "    📄 langchain_community.document_loaders.blob_loaders.youtube_audio\n",
      "  📄 langchain_community.document_loaders.blockchain\n",
      "  📄 langchain_community.document_loaders.brave_search\n",
      "  📄 langchain_community.document_loaders.browserbase\n",
      "  📄 langchain_community.document_loaders.browserless\n",
      "  📄 langchain_community.document_loaders.cassandra\n",
      "  📄 langchain_community.document_loaders.chatgpt\n",
      "  📄 langchain_community.document_loaders.chm\n",
      "  📄 langchain_community.document_loaders.chromium\n",
      "  📄 langchain_community.document_loaders.college_confidential\n",
      "  📄 langchain_community.document_loaders.concurrent\n",
      "  📄 langchain_community.document_loaders.confluence\n",
      "  📄 langchain_community.document_loaders.conllu\n",
      "  📄 langchain_community.document_loaders.couchbase\n",
      "  📄 langchain_community.document_loaders.csv_loader\n",
      "  📄 langchain_community.document_loaders.cube_semantic\n",
      "  📄 langchain_community.document_loaders.datadog_logs\n",
      "  📄 langchain_community.document_loaders.dataframe\n",
      "  📄 langchain_community.document_loaders.dedoc\n",
      "  📄 langchain_community.document_loaders.diffbot\n",
      "  📄 langchain_community.document_loaders.directory\n",
      "  📄 langchain_community.document_loaders.discord\n",
      "  📄 langchain_community.document_loaders.doc_intelligence\n",
      "  📄 langchain_community.document_loaders.docugami\n",
      "  📄 langchain_community.document_loaders.docusaurus\n",
      "  📄 langchain_community.document_loaders.dropbox\n",
      "  📄 langchain_community.document_loaders.duckdb_loader\n",
      "  📄 langchain_community.document_loaders.email\n",
      "  📄 langchain_community.document_loaders.epub\n",
      "  📄 langchain_community.document_loaders.etherscan\n",
      "  📄 langchain_community.document_loaders.evernote\n",
      "  📄 langchain_community.document_loaders.excel\n",
      "  📄 langchain_community.document_loaders.facebook_chat\n",
      "  📄 langchain_community.document_loaders.fauna\n",
      "  📄 langchain_community.document_loaders.figma\n",
      "  📄 langchain_community.document_loaders.firecrawl\n",
      "  📄 langchain_community.document_loaders.gcs_directory\n",
      "  📄 langchain_community.document_loaders.gcs_file\n",
      "  📄 langchain_community.document_loaders.generic\n",
      "  📄 langchain_community.document_loaders.geodataframe\n",
      "  📄 langchain_community.document_loaders.git\n",
      "  📄 langchain_community.document_loaders.gitbook\n",
      "  📄 langchain_community.document_loaders.github\n",
      "  📄 langchain_community.document_loaders.glue_catalog\n",
      "  📄 langchain_community.document_loaders.google_speech_to_text\n",
      "  📄 langchain_community.document_loaders.googledrive\n",
      "  📄 langchain_community.document_loaders.gutenberg\n",
      "  📄 langchain_community.document_loaders.helpers\n",
      "  📄 langchain_community.document_loaders.hn\n",
      "  📄 langchain_community.document_loaders.html\n",
      "  📄 langchain_community.document_loaders.html_bs\n",
      "  📄 langchain_community.document_loaders.hugging_face_dataset\n",
      "  📄 langchain_community.document_loaders.hugging_face_model\n",
      "  📄 langchain_community.document_loaders.ifixit\n",
      "  📄 langchain_community.document_loaders.image\n",
      "  📄 langchain_community.document_loaders.image_captions\n",
      "  📄 langchain_community.document_loaders.imsdb\n",
      "  📄 langchain_community.document_loaders.iugu\n",
      "  📄 langchain_community.document_loaders.joplin\n",
      "  📄 langchain_community.document_loaders.json_loader\n",
      "  📄 langchain_community.document_loaders.kinetica_loader\n",
      "  📄 langchain_community.document_loaders.lakefs\n",
      "  📄 langchain_community.document_loaders.larksuite\n",
      "  📄 langchain_community.document_loaders.llmsherpa\n",
      "  📄 langchain_community.document_loaders.markdown\n",
      "  📄 langchain_community.document_loaders.mastodon\n",
      "  📄 langchain_community.document_loaders.max_compute\n",
      "  📄 langchain_community.document_loaders.mediawikidump\n",
      "  📄 langchain_community.document_loaders.merge\n",
      "  📄 langchain_community.document_loaders.mhtml\n",
      "  📄 langchain_community.document_loaders.mintbase\n",
      "  📄 langchain_community.document_loaders.modern_treasury\n",
      "  📄 langchain_community.document_loaders.mongodb\n",
      "  📄 langchain_community.document_loaders.needle\n",
      "  📄 langchain_community.document_loaders.news\n",
      "  📄 langchain_community.document_loaders.notebook\n",
      "  📄 langchain_community.document_loaders.notion\n",
      "  📄 langchain_community.document_loaders.notiondb\n",
      "  📄 langchain_community.document_loaders.nuclia\n",
      "  📄 langchain_community.document_loaders.obs_directory\n",
      "  📄 langchain_community.document_loaders.obs_file\n",
      "  📄 langchain_community.document_loaders.obsidian\n",
      "  📄 langchain_community.document_loaders.odt\n",
      "  📄 langchain_community.document_loaders.onedrive\n",
      "  📄 langchain_community.document_loaders.onedrive_file\n",
      "  📄 langchain_community.document_loaders.onenote\n",
      "  📄 langchain_community.document_loaders.open_city_data\n",
      "  📄 langchain_community.document_loaders.oracleadb_loader\n",
      "  📄 langchain_community.document_loaders.oracleai\n",
      "  📄 langchain_community.document_loaders.org_mode\n",
      "  📦 langchain_community.document_loaders.parsers\n",
      "    📄 langchain_community.document_loaders.parsers.audio\n",
      "    📄 langchain_community.document_loaders.parsers.doc_intelligence\n",
      "    📄 langchain_community.document_loaders.parsers.docai\n",
      "    📄 langchain_community.document_loaders.parsers.documentloader_adapter\n",
      "    📄 langchain_community.document_loaders.parsers.generic\n",
      "    📄 langchain_community.document_loaders.parsers.grobid\n",
      "    📦 langchain_community.document_loaders.parsers.html\n",
      "      📄 langchain_community.document_loaders.parsers.html.bs4\n",
      "    📄 langchain_community.document_loaders.parsers.images\n",
      "    📦 langchain_community.document_loaders.parsers.language\n",
      "      📄 langchain_community.document_loaders.parsers.language.c\n",
      "      📄 langchain_community.document_loaders.parsers.language.cobol\n",
      "      📄 langchain_community.document_loaders.parsers.language.code_segmenter\n",
      "      📄 langchain_community.document_loaders.parsers.language.cpp\n",
      "      📄 langchain_community.document_loaders.parsers.language.csharp\n",
      "      📄 langchain_community.document_loaders.parsers.language.elixir\n",
      "      📄 langchain_community.document_loaders.parsers.language.go\n",
      "      📄 langchain_community.document_loaders.parsers.language.java\n",
      "      📄 langchain_community.document_loaders.parsers.language.javascript\n",
      "      📄 langchain_community.document_loaders.parsers.language.kotlin\n",
      "      📄 langchain_community.document_loaders.parsers.language.language_parser\n",
      "      📄 langchain_community.document_loaders.parsers.language.lua\n",
      "      📄 langchain_community.document_loaders.parsers.language.perl\n",
      "      📄 langchain_community.document_loaders.parsers.language.php\n",
      "      📄 langchain_community.document_loaders.parsers.language.python\n",
      "      📄 langchain_community.document_loaders.parsers.language.ruby\n",
      "      📄 langchain_community.document_loaders.parsers.language.rust\n",
      "      📄 langchain_community.document_loaders.parsers.language.scala\n",
      "      📄 langchain_community.document_loaders.parsers.language.sql\n",
      "      📄 langchain_community.document_loaders.parsers.language.tree_sitter_segmenter\n",
      "      📄 langchain_community.document_loaders.parsers.language.typescript\n",
      "    📄 langchain_community.document_loaders.parsers.msword\n",
      "    📄 langchain_community.document_loaders.parsers.pdf\n",
      "    📄 langchain_community.document_loaders.parsers.registry\n",
      "    📄 langchain_community.document_loaders.parsers.txt\n",
      "    📄 langchain_community.document_loaders.parsers.vsdx\n",
      "  📄 langchain_community.document_loaders.pdf\n",
      "  📄 langchain_community.document_loaders.pebblo\n",
      "  📄 langchain_community.document_loaders.polars_dataframe\n",
      "  📄 langchain_community.document_loaders.powerpoint\n",
      "  📄 langchain_community.document_loaders.psychic\n",
      "  📄 langchain_community.document_loaders.pubmed\n",
      "  📄 langchain_community.document_loaders.pyspark_dataframe\n",
      "  📄 langchain_community.document_loaders.python\n",
      "  📄 langchain_community.document_loaders.quip\n",
      "  📄 langchain_community.document_loaders.readthedocs\n",
      "  📄 langchain_community.document_loaders.recursive_url_loader\n",
      "  📄 langchain_community.document_loaders.reddit\n",
      "  📄 langchain_community.document_loaders.roam\n",
      "  📄 langchain_community.document_loaders.rocksetdb\n",
      "  📄 langchain_community.document_loaders.rspace\n",
      "  📄 langchain_community.document_loaders.rss\n",
      "  📄 langchain_community.document_loaders.rst\n",
      "  📄 langchain_community.document_loaders.rtf\n",
      "  📄 langchain_community.document_loaders.s3_directory\n",
      "  📄 langchain_community.document_loaders.s3_file\n",
      "  📄 langchain_community.document_loaders.scrapfly\n",
      "  📄 langchain_community.document_loaders.scrapingant\n",
      "  📄 langchain_community.document_loaders.sharepoint\n",
      "  📄 langchain_community.document_loaders.sitemap\n",
      "  📄 langchain_community.document_loaders.slack_directory\n",
      "  📄 langchain_community.document_loaders.snowflake_loader\n",
      "  📄 langchain_community.document_loaders.spider\n",
      "  📄 langchain_community.document_loaders.spreedly\n",
      "  📄 langchain_community.document_loaders.sql_database\n",
      "  📄 langchain_community.document_loaders.srt\n",
      "  📄 langchain_community.document_loaders.stripe\n",
      "  📄 langchain_community.document_loaders.surrealdb\n",
      "  📄 langchain_community.document_loaders.telegram\n",
      "  📄 langchain_community.document_loaders.tencent_cos_directory\n",
      "  📄 langchain_community.document_loaders.tencent_cos_file\n",
      "  📄 langchain_community.document_loaders.tensorflow_datasets\n",
      "  📄 langchain_community.document_loaders.text\n",
      "  📄 langchain_community.document_loaders.tidb\n",
      "  📄 langchain_community.document_loaders.tomarkdown\n",
      "  📄 langchain_community.document_loaders.toml\n",
      "  📄 langchain_community.document_loaders.trello\n",
      "  📄 langchain_community.document_loaders.tsv\n",
      "  📄 langchain_community.document_loaders.twitter\n",
      "  📄 langchain_community.document_loaders.unstructured\n",
      "  📄 langchain_community.document_loaders.url\n",
      "  📄 langchain_community.document_loaders.url_playwright\n",
      "  📄 langchain_community.document_loaders.url_selenium\n",
      "  📄 langchain_community.document_loaders.vsdx\n",
      "  📄 langchain_community.document_loaders.weather\n",
      "  📄 langchain_community.document_loaders.web_base\n",
      "  📄 langchain_community.document_loaders.whatsapp_chat\n",
      "  📄 langchain_community.document_loaders.wikipedia\n",
      "  📄 langchain_community.document_loaders.word_document\n",
      "  📄 langchain_community.document_loaders.xml\n",
      "  📄 langchain_community.document_loaders.xorbits\n",
      "  📄 langchain_community.document_loaders.youtube\n",
      "  📄 langchain_community.document_loaders.yuque\n",
      "📦 langchain_community.document_transformers\n",
      "  📄 langchain_community.document_transformers.beautiful_soup_transformer\n",
      "  📄 langchain_community.document_transformers.doctran_text_extract\n",
      "  📄 langchain_community.document_transformers.doctran_text_qa\n",
      "  📄 langchain_community.document_transformers.doctran_text_translate\n",
      "  📄 langchain_community.document_transformers.embeddings_redundant_filter\n",
      "  📄 langchain_community.document_transformers.google_translate\n",
      "  📄 langchain_community.document_transformers.html2text\n",
      "  📄 langchain_community.document_transformers.long_context_reorder\n",
      "  📄 langchain_community.document_transformers.markdownify\n",
      "  📄 langchain_community.document_transformers.nuclia_text_transform\n",
      "  📄 langchain_community.document_transformers.openai_functions\n",
      "📦 langchain_community.embeddings\n",
      "  📄 langchain_community.embeddings.aleph_alpha\n",
      "  📄 langchain_community.embeddings.anyscale\n",
      "  📄 langchain_community.embeddings.ascend\n",
      "  📄 langchain_community.embeddings.awa\n",
      "  📄 langchain_community.embeddings.azure_openai\n",
      "  📄 langchain_community.embeddings.baichuan\n",
      "  📄 langchain_community.embeddings.baidu_qianfan_endpoint\n",
      "  📄 langchain_community.embeddings.bedrock\n",
      "  📄 langchain_community.embeddings.bookend\n",
      "  📄 langchain_community.embeddings.clarifai\n",
      "  📄 langchain_community.embeddings.cloudflare_workersai\n",
      "  📄 langchain_community.embeddings.clova\n",
      "  📄 langchain_community.embeddings.cohere\n",
      "  📄 langchain_community.embeddings.dashscope\n",
      "  📄 langchain_community.embeddings.databricks\n",
      "  📄 langchain_community.embeddings.deepinfra\n",
      "  📄 langchain_community.embeddings.edenai\n",
      "  📄 langchain_community.embeddings.elasticsearch\n",
      "  📄 langchain_community.embeddings.embaas\n",
      "  📄 langchain_community.embeddings.ernie\n",
      "  📄 langchain_community.embeddings.fake\n",
      "  📄 langchain_community.embeddings.fastembed\n",
      "  📄 langchain_community.embeddings.gigachat\n",
      "  📄 langchain_community.embeddings.google_palm\n",
      "  📄 langchain_community.embeddings.gpt4all\n",
      "  📄 langchain_community.embeddings.gradient_ai\n",
      "  📄 langchain_community.embeddings.huggingface\n",
      "  📄 langchain_community.embeddings.huggingface_hub\n",
      "  📄 langchain_community.embeddings.hunyuan\n",
      "  📄 langchain_community.embeddings.infinity\n",
      "  📄 langchain_community.embeddings.infinity_local\n",
      "  📄 langchain_community.embeddings.ipex_llm\n",
      "  📄 langchain_community.embeddings.itrex\n",
      "  📄 langchain_community.embeddings.javelin_ai_gateway\n",
      "  📄 langchain_community.embeddings.jina\n",
      "  📄 langchain_community.embeddings.johnsnowlabs\n",
      "  📄 langchain_community.embeddings.laser\n",
      "  📄 langchain_community.embeddings.llamacpp\n",
      "  📄 langchain_community.embeddings.llamafile\n",
      "  📄 langchain_community.embeddings.llm_rails\n",
      "  📄 langchain_community.embeddings.localai\n",
      "  📄 langchain_community.embeddings.minimax\n",
      "  📄 langchain_community.embeddings.mlflow\n",
      "  📄 langchain_community.embeddings.mlflow_gateway\n",
      "  📄 langchain_community.embeddings.model2vec\n",
      "  📄 langchain_community.embeddings.modelscope_hub\n",
      "  📄 langchain_community.embeddings.mosaicml\n",
      "  📄 langchain_community.embeddings.naver\n",
      "  📄 langchain_community.embeddings.nemo\n",
      "  📄 langchain_community.embeddings.nlpcloud\n",
      "  📄 langchain_community.embeddings.oci_generative_ai\n",
      "  📄 langchain_community.embeddings.octoai_embeddings\n",
      "  📄 langchain_community.embeddings.ollama\n",
      "  📄 langchain_community.embeddings.openai\n",
      "  📄 langchain_community.embeddings.openvino\n",
      "  📄 langchain_community.embeddings.optimum_intel\n",
      "  📄 langchain_community.embeddings.oracleai\n",
      "  📄 langchain_community.embeddings.ovhcloud\n",
      "  📄 langchain_community.embeddings.premai\n",
      "  📄 langchain_community.embeddings.sagemaker_endpoint\n",
      "  📄 langchain_community.embeddings.sambanova\n",
      "  📄 langchain_community.embeddings.self_hosted\n",
      "  📄 langchain_community.embeddings.self_hosted_hugging_face\n",
      "  📄 langchain_community.embeddings.sentence_transformer\n",
      "  📄 langchain_community.embeddings.solar\n",
      "  📄 langchain_community.embeddings.spacy_embeddings\n",
      "  📄 langchain_community.embeddings.sparkllm\n",
      "  📄 langchain_community.embeddings.tensorflow_hub\n",
      "  📄 langchain_community.embeddings.text2vec\n",
      "  📄 langchain_community.embeddings.textembed\n",
      "  📄 langchain_community.embeddings.titan_takeoff\n",
      "  📄 langchain_community.embeddings.vertexai\n",
      "  📄 langchain_community.embeddings.volcengine\n",
      "  📄 langchain_community.embeddings.voyageai\n",
      "  📄 langchain_community.embeddings.xinference\n",
      "  📄 langchain_community.embeddings.yandex\n",
      "  📄 langchain_community.embeddings.zhipuai\n",
      "📦 langchain_community.example_selectors\n",
      "  📄 langchain_community.example_selectors.ngram_overlap\n",
      "📦 langchain_community.graph_vectorstores\n",
      "  📄 langchain_community.graph_vectorstores.base\n",
      "  📄 langchain_community.graph_vectorstores.cassandra\n",
      "  📦 langchain_community.graph_vectorstores.extractors\n",
      "    📄 langchain_community.graph_vectorstores.extractors.gliner_link_extractor\n",
      "    📄 langchain_community.graph_vectorstores.extractors.hierarchy_link_extractor\n",
      "    📄 langchain_community.graph_vectorstores.extractors.html_link_extractor\n",
      "    📄 langchain_community.graph_vectorstores.extractors.keybert_link_extractor\n",
      "    📄 langchain_community.graph_vectorstores.extractors.link_extractor\n",
      "    📄 langchain_community.graph_vectorstores.extractors.link_extractor_adapter\n",
      "    📄 langchain_community.graph_vectorstores.extractors.link_extractor_transformer\n",
      "  📄 langchain_community.graph_vectorstores.links\n",
      "  📄 langchain_community.graph_vectorstores.mmr_helper\n",
      "  📄 langchain_community.graph_vectorstores.networkx\n",
      "  📄 langchain_community.graph_vectorstores.visualize\n",
      "📦 langchain_community.graphs\n",
      "  📄 langchain_community.graphs.age_graph\n",
      "  📄 langchain_community.graphs.arangodb_graph\n",
      "  📄 langchain_community.graphs.falkordb_graph\n",
      "  📄 langchain_community.graphs.graph_document\n",
      "  📄 langchain_community.graphs.graph_store\n",
      "  📄 langchain_community.graphs.gremlin_graph\n",
      "  📄 langchain_community.graphs.hugegraph\n",
      "  📄 langchain_community.graphs.index_creator\n",
      "  📄 langchain_community.graphs.kuzu_graph\n",
      "  📄 langchain_community.graphs.memgraph_graph\n",
      "  📄 langchain_community.graphs.nebula_graph\n",
      "  📄 langchain_community.graphs.neo4j_graph\n",
      "  📄 langchain_community.graphs.neptune_graph\n",
      "  📄 langchain_community.graphs.neptune_rdf_graph\n",
      "  📄 langchain_community.graphs.networkx_graph\n",
      "  📄 langchain_community.graphs.ontotext_graphdb_graph\n",
      "  📄 langchain_community.graphs.rdf_graph\n",
      "  📄 langchain_community.graphs.tigergraph_graph\n",
      "📦 langchain_community.indexes\n",
      "  📄 langchain_community.indexes._document_manager\n",
      "  📄 langchain_community.indexes._sql_record_manager\n",
      "  📄 langchain_community.indexes.base\n",
      "📦 langchain_community.llms\n",
      "  📄 langchain_community.llms.ai21\n",
      "  📄 langchain_community.llms.aleph_alpha\n",
      "  📄 langchain_community.llms.amazon_api_gateway\n",
      "  📄 langchain_community.llms.anthropic\n",
      "  📄 langchain_community.llms.anyscale\n",
      "  📄 langchain_community.llms.aphrodite\n",
      "  📄 langchain_community.llms.arcee\n",
      "  📄 langchain_community.llms.aviary\n",
      "  📄 langchain_community.llms.azureml_endpoint\n",
      "  📄 langchain_community.llms.baichuan\n",
      "  📄 langchain_community.llms.baidu_qianfan_endpoint\n",
      "  📄 langchain_community.llms.bananadev\n",
      "  📄 langchain_community.llms.baseten\n",
      "  📄 langchain_community.llms.beam\n",
      "  📄 langchain_community.llms.bedrock\n",
      "  📄 langchain_community.llms.bigdl_llm\n",
      "  📄 langchain_community.llms.bittensor\n",
      "  📄 langchain_community.llms.cerebriumai\n",
      "  📄 langchain_community.llms.chatglm\n",
      "  📄 langchain_community.llms.chatglm3\n",
      "  📄 langchain_community.llms.clarifai\n",
      "  📄 langchain_community.llms.cloudflare_workersai\n",
      "  📄 langchain_community.llms.cohere\n",
      "  📄 langchain_community.llms.ctransformers\n",
      "  📄 langchain_community.llms.ctranslate2\n",
      "  📄 langchain_community.llms.databricks\n",
      "  📄 langchain_community.llms.deepinfra\n",
      "  📄 langchain_community.llms.deepsparse\n",
      "  📄 langchain_community.llms.edenai\n",
      "  📄 langchain_community.llms.exllamav2\n",
      "  📄 langchain_community.llms.fake\n",
      "  📄 langchain_community.llms.fireworks\n",
      "  📄 langchain_community.llms.forefrontai\n",
      "  📄 langchain_community.llms.friendli\n",
      "  📄 langchain_community.llms.gigachat\n",
      "  📄 langchain_community.llms.google_palm\n",
      "  📄 langchain_community.llms.gooseai\n",
      "  📄 langchain_community.llms.gpt4all\n",
      "  📄 langchain_community.llms.gradient_ai\n",
      "  📄 langchain_community.llms.huggingface_endpoint\n",
      "  📄 langchain_community.llms.huggingface_hub\n",
      "  📄 langchain_community.llms.huggingface_pipeline\n",
      "  📄 langchain_community.llms.huggingface_text_gen_inference\n",
      "  📄 langchain_community.llms.human\n",
      "  📄 langchain_community.llms.ipex_llm\n",
      "  📄 langchain_community.llms.javelin_ai_gateway\n",
      "  📄 langchain_community.llms.koboldai\n",
      "  📄 langchain_community.llms.konko\n",
      "  📄 langchain_community.llms.layerup_security\n",
      "  📄 langchain_community.llms.llamacpp\n",
      "  📄 langchain_community.llms.llamafile\n",
      "  📄 langchain_community.llms.loading\n",
      "  📄 langchain_community.llms.manifest\n",
      "  📄 langchain_community.llms.minimax\n",
      "  📄 langchain_community.llms.mlflow\n",
      "  📄 langchain_community.llms.mlflow_ai_gateway\n",
      "  📄 langchain_community.llms.mlx_pipeline\n",
      "  📄 langchain_community.llms.modal\n",
      "  📄 langchain_community.llms.moonshot\n",
      "  📄 langchain_community.llms.mosaicml\n",
      "  📄 langchain_community.llms.nlpcloud\n",
      "  📄 langchain_community.llms.oci_data_science_model_deployment_endpoint\n",
      "  📄 langchain_community.llms.oci_generative_ai\n",
      "  📄 langchain_community.llms.octoai_endpoint\n",
      "  📄 langchain_community.llms.ollama\n",
      "  📄 langchain_community.llms.opaqueprompts\n",
      "  📄 langchain_community.llms.openai\n",
      "  📄 langchain_community.llms.openllm\n",
      "  📄 langchain_community.llms.openlm\n",
      "  📄 langchain_community.llms.outlines\n",
      "  📄 langchain_community.llms.pai_eas_endpoint\n",
      "  📄 langchain_community.llms.petals\n",
      "  📄 langchain_community.llms.pipelineai\n",
      "  📄 langchain_community.llms.predibase\n",
      "  📄 langchain_community.llms.predictionguard\n",
      "  📄 langchain_community.llms.promptlayer_openai\n",
      "  📄 langchain_community.llms.replicate\n",
      "  📄 langchain_community.llms.rwkv\n",
      "  📄 langchain_community.llms.sagemaker_endpoint\n",
      "  📄 langchain_community.llms.sambanova\n",
      "  📄 langchain_community.llms.self_hosted\n",
      "  📄 langchain_community.llms.self_hosted_hugging_face\n",
      "  📄 langchain_community.llms.solar\n",
      "  📄 langchain_community.llms.sparkllm\n",
      "  📄 langchain_community.llms.stochasticai\n",
      "  📄 langchain_community.llms.symblai_nebula\n",
      "  📄 langchain_community.llms.textgen\n",
      "  📄 langchain_community.llms.titan_takeoff\n",
      "  📄 langchain_community.llms.together\n",
      "  📄 langchain_community.llms.tongyi\n",
      "  📄 langchain_community.llms.utils\n",
      "  📄 langchain_community.llms.vertexai\n",
      "  📄 langchain_community.llms.vllm\n",
      "  📄 langchain_community.llms.volcengine_maas\n",
      "  📄 langchain_community.llms.watsonxllm\n",
      "  📄 langchain_community.llms.weight_only_quantization\n",
      "  📄 langchain_community.llms.writer\n",
      "  📄 langchain_community.llms.xinference\n",
      "  📄 langchain_community.llms.yandex\n",
      "  📄 langchain_community.llms.yi\n",
      "  📄 langchain_community.llms.you\n",
      "  📄 langchain_community.llms.yuan2\n",
      "📦 langchain_community.memory\n",
      "  📄 langchain_community.memory.kg\n",
      "  📄 langchain_community.memory.motorhead_memory\n",
      "  📄 langchain_community.memory.zep_cloud_memory\n",
      "  📄 langchain_community.memory.zep_memory\n",
      "📦 langchain_community.output_parsers\n",
      "  📄 langchain_community.output_parsers.ernie_functions\n",
      "  📄 langchain_community.output_parsers.rail_parser\n",
      "📦 langchain_community.query_constructors\n",
      "  📄 langchain_community.query_constructors.astradb\n",
      "  📄 langchain_community.query_constructors.chroma\n",
      "  📄 langchain_community.query_constructors.dashvector\n",
      "  📄 langchain_community.query_constructors.databricks_vector_search\n",
      "  📄 langchain_community.query_constructors.deeplake\n",
      "  📄 langchain_community.query_constructors.dingo\n",
      "  📄 langchain_community.query_constructors.elasticsearch\n",
      "  📄 langchain_community.query_constructors.hanavector\n",
      "  📄 langchain_community.query_constructors.milvus\n",
      "  📄 langchain_community.query_constructors.mongodb_atlas\n",
      "  📄 langchain_community.query_constructors.myscale\n",
      "  📄 langchain_community.query_constructors.neo4j\n",
      "  📄 langchain_community.query_constructors.opensearch\n",
      "  📄 langchain_community.query_constructors.pgvector\n",
      "  📄 langchain_community.query_constructors.pinecone\n",
      "  📄 langchain_community.query_constructors.qdrant\n",
      "  📄 langchain_community.query_constructors.redis\n",
      "  📄 langchain_community.query_constructors.supabase\n",
      "  📄 langchain_community.query_constructors.tencentvectordb\n",
      "  📄 langchain_community.query_constructors.timescalevector\n",
      "  📄 langchain_community.query_constructors.vectara\n",
      "  📄 langchain_community.query_constructors.weaviate\n",
      "📦 langchain_community.retrievers\n",
      "  📄 langchain_community.retrievers.arcee\n",
      "  📄 langchain_community.retrievers.arxiv\n",
      "  📄 langchain_community.retrievers.asknews\n",
      "  📄 langchain_community.retrievers.azure_ai_search\n",
      "  📄 langchain_community.retrievers.bedrock\n",
      "  📄 langchain_community.retrievers.bm25\n",
      "  📄 langchain_community.retrievers.breebs\n",
      "  📄 langchain_community.retrievers.chaindesk\n",
      "  📄 langchain_community.retrievers.chatgpt_plugin_retriever\n",
      "  📄 langchain_community.retrievers.cohere_rag_retriever\n",
      "  📄 langchain_community.retrievers.databerry\n",
      "  📄 langchain_community.retrievers.docarray\n",
      "  📄 langchain_community.retrievers.dria_index\n",
      "  📄 langchain_community.retrievers.elastic_search_bm25\n",
      "  📄 langchain_community.retrievers.embedchain\n",
      "  📄 langchain_community.retrievers.google_cloud_documentai_warehouse\n",
      "  📄 langchain_community.retrievers.google_vertex_ai_search\n",
      "  📄 langchain_community.retrievers.kay\n",
      "  📄 langchain_community.retrievers.kendra\n",
      "  📄 langchain_community.retrievers.knn\n",
      "  📄 langchain_community.retrievers.llama_index\n",
      "  📄 langchain_community.retrievers.metal\n",
      "  📄 langchain_community.retrievers.milvus\n",
      "  📄 langchain_community.retrievers.nanopq\n",
      "  📄 langchain_community.retrievers.needle\n",
      "  📄 langchain_community.retrievers.outline\n",
      "  📄 langchain_community.retrievers.pinecone_hybrid_search\n",
      "  📄 langchain_community.retrievers.pubmed\n",
      "  📄 langchain_community.retrievers.pupmed\n",
      "  📄 langchain_community.retrievers.qdrant_sparse_vector_retriever\n",
      "  📄 langchain_community.retrievers.rememberizer\n",
      "  📄 langchain_community.retrievers.remote_retriever\n",
      "  📄 langchain_community.retrievers.svm\n",
      "  📄 langchain_community.retrievers.tavily_search_api\n",
      "  📄 langchain_community.retrievers.tfidf\n",
      "  📄 langchain_community.retrievers.thirdai_neuraldb\n",
      "  📄 langchain_community.retrievers.vespa_retriever\n",
      "  📄 langchain_community.retrievers.weaviate_hybrid_search\n",
      "  📄 langchain_community.retrievers.web_research\n",
      "  📄 langchain_community.retrievers.wikipedia\n",
      "  📄 langchain_community.retrievers.you\n",
      "  📄 langchain_community.retrievers.zep\n",
      "  📄 langchain_community.retrievers.zep_cloud\n",
      "  📄 langchain_community.retrievers.zilliz\n",
      "📦 langchain_community.storage\n",
      "  📄 langchain_community.storage.astradb\n",
      "  📄 langchain_community.storage.cassandra\n",
      "  📄 langchain_community.storage.exceptions\n",
      "  📄 langchain_community.storage.mongodb\n",
      "  📄 langchain_community.storage.redis\n",
      "  📄 langchain_community.storage.sql\n",
      "  📄 langchain_community.storage.upstash_redis\n",
      "📦 langchain_community.tools\n",
      "  📦 langchain_community.tools.ainetwork\n",
      "    📄 langchain_community.tools.ainetwork.app\n",
      "    📄 langchain_community.tools.ainetwork.base\n",
      "    📄 langchain_community.tools.ainetwork.owner\n",
      "    📄 langchain_community.tools.ainetwork.rule\n",
      "    📄 langchain_community.tools.ainetwork.transfer\n",
      "    📄 langchain_community.tools.ainetwork.utils\n",
      "    📄 langchain_community.tools.ainetwork.value\n",
      "  📦 langchain_community.tools.amadeus\n",
      "    📄 langchain_community.tools.amadeus.base\n",
      "    📄 langchain_community.tools.amadeus.closest_airport\n",
      "    📄 langchain_community.tools.amadeus.flight_search\n",
      "    📄 langchain_community.tools.amadeus.utils\n",
      "  📦 langchain_community.tools.arxiv\n",
      "    📄 langchain_community.tools.arxiv.tool\n",
      "  📦 langchain_community.tools.asknews\n",
      "    📄 langchain_community.tools.asknews.tool\n",
      "  📦 langchain_community.tools.audio\n",
      "    📄 langchain_community.tools.audio.huggingface_text_to_speech_inference\n",
      "  📦 langchain_community.tools.azure_ai_services\n",
      "    📄 langchain_community.tools.azure_ai_services.document_intelligence\n",
      "    📄 langchain_community.tools.azure_ai_services.image_analysis\n",
      "    📄 langchain_community.tools.azure_ai_services.speech_to_text\n",
      "    📄 langchain_community.tools.azure_ai_services.text_analytics_for_health\n",
      "    📄 langchain_community.tools.azure_ai_services.text_to_speech\n",
      "    📄 langchain_community.tools.azure_ai_services.utils\n",
      "  📦 langchain_community.tools.azure_cognitive_services\n",
      "    📄 langchain_community.tools.azure_cognitive_services.form_recognizer\n",
      "    📄 langchain_community.tools.azure_cognitive_services.image_analysis\n",
      "    📄 langchain_community.tools.azure_cognitive_services.speech2text\n",
      "    📄 langchain_community.tools.azure_cognitive_services.text2speech\n",
      "    📄 langchain_community.tools.azure_cognitive_services.text_analytics_health\n",
      "    📄 langchain_community.tools.azure_cognitive_services.utils\n",
      "  📦 langchain_community.tools.bearly\n",
      "    📄 langchain_community.tools.bearly.tool\n",
      "  📦 langchain_community.tools.bing_search\n",
      "    📄 langchain_community.tools.bing_search.tool\n",
      "  📦 langchain_community.tools.brave_search\n",
      "    📄 langchain_community.tools.brave_search.tool\n",
      "  📦 langchain_community.tools.cassandra_database\n",
      "    📄 langchain_community.tools.cassandra_database.prompt\n",
      "    📄 langchain_community.tools.cassandra_database.tool\n",
      "  📦 langchain_community.tools.clickup\n",
      "    📄 langchain_community.tools.clickup.prompt\n",
      "    📄 langchain_community.tools.clickup.tool\n",
      "  📦 langchain_community.tools.cogniswitch\n",
      "    📄 langchain_community.tools.cogniswitch.tool\n",
      "  📦 langchain_community.tools.connery\n",
      "    📄 langchain_community.tools.connery.models\n",
      "    📄 langchain_community.tools.connery.service\n",
      "    📄 langchain_community.tools.connery.tool\n",
      "  📄 langchain_community.tools.convert_to_openai\n",
      "  📦 langchain_community.tools.databricks\n",
      "    📄 langchain_community.tools.databricks._execution\n",
      "    📄 langchain_community.tools.databricks.tool\n",
      "  📦 langchain_community.tools.dataforseo_api_search\n",
      "    📄 langchain_community.tools.dataforseo_api_search.tool\n",
      "  📦 langchain_community.tools.dataherald\n",
      "    📄 langchain_community.tools.dataherald.tool\n",
      "  📦 langchain_community.tools.ddg_search\n",
      "    📄 langchain_community.tools.ddg_search.tool\n",
      "  📦 langchain_community.tools.e2b_data_analysis\n",
      "    📄 langchain_community.tools.e2b_data_analysis.tool\n",
      "    📄 langchain_community.tools.e2b_data_analysis.unparse\n",
      "  📦 langchain_community.tools.edenai\n",
      "    📄 langchain_community.tools.edenai.audio_speech_to_text\n",
      "    📄 langchain_community.tools.edenai.audio_text_to_speech\n",
      "    📄 langchain_community.tools.edenai.edenai_base_tool\n",
      "    📄 langchain_community.tools.edenai.image_explicitcontent\n",
      "    📄 langchain_community.tools.edenai.image_objectdetection\n",
      "    📄 langchain_community.tools.edenai.ocr_identityparser\n",
      "    📄 langchain_community.tools.edenai.ocr_invoiceparser\n",
      "    📄 langchain_community.tools.edenai.text_moderation\n",
      "  📦 langchain_community.tools.eleven_labs\n",
      "    📄 langchain_community.tools.eleven_labs.models\n",
      "    📄 langchain_community.tools.eleven_labs.text2speech\n",
      "  📦 langchain_community.tools.few_shot\n",
      "    📄 langchain_community.tools.few_shot.tool\n",
      "  📦 langchain_community.tools.file_management\n",
      "    📄 langchain_community.tools.file_management.copy\n",
      "    📄 langchain_community.tools.file_management.delete\n",
      "    📄 langchain_community.tools.file_management.file_search\n",
      "    📄 langchain_community.tools.file_management.list_dir\n",
      "    📄 langchain_community.tools.file_management.move\n",
      "    📄 langchain_community.tools.file_management.read\n",
      "    📄 langchain_community.tools.file_management.utils\n",
      "    📄 langchain_community.tools.file_management.write\n",
      "  📦 langchain_community.tools.financial_datasets\n",
      "    📄 langchain_community.tools.financial_datasets.balance_sheets\n",
      "    📄 langchain_community.tools.financial_datasets.cash_flow_statements\n",
      "    📄 langchain_community.tools.financial_datasets.income_statements\n",
      "  📦 langchain_community.tools.github\n",
      "    📄 langchain_community.tools.github.prompt\n",
      "    📄 langchain_community.tools.github.tool\n",
      "  📦 langchain_community.tools.gitlab\n",
      "    📄 langchain_community.tools.gitlab.prompt\n",
      "    📄 langchain_community.tools.gitlab.tool\n",
      "  📦 langchain_community.tools.gmail\n",
      "    📄 langchain_community.tools.gmail.base\n",
      "    📄 langchain_community.tools.gmail.create_draft\n",
      "    📄 langchain_community.tools.gmail.get_message\n",
      "    📄 langchain_community.tools.gmail.get_thread\n",
      "    📄 langchain_community.tools.gmail.search\n",
      "    📄 langchain_community.tools.gmail.send_message\n",
      "    📄 langchain_community.tools.gmail.utils\n",
      "  📦 langchain_community.tools.golden_query\n",
      "    📄 langchain_community.tools.golden_query.tool\n",
      "  📄 langchain_community.tools.google_books\n",
      "  📦 langchain_community.tools.google_cloud\n",
      "    📄 langchain_community.tools.google_cloud.texttospeech\n",
      "  📦 langchain_community.tools.google_finance\n",
      "    📄 langchain_community.tools.google_finance.tool\n",
      "  📦 langchain_community.tools.google_jobs\n",
      "    📄 langchain_community.tools.google_jobs.tool\n",
      "  📦 langchain_community.tools.google_lens\n",
      "    📄 langchain_community.tools.google_lens.tool\n",
      "  📦 langchain_community.tools.google_places\n",
      "    📄 langchain_community.tools.google_places.tool\n",
      "  📦 langchain_community.tools.google_scholar\n",
      "    📄 langchain_community.tools.google_scholar.tool\n",
      "  📦 langchain_community.tools.google_search\n",
      "    📄 langchain_community.tools.google_search.tool\n",
      "  📦 langchain_community.tools.google_serper\n",
      "    📄 langchain_community.tools.google_serper.tool\n",
      "  📦 langchain_community.tools.google_trends\n",
      "    📄 langchain_community.tools.google_trends.tool\n",
      "  📦 langchain_community.tools.graphql\n",
      "    📄 langchain_community.tools.graphql.tool\n",
      "  📦 langchain_community.tools.human\n",
      "    📄 langchain_community.tools.human.tool\n",
      "  📄 langchain_community.tools.ifttt\n",
      "  📦 langchain_community.tools.interaction\n",
      "    📄 langchain_community.tools.interaction.tool\n",
      "  📦 langchain_community.tools.jina_search\n",
      "    📄 langchain_community.tools.jina_search.tool\n",
      "  📦 langchain_community.tools.jira\n",
      "    📄 langchain_community.tools.jira.prompt\n",
      "    📄 langchain_community.tools.jira.tool\n",
      "  📦 langchain_community.tools.json\n",
      "    📄 langchain_community.tools.json.tool\n",
      "  📦 langchain_community.tools.memorize\n",
      "    📄 langchain_community.tools.memorize.tool\n",
      "  📦 langchain_community.tools.merriam_webster\n",
      "    📄 langchain_community.tools.merriam_webster.tool\n",
      "  📦 langchain_community.tools.metaphor_search\n",
      "    📄 langchain_community.tools.metaphor_search.tool\n",
      "  📦 langchain_community.tools.mojeek_search\n",
      "    📄 langchain_community.tools.mojeek_search.tool\n",
      "  📦 langchain_community.tools.multion\n",
      "    📄 langchain_community.tools.multion.close_session\n",
      "    📄 langchain_community.tools.multion.create_session\n",
      "    📄 langchain_community.tools.multion.update_session\n",
      "  📦 langchain_community.tools.nasa\n",
      "    📄 langchain_community.tools.nasa.prompt\n",
      "    📄 langchain_community.tools.nasa.tool\n",
      "  📦 langchain_community.tools.nuclia\n",
      "    📄 langchain_community.tools.nuclia.tool\n",
      "  📦 langchain_community.tools.office365\n",
      "    📄 langchain_community.tools.office365.base\n",
      "    📄 langchain_community.tools.office365.create_draft_message\n",
      "    📄 langchain_community.tools.office365.events_search\n",
      "    📄 langchain_community.tools.office365.messages_search\n",
      "    📄 langchain_community.tools.office365.send_event\n",
      "    📄 langchain_community.tools.office365.send_message\n",
      "    📄 langchain_community.tools.office365.utils\n",
      "  📦 langchain_community.tools.openai_dalle_image_generation\n",
      "    📄 langchain_community.tools.openai_dalle_image_generation.tool\n",
      "  📦 langchain_community.tools.openapi\n",
      "    📦 langchain_community.tools.openapi.utils\n",
      "      📄 langchain_community.tools.openapi.utils.api_models\n",
      "      📄 langchain_community.tools.openapi.utils.openapi_utils\n",
      "  📦 langchain_community.tools.openweathermap\n",
      "    📄 langchain_community.tools.openweathermap.tool\n",
      "  📦 langchain_community.tools.passio_nutrition_ai\n",
      "    📄 langchain_community.tools.passio_nutrition_ai.tool\n",
      "  📦 langchain_community.tools.playwright\n",
      "    📄 langchain_community.tools.playwright.base\n",
      "    📄 langchain_community.tools.playwright.click\n",
      "    📄 langchain_community.tools.playwright.current_page\n",
      "    📄 langchain_community.tools.playwright.extract_hyperlinks\n",
      "    📄 langchain_community.tools.playwright.extract_text\n",
      "    📄 langchain_community.tools.playwright.get_elements\n",
      "    📄 langchain_community.tools.playwright.navigate\n",
      "    📄 langchain_community.tools.playwright.navigate_back\n",
      "    📄 langchain_community.tools.playwright.utils\n",
      "  📄 langchain_community.tools.plugin\n",
      "  📦 langchain_community.tools.polygon\n",
      "    📄 langchain_community.tools.polygon.aggregates\n",
      "    📄 langchain_community.tools.polygon.financials\n",
      "    📄 langchain_community.tools.polygon.last_quote\n",
      "    📄 langchain_community.tools.polygon.ticker_news\n",
      "  📦 langchain_community.tools.powerbi\n",
      "    📄 langchain_community.tools.powerbi.prompt\n",
      "    📄 langchain_community.tools.powerbi.tool\n",
      "  📦 langchain_community.tools.pubmed\n",
      "    📄 langchain_community.tools.pubmed.tool\n",
      "  📄 langchain_community.tools.render\n",
      "  📦 langchain_community.tools.requests\n",
      "    📄 langchain_community.tools.requests.tool\n",
      "  📦 langchain_community.tools.riza\n",
      "    📄 langchain_community.tools.riza.command\n",
      "  📦 langchain_community.tools.scenexplain\n",
      "    📄 langchain_community.tools.scenexplain.tool\n",
      "  📦 langchain_community.tools.searchapi\n",
      "    📄 langchain_community.tools.searchapi.tool\n",
      "  📦 langchain_community.tools.searx_search\n",
      "    📄 langchain_community.tools.searx_search.tool\n",
      "  📦 langchain_community.tools.semanticscholar\n",
      "    📄 langchain_community.tools.semanticscholar.tool\n",
      "  📦 langchain_community.tools.shell\n",
      "    📄 langchain_community.tools.shell.tool\n",
      "  📦 langchain_community.tools.slack\n",
      "    📄 langchain_community.tools.slack.base\n",
      "    📄 langchain_community.tools.slack.get_channel\n",
      "    📄 langchain_community.tools.slack.get_message\n",
      "    📄 langchain_community.tools.slack.schedule_message\n",
      "    📄 langchain_community.tools.slack.send_message\n",
      "    📄 langchain_community.tools.slack.utils\n",
      "  📦 langchain_community.tools.sleep\n",
      "    📄 langchain_community.tools.sleep.tool\n",
      "  📦 langchain_community.tools.spark_sql\n",
      "    📄 langchain_community.tools.spark_sql.prompt\n",
      "    📄 langchain_community.tools.spark_sql.tool\n",
      "  📦 langchain_community.tools.sql_database\n",
      "    📄 langchain_community.tools.sql_database.prompt\n",
      "    📄 langchain_community.tools.sql_database.tool\n",
      "  📦 langchain_community.tools.stackexchange\n",
      "    📄 langchain_community.tools.stackexchange.tool\n",
      "  📦 langchain_community.tools.steam\n",
      "    📄 langchain_community.tools.steam.prompt\n",
      "    📄 langchain_community.tools.steam.tool\n",
      "  📦 langchain_community.tools.steamship_image_generation\n",
      "    📄 langchain_community.tools.steamship_image_generation.tool\n",
      "    📄 langchain_community.tools.steamship_image_generation.utils\n",
      "  📦 langchain_community.tools.tavily_search\n",
      "    📄 langchain_community.tools.tavily_search.tool\n",
      "  📦 langchain_community.tools.vectorstore\n",
      "    📄 langchain_community.tools.vectorstore.tool\n",
      "  📦 langchain_community.tools.wikidata\n",
      "    📄 langchain_community.tools.wikidata.tool\n",
      "  📦 langchain_community.tools.wikipedia\n",
      "    📄 langchain_community.tools.wikipedia.tool\n",
      "  📦 langchain_community.tools.wolfram_alpha\n",
      "    📄 langchain_community.tools.wolfram_alpha.tool\n",
      "  📄 langchain_community.tools.yahoo_finance_news\n",
      "  📦 langchain_community.tools.you\n",
      "    📄 langchain_community.tools.you.tool\n",
      "  📦 langchain_community.tools.youtube\n",
      "    📄 langchain_community.tools.youtube.search\n",
      "  📦 langchain_community.tools.zapier\n",
      "    📄 langchain_community.tools.zapier.prompt\n",
      "    📄 langchain_community.tools.zapier.tool\n",
      "  📦 langchain_community.tools.zenguard\n",
      "    📄 langchain_community.tools.zenguard.tool\n",
      "📦 langchain_community.utilities\n",
      "  📄 langchain_community.utilities.alpha_vantage\n",
      "  📄 langchain_community.utilities.anthropic\n",
      "  📄 langchain_community.utilities.apify\n",
      "  📄 langchain_community.utilities.arcee\n",
      "  📄 langchain_community.utilities.arxiv\n",
      "  📄 langchain_community.utilities.asknews\n",
      "  📄 langchain_community.utilities.astradb\n",
      "  📄 langchain_community.utilities.awslambda\n",
      "  📄 langchain_community.utilities.bibtex\n",
      "  📄 langchain_community.utilities.bing_search\n",
      "  📄 langchain_community.utilities.brave_search\n",
      "  📄 langchain_community.utilities.cassandra\n",
      "  📄 langchain_community.utilities.cassandra_database\n",
      "  📄 langchain_community.utilities.clickup\n",
      "  📄 langchain_community.utilities.dalle_image_generator\n",
      "  📄 langchain_community.utilities.dataforseo_api_search\n",
      "  📄 langchain_community.utilities.dataherald\n",
      "  📄 langchain_community.utilities.dria_index\n",
      "  📄 langchain_community.utilities.duckduckgo_search\n",
      "  📄 langchain_community.utilities.financial_datasets\n",
      "  📄 langchain_community.utilities.github\n",
      "  📄 langchain_community.utilities.gitlab\n",
      "  📄 langchain_community.utilities.golden_query\n",
      "  📄 langchain_community.utilities.google_books\n",
      "  📄 langchain_community.utilities.google_finance\n",
      "  📄 langchain_community.utilities.google_jobs\n",
      "  📄 langchain_community.utilities.google_lens\n",
      "  📄 langchain_community.utilities.google_places_api\n",
      "  📄 langchain_community.utilities.google_scholar\n",
      "  📄 langchain_community.utilities.google_search\n",
      "  📄 langchain_community.utilities.google_serper\n",
      "  📄 langchain_community.utilities.google_trends\n",
      "  📄 langchain_community.utilities.graphql\n",
      "  📄 langchain_community.utilities.infobip\n",
      "  📄 langchain_community.utilities.jina_search\n",
      "  📄 langchain_community.utilities.jira\n",
      "  📄 langchain_community.utilities.max_compute\n",
      "  📄 langchain_community.utilities.merriam_webster\n",
      "  📄 langchain_community.utilities.metaphor_search\n",
      "  📄 langchain_community.utilities.mojeek_search\n",
      "  📄 langchain_community.utilities.nasa\n",
      "  📄 langchain_community.utilities.nvidia_riva\n",
      "  📄 langchain_community.utilities.opaqueprompts\n",
      "  📄 langchain_community.utilities.openapi\n",
      "  📄 langchain_community.utilities.openweathermap\n",
      "  📄 langchain_community.utilities.oracleai\n",
      "  📄 langchain_community.utilities.outline\n",
      "  📄 langchain_community.utilities.passio_nutrition_ai\n",
      "  📄 langchain_community.utilities.pebblo\n",
      "  📄 langchain_community.utilities.polygon\n",
      "  📄 langchain_community.utilities.portkey\n",
      "  📄 langchain_community.utilities.powerbi\n",
      "  📄 langchain_community.utilities.pubmed\n",
      "  📄 langchain_community.utilities.python\n",
      "  📄 langchain_community.utilities.reddit_search\n",
      "  📄 langchain_community.utilities.redis\n",
      "  📄 langchain_community.utilities.rememberizer\n",
      "  📄 langchain_community.utilities.requests\n",
      "  📄 langchain_community.utilities.scenexplain\n",
      "  📄 langchain_community.utilities.searchapi\n",
      "  📄 langchain_community.utilities.searx_search\n",
      "  📄 langchain_community.utilities.semanticscholar\n",
      "  📄 langchain_community.utilities.serpapi\n",
      "  📄 langchain_community.utilities.spark_sql\n",
      "  📄 langchain_community.utilities.sql_database\n",
      "  📄 langchain_community.utilities.stackexchange\n",
      "  📄 langchain_community.utilities.steam\n",
      "  📄 langchain_community.utilities.tavily_search\n",
      "  📄 langchain_community.utilities.tensorflow_datasets\n",
      "  📄 langchain_community.utilities.twilio\n",
      "  📄 langchain_community.utilities.vertexai\n",
      "  📄 langchain_community.utilities.wikidata\n",
      "  📄 langchain_community.utilities.wikipedia\n",
      "  📄 langchain_community.utilities.wolfram_alpha\n",
      "  📄 langchain_community.utilities.you\n",
      "  📄 langchain_community.utilities.zapier\n",
      "📦 langchain_community.utils\n",
      "  📄 langchain_community.utils.ernie_functions\n",
      "  📄 langchain_community.utils.google\n",
      "  📄 langchain_community.utils.math\n",
      "  📄 langchain_community.utils.openai\n",
      "  📄 langchain_community.utils.openai_functions\n",
      "  📄 langchain_community.utils.user_agent\n",
      "📦 langchain_community.vectorstores\n",
      "  📄 langchain_community.vectorstores.aerospike\n",
      "  📄 langchain_community.vectorstores.alibabacloud_opensearch\n",
      "  📄 langchain_community.vectorstores.analyticdb\n",
      "  📄 langchain_community.vectorstores.annoy\n",
      "  📄 langchain_community.vectorstores.apache_doris\n",
      "  📄 langchain_community.vectorstores.aperturedb\n",
      "  📄 langchain_community.vectorstores.astradb\n",
      "  📄 langchain_community.vectorstores.atlas\n",
      "  📄 langchain_community.vectorstores.awadb\n",
      "  📄 langchain_community.vectorstores.azure_cosmos_db\n",
      "  📄 langchain_community.vectorstores.azure_cosmos_db_no_sql\n",
      "  📄 langchain_community.vectorstores.azuresearch\n",
      "  📄 langchain_community.vectorstores.bagel\n",
      "  📄 langchain_community.vectorstores.bageldb\n",
      "  📄 langchain_community.vectorstores.baiducloud_vector_search\n",
      "  📄 langchain_community.vectorstores.baiduvectordb\n",
      "  📄 langchain_community.vectorstores.bigquery_vector_search\n",
      "  📄 langchain_community.vectorstores.cassandra\n",
      "  📄 langchain_community.vectorstores.chroma\n",
      "  📄 langchain_community.vectorstores.clarifai\n",
      "  📄 langchain_community.vectorstores.clickhouse\n",
      "  📄 langchain_community.vectorstores.couchbase\n",
      "  📄 langchain_community.vectorstores.dashvector\n",
      "  📄 langchain_community.vectorstores.databricks_vector_search\n",
      "  📄 langchain_community.vectorstores.deeplake\n",
      "  📄 langchain_community.vectorstores.dingo\n",
      "  📦 langchain_community.vectorstores.docarray\n",
      "    📄 langchain_community.vectorstores.docarray.base\n",
      "    📄 langchain_community.vectorstores.docarray.hnsw\n",
      "    📄 langchain_community.vectorstores.docarray.in_memory\n",
      "  📄 langchain_community.vectorstores.documentdb\n",
      "  📄 langchain_community.vectorstores.duckdb\n",
      "  📄 langchain_community.vectorstores.ecloud_vector_search\n",
      "  📄 langchain_community.vectorstores.elastic_vector_search\n",
      "  📄 langchain_community.vectorstores.elasticsearch\n",
      "  📄 langchain_community.vectorstores.epsilla\n",
      "  📄 langchain_community.vectorstores.faiss\n",
      "  📄 langchain_community.vectorstores.falkordb_vector\n",
      "  📄 langchain_community.vectorstores.hanavector\n",
      "  📄 langchain_community.vectorstores.hippo\n",
      "  📄 langchain_community.vectorstores.hologres\n",
      "  📄 langchain_community.vectorstores.infinispanvs\n",
      "  📄 langchain_community.vectorstores.inmemory\n",
      "  📄 langchain_community.vectorstores.jaguar\n",
      "  📄 langchain_community.vectorstores.kdbai\n",
      "  📄 langchain_community.vectorstores.kinetica\n",
      "  📄 langchain_community.vectorstores.lancedb\n",
      "  📄 langchain_community.vectorstores.lantern\n",
      "  📄 langchain_community.vectorstores.llm_rails\n",
      "  📄 langchain_community.vectorstores.manticore_search\n",
      "  📄 langchain_community.vectorstores.marqo\n",
      "  📄 langchain_community.vectorstores.matching_engine\n",
      "  📄 langchain_community.vectorstores.meilisearch\n",
      "  📄 langchain_community.vectorstores.milvus\n",
      "  📄 langchain_community.vectorstores.momento_vector_index\n",
      "  📄 langchain_community.vectorstores.mongodb_atlas\n",
      "  📄 langchain_community.vectorstores.myscale\n",
      "  📄 langchain_community.vectorstores.neo4j_vector\n",
      "  📄 langchain_community.vectorstores.nucliadb\n",
      "  📄 langchain_community.vectorstores.opensearch_vector_search\n",
      "  📄 langchain_community.vectorstores.oraclevs\n",
      "  📄 langchain_community.vectorstores.pathway\n",
      "  📄 langchain_community.vectorstores.pgembedding\n",
      "  📄 langchain_community.vectorstores.pgvecto_rs\n",
      "  📄 langchain_community.vectorstores.pgvector\n",
      "  📄 langchain_community.vectorstores.pinecone\n",
      "  📄 langchain_community.vectorstores.qdrant\n",
      "  📦 langchain_community.vectorstores.redis\n",
      "    📄 langchain_community.vectorstores.redis.base\n",
      "    📄 langchain_community.vectorstores.redis.constants\n",
      "    📄 langchain_community.vectorstores.redis.filters\n",
      "    📄 langchain_community.vectorstores.redis.schema\n",
      "  📄 langchain_community.vectorstores.relyt\n",
      "  📄 langchain_community.vectorstores.rocksetdb\n",
      "  📄 langchain_community.vectorstores.scann\n",
      "  📄 langchain_community.vectorstores.semadb\n",
      "  📄 langchain_community.vectorstores.singlestoredb\n",
      "  📄 langchain_community.vectorstores.sklearn\n",
      "  📄 langchain_community.vectorstores.sqlitevec\n",
      "  📄 langchain_community.vectorstores.sqlitevss\n",
      "  📄 langchain_community.vectorstores.starrocks\n",
      "  📄 langchain_community.vectorstores.supabase\n",
      "  📄 langchain_community.vectorstores.surrealdb\n",
      "  📄 langchain_community.vectorstores.tablestore\n",
      "  📄 langchain_community.vectorstores.tair\n",
      "  📄 langchain_community.vectorstores.tencentvectordb\n",
      "  📄 langchain_community.vectorstores.thirdai_neuraldb\n",
      "  📄 langchain_community.vectorstores.tidb_vector\n",
      "  📄 langchain_community.vectorstores.tigris\n",
      "  📄 langchain_community.vectorstores.tiledb\n",
      "  📄 langchain_community.vectorstores.timescalevector\n",
      "  📄 langchain_community.vectorstores.typesense\n",
      "  📄 langchain_community.vectorstores.upstash\n",
      "  📄 langchain_community.vectorstores.usearch\n",
      "  📄 langchain_community.vectorstores.utils\n",
      "  📄 langchain_community.vectorstores.vald\n",
      "  📄 langchain_community.vectorstores.vdms\n",
      "  📄 langchain_community.vectorstores.vearch\n",
      "  📄 langchain_community.vectorstores.vectara\n",
      "  📄 langchain_community.vectorstores.vespa\n",
      "  📄 langchain_community.vectorstores.vikingdb\n",
      "  📄 langchain_community.vectorstores.vlite\n",
      "  📄 langchain_community.vectorstores.weaviate\n",
      "  📄 langchain_community.vectorstores.xata\n",
      "  📄 langchain_community.vectorstores.yellowbrick\n",
      "  📄 langchain_community.vectorstores.zep\n",
      "  📄 langchain_community.vectorstores.zep_cloud\n",
      "  📄 langchain_community.vectorstores.zilliz\n"
     ]
    }
   ],
   "source": [
    "import pkgutil\n",
    "import  langchain_community \n",
    "\n",
    "def tree(pkg):\n",
    "    base = pkg.__name__ + \".\"\n",
    "    for info in pkgutil.walk_packages(pkg.__path__, base):\n",
    "        indent = info.name.count(\".\") - base.count(\".\")\n",
    "        print(\"  \" * indent + (\"📦 \" if info.ispkg else \"📄 \") + info.name)\n",
    "\n",
    "tree(langchain_community)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3490411a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
